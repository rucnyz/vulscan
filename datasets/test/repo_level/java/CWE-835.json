[
  {
    "CWE_ID": [
      "CWE-835"
    ],
    "code": "/*\n *  Licensed under the Apache License, Version 2.0 (the \"License\");\n *  you may not use this file except in compliance with the License.\n *  You may obtain a copy of the License at\n * \n *       http://www.apache.org/licenses/LICENSE-2.0\n * \n *  Unless required by applicable law or agreed to in writing, software\n *  distributed under the License is distributed on an \"AS IS\" BASIS,\n *  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n *  See the License for the specific language governing permissions and\n *  limitations under the License.\n *  under the License.\n */\n\npackage org.apache.sanselan.formats.jpeg.decoder;\n\nimport java.awt.image.BufferedImage;\nimport java.awt.image.ColorModel;\nimport java.awt.image.DataBuffer;\nimport java.awt.image.DirectColorModel;\nimport java.awt.image.WritableRaster;\nimport java.io.ByteArrayInputStream;\nimport java.io.IOException;\nimport java.util.Arrays;\nimport java.util.Properties;\nimport org.apache.sanselan.ImageReadException;\nimport org.apache.sanselan.common.BinaryFileParser;\nimport org.apache.sanselan.common.byteSources.ByteSource;\nimport org.apache.sanselan.formats.jpeg.Block;\nimport org.apache.sanselan.formats.jpeg.JpegConstants;\nimport org.apache.sanselan.formats.jpeg.JpegUtils;\nimport org.apache.sanselan.formats.jpeg.ZigZag;\nimport org.apache.sanselan.formats.jpeg.segments.DHTSegment;\nimport org.apache.sanselan.formats.jpeg.segments.DQTSegment;\nimport org.apache.sanselan.formats.jpeg.segments.SOFNSegment;\nimport org.apache.sanselan.formats.jpeg.segments.SOSSegment;\n\npublic class JpegDecoder extends BinaryFileParser implements JpegUtils.Visitor,\n        JpegConstants\n{\n    /*\n     * JPEG is an advanced image format that takes\n     * significant computation to decode. Keep\n     * decoding fast:\n     * - Don't allocate memory inside loops,\n     *   allocate it once and reuse.\n     * - Minimize calculations\n     *   per pixel and per block (using lookup tables\n     *   for YCbCr->RGB conversion doubled performance).\n     * - Math.round() is slow, use (int)(x+0.5f) instead\n     *   for positive numbers.\n     */\n\n    private DQTSegment.QuantizationTable[] quantizationTables = new DQTSegment.QuantizationTable[4];\n    private DHTSegment.HuffmanTable[] huffmanDCTables = new DHTSegment.HuffmanTable[4];\n    private DHTSegment.HuffmanTable[] huffmanACTables = new DHTSegment.HuffmanTable[4];\n    private SOFNSegment sofnSegment;\n    private SOSSegment sosSegment;\n    private float[][] scaledQuantizationTables = new float[4][];\n    private BufferedImage image = null;\n    private ImageReadException imageReadException = null;\n    private IOException ioException = null;\n\n    public boolean beginSOS()\n    {\n        return true;\n    }\n\n    public void visitSOS(int marker, byte markerBytes[],\n                    byte imageData[])\n    {\n        ByteArrayInputStream is = new ByteArrayInputStream(imageData);\n        try\n        {\n            int segmentLength = read2Bytes(\"segmentLength\", is,\n                    \"Not a Valid JPEG File\");\n            byte[] sosSegmentBytes = readByteArray(\"SOSSegment\",\n                    segmentLength - 2, is, \"Not a Valid JPEG File\");\n            sosSegment = new SOSSegment(marker, sosSegmentBytes);\n\n            int hMax = 0;\n            int vMax = 0;\n            for (int i = 0; i < sofnSegment.numberOfComponents; i++)\n            {\n                hMax = Math.max(hMax, sofnSegment.components[i].horizontalSamplingFactor);\n                vMax = Math.max(vMax, sofnSegment.components[i].verticalSamplingFactor);\n            }\n            int hSize = 8*hMax;\n            int vSize = 8*vMax;\n\n            JpegInputStream bitInputStream = new JpegInputStream(is);\n            int xMCUs = (sofnSegment.width + hSize - 1) / hSize;\n            int yMCUs = (sofnSegment.height + vSize - 1) / vSize;\n            Block[] mcu = allocateMCUMemory();\n            Block[] scaledMCU = new Block[mcu.length];\n            for (int i = 0; i < scaledMCU.length; i++)\n                scaledMCU[i] = new Block(hSize, vSize);\n            int[] preds = new int[sofnSegment.numberOfComponents];\n            ColorModel colorModel;\n            WritableRaster raster;\n            if (sofnSegment.numberOfComponents == 3)\n            {\n                colorModel = new DirectColorModel(24,\n                        0x00ff0000, 0x0000ff00, 0x000000ff);\n                raster = WritableRaster.createPackedRaster(DataBuffer.TYPE_INT,\n                        sofnSegment.width, sofnSegment.height,\n                        new int[]{0x00ff0000,0x0000ff00,0x000000ff}, null);\n            }\n            else if (sofnSegment.numberOfComponents == 1)\n            {\n                colorModel = new DirectColorModel(24,\n                        0x00ff0000, 0x0000ff00, 0x000000ff);\n                raster = WritableRaster.createPackedRaster(DataBuffer.TYPE_INT,\n                        sofnSegment.width, sofnSegment.height,\n                        new int[]{0x00ff0000,0x0000ff00,0x000000ff}, null);\n                // FIXME: why do images come out too bright with CS_GRAY?\n//                colorModel = new ComponentColorModel(\n//                        ColorSpace.getInstance(ColorSpace.CS_GRAY), false, true,\n//                        Transparency.OPAQUE, DataBuffer.TYPE_BYTE);\n//                raster = colorModel.createCompatibleWritableRaster(\n//                        sofnSegment.width, sofnSegment.height);\n            }\n            else\n                throw new ImageReadException(sofnSegment.numberOfComponents +\n                        \" components are invalid or unsupported\");\n            DataBuffer dataBuffer = raster.getDataBuffer();\n\n            \n            for (int y1 = 0; y1 < vSize*yMCUs; y1 += vSize)\n            {\n                for (int x1 = 0; x1 < hSize*xMCUs; x1 += hSize)\n                {\n                    readMCU(bitInputStream, preds, mcu);\n                    rescaleMCU(mcu, hSize, vSize, scaledMCU);\n                    int srcRowOffset = 0;\n                    int dstRowOffset = y1*sofnSegment.width + x1;\n                    for (int y2 = 0; y2 < vSize && y1 + y2 < sofnSegment.height; y2++)\n                    {\n                        for (int x2 = 0; x2 < hSize && x1 + x2 < sofnSegment.width; x2++)\n                        {\n                            if (scaledMCU.length == 3)\n                            {\n                                int Y = scaledMCU[0].samples[srcRowOffset + x2];\n                                int Cb = scaledMCU[1].samples[srcRowOffset + x2];\n                                int Cr = scaledMCU[2].samples[srcRowOffset + x2];\n                                int rgb = YCbCrConverter.convertYCbCrToRGB(Y, Cb, Cr);\n                                dataBuffer.setElem(dstRowOffset + x2, rgb);\n                            }\n                            else if (mcu.length == 1)\n                            {\n                                int Y = scaledMCU[0].samples[srcRowOffset + x2];\n                                dataBuffer.setElem(dstRowOffset + x2,\n                                        (Y << 16) | (Y << 8) | Y);\n                            }\n                            else\n                                throw new ImageReadException(\"Unsupported JPEG with \" +\n                                        mcu.length + \" components\");\n                        }\n                        srcRowOffset += hSize;\n                        dstRowOffset += sofnSegment.width;\n                    }\n                }\n            }\n            image = new BufferedImage(colorModel, raster,\n                    colorModel.isAlphaPremultiplied(), new Properties());\n            //byte[] remainder = super.getStreamBytes(is);\n            //for (int i = 0; i < remainder.length; i++)\n            //{\n            //    System.out.println(\"\" + i + \" = \" + Integer.toHexString(remainder[i]));\n            //}\n        }\n        catch (ImageReadException imageReadEx)\n        {\n            imageReadException = imageReadEx;\n        }\n        catch (IOException ioEx)\n        {\n            ioException = ioEx;\n        }\n        catch (RuntimeException ex)\n        {\n            // Corrupt images can throw NPE and IOOBE\n            imageReadException = new ImageReadException(\"Error parsing JPEG\", ex);\n        }\n    }\n\n    public boolean visitSegment(int marker, byte[] markerBytes,\n            int segmentLength, byte[] segmentLengthBytes,\n            byte[] segmentData) throws ImageReadException, IOException\n    {\n        final int[] sofnSegments = {\n            SOF0Marker,\n            SOF1Marker, SOF2Marker, SOF3Marker, SOF5Marker, SOF6Marker,\n            SOF7Marker, SOF9Marker, SOF10Marker, SOF11Marker, SOF13Marker,\n            SOF14Marker, SOF15Marker,\n        };\n\n        if (Arrays.binarySearch(sofnSegments, marker) >= 0)\n        {\n            if (marker != SOF0Marker)\n                throw new ImageReadException(\"Only sequential, baseline JPEGs \" +\n                        \"are supported at the moment\");\n            sofnSegment = new SOFNSegment(marker, segmentData);\n        }\n        else if (marker == DQTMarker)\n        {\n            DQTSegment dqtSegment = new DQTSegment(marker, segmentData);\n            for (int i = 0; i < dqtSegment.quantizationTables.size(); i++)\n            {\n                DQTSegment.QuantizationTable table = (DQTSegment.QuantizationTable)\n                        dqtSegment.quantizationTables.get(i);\n                if (0 > table.destinationIdentifier ||\n                        table.destinationIdentifier >= quantizationTables.length)\n                    throw new ImageReadException(\"Invalid quantization table identifier \" +\n                            table.destinationIdentifier);\n                quantizationTables[table.destinationIdentifier] = table;\n                int[] quantizationMatrixInt = new int[64];\n                ZigZag.zigZagToBlock(table.elements, quantizationMatrixInt);\n                float[] quantizationMatrixFloat = new float[64];\n                for (int j = 0; j < 64; j++)\n                    quantizationMatrixFloat[j] = quantizationMatrixInt[j];\n                DCT.scaleDequantizationMatrix(quantizationMatrixFloat);\n                scaledQuantizationTables[table.destinationIdentifier] =\n                        quantizationMatrixFloat;\n            }\n        }\n        else if (marker == DHTMarker)\n        {\n            DHTSegment dhtSegment = new DHTSegment(marker, segmentData);\n            for (int i = 0; i < dhtSegment.huffmanTables.size(); i++)\n            {\n                DHTSegment.HuffmanTable table = (DHTSegment.HuffmanTable)\n                        dhtSegment.huffmanTables.get(i);\n                DHTSegment.HuffmanTable[] tables;\n                if (table.tableClass == 0)\n                    tables = huffmanDCTables;\n                else if (table.tableClass == 1)\n                    tables = huffmanACTables;\n                else\n                    throw new ImageReadException(\"Invalid huffman table class \" +\n                            table.tableClass);\n                if (0 > table.destinationIdentifier ||\n                        table.destinationIdentifier >= tables.length)\n                    throw new ImageReadException(\"Invalid huffman table identifier \" +\n                            table.destinationIdentifier);\n                tables[table.destinationIdentifier] = table;\n            }\n        }\n        return true;\n    }\n\n    private void rescaleMCU(Block[] dataUnits, int hSize, int vSize, Block[] ret)\n    {\n        for (int i = 0; i < dataUnits.length; i++)\n        {\n            Block block = dataUnits[i];\n            if (block.width == hSize && block.height == vSize)\n                System.arraycopy(block.samples, 0, ret[i].samples, 0, hSize*vSize);\n            else\n            {\n                int hScale = hSize / block.width;\n                int vScale = vSize / block.height;\n                if (hScale == 2 && vScale == 2)\n                {\n                    int srcRowOffset = 0;\n                    int dstRowOffset = 0;\n                    for (int y = 0; y < block.height; y++)\n                    {\n                        for (int x = 0; x < hSize; x++)\n                        {\n                            int sample = block.samples[srcRowOffset + (x >> 1)];\n                            ret[i].samples[dstRowOffset + x] = sample;\n                            ret[i].samples[dstRowOffset + hSize + x] = sample;\n                        }\n                        srcRowOffset += block.width;\n                        dstRowOffset += 2*hSize;\n                    }\n                }\n                else\n                {\n                    // FIXME: optimize\n                    int dstRowOffset = 0;\n                    for (int y = 0; y < vSize; y++)\n                    {\n                        for (int x = 0; x < hSize; x++)\n                        {\n                            ret[i].samples[dstRowOffset + x] =\n                                    block.samples[(y/vScale)*block.width + (x/hScale)];\n                        }\n                        dstRowOffset += hSize;\n                    }\n                }\n            }\n        }\n    }\n    \n    private Block[] allocateMCUMemory() throws ImageReadException\n    {\n        Block[] mcu = new Block[sosSegment.numberOfComponents];\n        for (int i = 0; i < sosSegment.numberOfComponents; i++)\n        {\n            SOSSegment.Component scanComponent = sosSegment.components[i];\n            SOFNSegment.Component frameComponent = null;\n            for (int j = 0; j < sofnSegment.numberOfComponents; j++)\n            {\n                if (sofnSegment.components[j].componentIdentifier ==\n                    scanComponent.scanComponentSelector)\n                {\n                    frameComponent = sofnSegment.components[j];\n                    break;\n                }\n            }\n            if (frameComponent == null)\n                throw new ImageReadException(\"Invalid component\");\n            Block fullBlock = new Block(\n                    8*frameComponent.horizontalSamplingFactor,\n                    8*frameComponent.verticalSamplingFactor);\n            mcu[i] = fullBlock;\n        }\n        return mcu;\n    }\n\n    private int[] zz = new int[64];\n    private int[] blockInt = new int[64];\n    private float[] block = new float[64];\n    private void readMCU(JpegInputStream is, int[] preds, Block[] mcu)\n            throws IOException, ImageReadException\n    {\n        for (int i = 0; i < sosSegment.numberOfComponents; i++)\n        {\n            SOSSegment.Component scanComponent = sosSegment.components[i];\n            SOFNSegment.Component frameComponent = null;\n            for (int j = 0; j < sofnSegment.numberOfComponents; j++)\n            {\n                if (sofnSegment.components[j].componentIdentifier ==\n                    scanComponent.scanComponentSelector)\n                {\n                    frameComponent = sofnSegment.components[j];\n                    break;\n                }\n            }\n            if (frameComponent == null)\n                throw new ImageReadException(\"Invalid component\");\n            Block fullBlock = mcu[i];\n            for (int y = 0; y < frameComponent.verticalSamplingFactor; y++)\n            {\n                for (int x = 0; x < frameComponent.horizontalSamplingFactor; x++)\n                {\n                    Arrays.fill(zz, 0);\n                    // page 104 of T.81\n                    int t = decode(is,\n                            huffmanDCTables[scanComponent.dcCodingTableSelector]);\n                    int diff = receive(t, is);\n                    diff = extend(diff, t);\n                    zz[0] = preds[i] + diff;\n                    preds[i] = zz[0];\n\n                    // \"Decode_AC_coefficients\", figure F.13, page 106 of T.81\n                    int k = 1;\n                    while (true)\n                    {\n                        int rs = decode(is,\n                                huffmanACTables[scanComponent.acCodingTableSelector]);\n                        int ssss = rs & 0xf;\n                        int rrrr = rs >> 4;\n                        int r = rrrr;\n\n                        if (ssss == 0)\n                        {\n                            if (r == 15)\n                                k += 16;\n                            else\n                                break;\n                        }\n                        else\n                        {\n                            k += r;\n\n                            // \"Decode_ZZ(k)\", figure F.14, page 107 of T.81\n                            zz[k] = receive(ssss, is);\n                            zz[k] = extend(zz[k], ssss);\n\n                            if (k == 63)\n                                break;\n                            else\n                                k++;\n                        }\n                    }\n\n                    final int shift = (1 << (sofnSegment.precision - 1));\n                    final int max = (1 << sofnSegment.precision) - 1;\n\n                    float[] scaledQuantizationTable =\n                            scaledQuantizationTables[frameComponent.quantTabDestSelector];\n                    ZigZag.zigZagToBlock(zz, blockInt);\n                    for (int j = 0; j < 64; j++)\n                        block[j] = blockInt[j] * scaledQuantizationTable[j];\n                    DCT.inverseDCT8x8(block);\n\n                    int dstRowOffset = 8*y*8*frameComponent.horizontalSamplingFactor +\n                            8*x;\n                    int srcNext = 0;\n                    for (int yy = 0; yy < 8; yy++)\n                    {\n                        for (int xx = 0; xx < 8; xx++)\n                        {\n                            float sample = block[srcNext++];\n                            sample += shift;\n                            int result;\n                            if (sample < 0)\n                                result = 0;\n                            else if (sample > max)\n                                result = max;\n                            else\n                                result = fastRound(sample);\n                            fullBlock.samples[dstRowOffset + xx] = result;\n                        }\n                        dstRowOffset += 8*frameComponent.horizontalSamplingFactor;\n                    }\n                }\n            }\n        }\n    }\n\n    private static int fastRound(float x)\n    {\n        return (int) (x + 0.5f);\n    }\n\n    private int extend(int v, int t)\n    {\n        // \"EXTEND\", section F.2.2.1, figure F.12, page 105 of T.81\n        int vt = (1 << (t - 1));\n        while (v < vt)\n        {\n            vt = (-1 << t) + 1;\n            v += vt;\n        }\n        return v;\n    }\n\n    private int receive(int ssss, JpegInputStream is)\n            throws IOException, ImageReadException\n    {\n        // \"RECEIVE\", section F.2.2.4, figure F.17, page 110 of T.81\n        int i = 0;\n        int v = 0;\n        while (i != ssss)\n        {\n            i++;\n            v = (v << 1) + is.nextBit();\n        }\n        return v;\n    }\n\n    private int decode(JpegInputStream is, DHTSegment.HuffmanTable huffmanTable)\n            throws IOException, ImageReadException\n    {\n        // \"DECODE\", section F.2.2.3, figure F.16, page 109 of T.81\n        int i = 1;\n        int code = is.nextBit();\n        while (code > huffmanTable.maxCode[i])\n        {\n            i++;\n            code = (code << 1) | is.nextBit();\n        }\n        int j = huffmanTable.valPtr[i];\n        j += code - huffmanTable.minCode[i];\n        int value = huffmanTable.huffVal[j];\n        return value;\n    }\n\n    public BufferedImage decode(ByteSource byteSource)\n            throws IOException, ImageReadException\n    {\n        JpegUtils jpegUtils = new JpegUtils();\n        jpegUtils.traverseJFIF(byteSource, this);\n        if (imageReadException != null)\n            throw imageReadException;\n        if (ioException != null)\n            throw ioException;\n        return image;\n    }\n}",
    "target": 1,
    "language": "java",
    "dataset": "A-Manually-Curated-Dataset-of-Vulnerability-Introducing-Commits-in-Java",
    "idx": 800020,
    "RELATED_CWE": [
      "CWE-908",
      "CWE-362",
      "CWE-667"
    ]
  },
  {
    "CWE_ID": [
      "CWE-835"
    ],
    "code": "/*\n *  Licensed under the Apache License, Version 2.0 (the \"License\");\n *  you may not use this file except in compliance with the License.\n *  You may obtain a copy of the License at\n *\n *       http://www.apache.org/licenses/LICENSE-2.0\n *\n *  Unless required by applicable law or agreed to in writing, software\n *  distributed under the License is distributed on an \"AS IS\" BASIS,\n *  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n *  See the License for the specific language governing permissions and\n *  limitations under the License.\n *  under the License.\n */\n\npackage org.apache.commons.imaging.formats.jpeg.decoder;\n\nimport static org.apache.commons.imaging.common.BinaryFunctions.read2Bytes;\nimport static org.apache.commons.imaging.common.BinaryFunctions.readBytes;\n\nimport java.awt.image.BufferedImage;\nimport java.awt.image.ColorModel;\nimport java.awt.image.DataBuffer;\nimport java.awt.image.DirectColorModel;\nimport java.awt.image.Raster;\nimport java.awt.image.WritableRaster;\nimport java.io.ByteArrayInputStream;\nimport java.io.IOException;\nimport java.util.Arrays;\nimport java.util.Properties;\n\nimport org.apache.commons.imaging.ImageReadException;\nimport org.apache.commons.imaging.common.BinaryFileParser;\nimport org.apache.commons.imaging.common.bytesource.ByteSource;\nimport org.apache.commons.imaging.formats.jpeg.JpegConstants;\nimport org.apache.commons.imaging.formats.jpeg.JpegUtils;\nimport org.apache.commons.imaging.formats.jpeg.segments.DhtSegment;\nimport org.apache.commons.imaging.formats.jpeg.segments.DqtSegment;\nimport org.apache.commons.imaging.formats.jpeg.segments.SofnSegment;\nimport org.apache.commons.imaging.formats.jpeg.segments.SosSegment;\n\npublic class JpegDecoder extends BinaryFileParser implements JpegUtils.Visitor {\n    /*\n     * JPEG is an advanced image format that takes significant computation to\n     * decode. Keep decoding fast: - Don't allocate memory inside loops,\n     * allocate it once and reuse. - Minimize calculations per pixel and per\n     * block (using lookup tables for YCbCr->RGB conversion doubled\n     * performance). - Math.round() is slow, use (int)(x+0.5f) instead for\n     * positive numbers.\n     */\n\n    private final DqtSegment.QuantizationTable[] quantizationTables = new DqtSegment.QuantizationTable[4];\n    private final DhtSegment.HuffmanTable[] huffmanDCTables = new DhtSegment.HuffmanTable[4];\n    private final DhtSegment.HuffmanTable[] huffmanACTables = new DhtSegment.HuffmanTable[4];\n    private SofnSegment sofnSegment;\n    private SosSegment sosSegment;\n    private final float[][] scaledQuantizationTables = new float[4][];\n    private BufferedImage image;\n    private ImageReadException imageReadException;\n    private IOException ioException;\n    private final int[] zz = new int[64];\n    private final int[] blockInt = new int[64];\n    private final float[] block = new float[64];\n\n    @Override\n    public boolean beginSOS() {\n        return true;\n    }\n\n    @Override\n    public void visitSOS(final int marker, final byte[] markerBytes, final byte[] imageData) {\n        final ByteArrayInputStream is = new ByteArrayInputStream(imageData);\n        try {\n            final int segmentLength = read2Bytes(\"segmentLength\", is, \"Not a Valid JPEG File\", getByteOrder());\n            final byte[] sosSegmentBytes = readBytes(\"SosSegment\",\n                    is, segmentLength - 2, \"Not a Valid JPEG File\");\n            sosSegment = new SosSegment(marker, sosSegmentBytes);\n\n            int hMax = 0;\n            int vMax = 0;\n            for (int i = 0; i < sofnSegment.numberOfComponents; i++) {\n                hMax = Math.max(hMax,\n                        sofnSegment.getComponents(i).horizontalSamplingFactor);\n                vMax = Math.max(vMax,\n                        sofnSegment.getComponents(i).verticalSamplingFactor);\n            }\n            final int hSize = 8 * hMax;\n            final int vSize = 8 * vMax;\n\n            final JpegInputStream bitInputStream = new JpegInputStream(is);\n            final int xMCUs = (sofnSegment.width + hSize - 1) / hSize;\n            final int yMCUs = (sofnSegment.height + vSize - 1) / vSize;\n            final Block[] mcu = allocateMCUMemory();\n            final Block[] scaledMCU = new Block[mcu.length];\n            for (int i = 0; i < scaledMCU.length; i++) {\n                scaledMCU[i] = new Block(hSize, vSize);\n            }\n            final int[] preds = new int[sofnSegment.numberOfComponents];\n            ColorModel colorModel;\n            WritableRaster raster;\n            if (sofnSegment.numberOfComponents == 3) {\n                colorModel = new DirectColorModel(24, 0x00ff0000, 0x0000ff00,\n                        0x000000ff);\n                raster = Raster.createPackedRaster(DataBuffer.TYPE_INT,\n                        sofnSegment.width, sofnSegment.height, new int[] {\n                                0x00ff0000, 0x0000ff00, 0x000000ff }, null);\n            } else if (sofnSegment.numberOfComponents == 1) {\n                colorModel = new DirectColorModel(24, 0x00ff0000, 0x0000ff00,\n                        0x000000ff);\n                raster = Raster.createPackedRaster(DataBuffer.TYPE_INT,\n                        sofnSegment.width, sofnSegment.height, new int[] {\n                                0x00ff0000, 0x0000ff00, 0x000000ff }, null);\n                // FIXME: why do images come out too bright with CS_GRAY?\n                // colorModel = new ComponentColorModel(\n                // ColorSpace.getInstance(ColorSpace.CS_GRAY), false, true,\n                // Transparency.OPAQUE, DataBuffer.TYPE_BYTE);\n                // raster = colorModel.createCompatibleWritableRaster(\n                // sofnSegment.width, sofnSegment.height);\n            } else {\n                throw new ImageReadException(sofnSegment.numberOfComponents\n                        + \" components are invalid or unsupported\");\n            }\n            final DataBuffer dataBuffer = raster.getDataBuffer();\n\n            for (int y1 = 0; y1 < vSize * yMCUs; y1 += vSize) {\n                for (int x1 = 0; x1 < hSize * xMCUs; x1 += hSize) {\n                    readMCU(bitInputStream, preds, mcu);\n                    rescaleMCU(mcu, hSize, vSize, scaledMCU);\n                    int srcRowOffset = 0;\n                    int dstRowOffset = y1 * sofnSegment.width + x1;\n                    for (int y2 = 0; y2 < vSize && y1 + y2 < sofnSegment.height; y2++) {\n                        for (int x2 = 0; x2 < hSize\n                                && x1 + x2 < sofnSegment.width; x2++) {\n                            if (scaledMCU.length == 3) {\n                                final int Y = scaledMCU[0].samples[srcRowOffset + x2];\n                                final int Cb = scaledMCU[1].samples[srcRowOffset + x2];\n                                final int Cr = scaledMCU[2].samples[srcRowOffset + x2];\n                                final int rgb = YCbCrConverter.convertYCbCrToRGB(Y,\n                                        Cb, Cr);\n                                dataBuffer.setElem(dstRowOffset + x2, rgb);\n                            } else if (mcu.length == 1) {\n                                final int Y = scaledMCU[0].samples[srcRowOffset + x2];\n                                dataBuffer.setElem(dstRowOffset + x2, (Y << 16)\n                                        | (Y << 8) | Y);\n                            } else {\n                                throw new ImageReadException(\n                                        \"Unsupported JPEG with \" + mcu.length\n                                                + \" components\");\n                            }\n                        }\n                        srcRowOffset += hSize;\n                        dstRowOffset += sofnSegment.width;\n                    }\n                }\n            }\n            image = new BufferedImage(colorModel, raster,\n                    colorModel.isAlphaPremultiplied(), new Properties());\n            // byte[] remainder = super.getStreamBytes(is);\n            // for (int i = 0; i < remainder.length; i++)\n            // {\n            // System.out.println(\"\" + i + \" = \" +\n            // Integer.toHexString(remainder[i]));\n            // }\n        } catch (final ImageReadException imageReadEx) {\n            imageReadException = imageReadEx;\n        } catch (final IOException ioEx) {\n            ioException = ioEx;\n        } catch (final RuntimeException ex) {\n            // Corrupt images can throw NPE and IOOBE\n            imageReadException = new ImageReadException(\"Error parsing JPEG\",\n                    ex);\n        }\n    }\n\n    @Override\n    public boolean visitSegment(final int marker, final byte[] markerBytes,\n            final int segmentLength, final byte[] segmentLengthBytes, final byte[] segmentData)\n            throws ImageReadException, IOException {\n        final int[] sofnSegments = {\n                JpegConstants.SOF0_MARKER,\n                JpegConstants.SOF1_MARKER,\n                JpegConstants.SOF2_MARKER,\n                JpegConstants.SOF3_MARKER,\n                JpegConstants.SOF5_MARKER,\n                JpegConstants.SOF6_MARKER,\n                JpegConstants.SOF7_MARKER,\n                JpegConstants.SOF9_MARKER,\n                JpegConstants.SOF10_MARKER,\n                JpegConstants.SOF11_MARKER,\n                JpegConstants.SOF13_MARKER,\n                JpegConstants.SOF14_MARKER,\n                JpegConstants.SOF15_MARKER,\n        };\n\n        if (Arrays.binarySearch(sofnSegments, marker) >= 0) {\n            if (marker != JpegConstants.SOF0_MARKER) {\n                throw new ImageReadException(\"Only sequential, baseline JPEGs \"\n                        + \"are supported at the moment\");\n            }\n            sofnSegment = new SofnSegment(marker, segmentData);\n        } else if (marker == JpegConstants.DQT_MARKER) {\n            final DqtSegment dqtSegment = new DqtSegment(marker, segmentData);\n            for (int i = 0; i < dqtSegment.quantizationTables.size(); i++) {\n                final DqtSegment.QuantizationTable table = dqtSegment.quantizationTables.get(i);\n                if (0 > table.destinationIdentifier\n                        || table.destinationIdentifier >= quantizationTables.length) {\n                    throw new ImageReadException(\n                            \"Invalid quantization table identifier \"\n                                    + table.destinationIdentifier);\n                }\n                quantizationTables[table.destinationIdentifier] = table;\n                final int[] quantizationMatrixInt = new int[64];\n                ZigZag.zigZagToBlock(table.getElements(), quantizationMatrixInt);\n                final float[] quantizationMatrixFloat = new float[64];\n                for (int j = 0; j < 64; j++) {\n                    quantizationMatrixFloat[j] = quantizationMatrixInt[j];\n                }\n                Dct.scaleDequantizationMatrix(quantizationMatrixFloat);\n                scaledQuantizationTables[table.destinationIdentifier] = quantizationMatrixFloat;\n            }\n        } else if (marker == JpegConstants.DHT_MARKER) {\n            final DhtSegment dhtSegment = new DhtSegment(marker, segmentData);\n            for (int i = 0; i < dhtSegment.huffmanTables.size(); i++) {\n                final DhtSegment.HuffmanTable table = dhtSegment.huffmanTables.get(i);\n                DhtSegment.HuffmanTable[] tables;\n                if (table.tableClass == 0) {\n                    tables = huffmanDCTables;\n                } else if (table.tableClass == 1) {\n                    tables = huffmanACTables;\n                } else {\n                    throw new ImageReadException(\"Invalid huffman table class \"\n                            + table.tableClass);\n                }\n                if (0 > table.destinationIdentifier\n                        || table.destinationIdentifier >= tables.length) {\n                    throw new ImageReadException(\n                            \"Invalid huffman table identifier \"\n                                    + table.destinationIdentifier);\n                }\n                tables[table.destinationIdentifier] = table;\n            }\n        }\n        return true;\n    }\n\n    private void rescaleMCU(final Block[] dataUnits, final int hSize, final int vSize, final Block[] ret) {\n        for (int i = 0; i < dataUnits.length; i++) {\n            final Block dataUnit = dataUnits[i];\n            if (dataUnit.width == hSize && dataUnit.height == vSize) {\n                System.arraycopy(dataUnit.samples, 0, ret[i].samples, 0, hSize\n                        * vSize);\n            } else {\n                final int hScale = hSize / dataUnit.width;\n                final int vScale = vSize / dataUnit.height;\n                if (hScale == 2 && vScale == 2) {\n                    int srcRowOffset = 0;\n                    int dstRowOffset = 0;\n                    for (int y = 0; y < dataUnit.height; y++) {\n                        for (int x = 0; x < hSize; x++) {\n                            final int sample = dataUnit.samples[srcRowOffset + (x >> 1)];\n                            ret[i].samples[dstRowOffset + x] = sample;\n                            ret[i].samples[dstRowOffset + hSize + x] = sample;\n                        }\n                        srcRowOffset += dataUnit.width;\n                        dstRowOffset += 2 * hSize;\n                    }\n                } else {\n                    // FIXME: optimize\n                    int dstRowOffset = 0;\n                    for (int y = 0; y < vSize; y++) {\n                        for (int x = 0; x < hSize; x++) {\n                            ret[i].samples[dstRowOffset + x] = dataUnit.samples[(y / vScale)\n                                    * dataUnit.width + (x / hScale)];\n                        }\n                        dstRowOffset += hSize;\n                    }\n                }\n            }\n        }\n    }\n\n    private Block[] allocateMCUMemory() throws ImageReadException {\n        final Block[] mcu = new Block[sosSegment.numberOfComponents];\n        for (int i = 0; i < sosSegment.numberOfComponents; i++) {\n            final SosSegment.Component scanComponent = sosSegment.getComponents(i);\n            SofnSegment.Component frameComponent = null;\n            for (int j = 0; j < sofnSegment.numberOfComponents; j++) {\n                if (sofnSegment.getComponents(j).componentIdentifier == scanComponent.scanComponentSelector) {\n                    frameComponent = sofnSegment.getComponents(j);\n                    break;\n                }\n            }\n            if (frameComponent == null) {\n                throw new ImageReadException(\"Invalid component\");\n            }\n            final Block fullBlock = new Block(\n                    8 * frameComponent.horizontalSamplingFactor,\n                    8 * frameComponent.verticalSamplingFactor);\n            mcu[i] = fullBlock;\n        }\n        return mcu;\n    }\n\n    private void readMCU(final JpegInputStream is, final int[] preds, final Block[] mcu)\n            throws IOException, ImageReadException {\n        for (int i = 0; i < sosSegment.numberOfComponents; i++) {\n            final SosSegment.Component scanComponent = sosSegment.getComponents(i);\n            SofnSegment.Component frameComponent = null;\n            for (int j = 0; j < sofnSegment.numberOfComponents; j++) {\n                if (sofnSegment.getComponents(j).componentIdentifier == scanComponent.scanComponentSelector) {\n                    frameComponent = sofnSegment.getComponents(j);\n                    break;\n                }\n            }\n            if (frameComponent == null) {\n                throw new ImageReadException(\"Invalid component\");\n            }\n            final Block fullBlock = mcu[i];\n            for (int y = 0; y < frameComponent.verticalSamplingFactor; y++) {\n                for (int x = 0; x < frameComponent.horizontalSamplingFactor; x++) {\n                    Arrays.fill(zz, 0);\n                    // page 104 of T.81\n                    final int t = decode(\n                            is,\n                            huffmanDCTables[scanComponent.dcCodingTableSelector]);\n                    int diff = receive(t, is);\n                    diff = extend(diff, t);\n                    zz[0] = preds[i] + diff;\n                    preds[i] = zz[0];\n\n                    // \"Decode_AC_coefficients\", figure F.13, page 106 of T.81\n                    int k = 1;\n                    while (true) {\n                        final int rs = decode(\n                                is,\n                                huffmanACTables[scanComponent.acCodingTableSelector]);\n                        final int ssss = rs & 0xf;\n                        final int rrrr = rs >> 4;\n                        final int r = rrrr;\n\n                        if (ssss == 0) {\n                            if (r == 15) {\n                                k += 16;\n                            } else {\n                                break;\n                            }\n                        } else {\n                            k += r;\n\n                            // \"Decode_ZZ(k)\", figure F.14, page 107 of T.81\n                            zz[k] = receive(ssss, is);\n                            zz[k] = extend(zz[k], ssss);\n\n                            if (k == 63) {\n                                break;\n                            } else {\n                                k++;\n                            }\n                        }\n                    }\n\n                    final int shift = (1 << (sofnSegment.precision - 1));\n                    final int max = (1 << sofnSegment.precision) - 1;\n\n                    final float[] scaledQuantizationTable = scaledQuantizationTables[frameComponent.quantTabDestSelector];\n                    ZigZag.zigZagToBlock(zz, blockInt);\n                    for (int j = 0; j < 64; j++) {\n                        block[j] = blockInt[j] * scaledQuantizationTable[j];\n                    }\n                    Dct.inverseDCT8x8(block);\n\n                    int dstRowOffset = 8 * y * 8\n                            * frameComponent.horizontalSamplingFactor + 8 * x;\n                    int srcNext = 0;\n                    for (int yy = 0; yy < 8; yy++) {\n                        for (int xx = 0; xx < 8; xx++) {\n                            float sample = block[srcNext++];\n                            sample += shift;\n                            int result;\n                            if (sample < 0) {\n                                result = 0;\n                            } else if (sample > max) {\n                                result = max;\n                            } else {\n                                result = fastRound(sample);\n                            }\n                            fullBlock.samples[dstRowOffset + xx] = result;\n                        }\n                        dstRowOffset += 8 * frameComponent.horizontalSamplingFactor;\n                    }\n                }\n            }\n        }\n    }\n\n    private static int fastRound(final float x) {\n        return (int) (x + 0.5f);\n    }\n\n    private int extend(int v, final int t) {\n        // \"EXTEND\", section F.2.2.1, figure F.12, page 105 of T.81\n        int vt = (1 << (t - 1));\n        if (v < vt) {\n            vt = (-1 << t) + 1;\n            v += vt;\n        }\n        return v;\n    }\n\n    private int receive(final int ssss, final JpegInputStream is) throws IOException,\n            ImageReadException {\n        // \"RECEIVE\", section F.2.2.4, figure F.17, page 110 of T.81\n        int i = 0;\n        int v = 0;\n        while (i != ssss) {\n            i++;\n            v = (v << 1) + is.nextBit();\n        }\n        return v;\n    }\n\n    private int decode(final JpegInputStream is, final DhtSegment.HuffmanTable huffmanTable)\n            throws IOException, ImageReadException {\n        // \"DECODE\", section F.2.2.3, figure F.16, page 109 of T.81\n        int i = 1;\n        int code = is.nextBit();\n        while (code > huffmanTable.getMaxCode(i)) {\n            i++;\n            code = (code << 1) | is.nextBit();\n        }\n        int j = huffmanTable.getValPtr(i);\n        j += code - huffmanTable.getMinCode(i);\n        return huffmanTable.getHuffVal(j);\n    }\n\n    public BufferedImage decode(final ByteSource byteSource) throws IOException,\n            ImageReadException {\n        final JpegUtils jpegUtils = new JpegUtils();\n        jpegUtils.traverseJFIF(byteSource, this);\n        if (imageReadException != null) {\n            throw imageReadException;\n        }\n        if (ioException != null) {\n            throw ioException;\n        }\n        return image;\n    }\n}",
    "target": 0,
    "language": "java",
    "dataset": "A-Manually-Curated-Dataset-of-Vulnerability-Introducing-Commits-in-Java",
    "idx": 800021,
    "RELATED_CWE": [
      "CWE-908",
      "CWE-362",
      "CWE-667"
    ]
  },
  {
    "CWE_ID": [
      "CWE-835"
    ],
    "code": "/*\n * Licensed to the Apache Software Foundation (ASF) under one\n * or more contributor license agreements.  See the NOTICE file\n * distributed with this work for additional information\n * regarding copyright ownership.  The ASF licenses this file\n * to you under the Apache License, Version 2.0 (the\n * \"License\"); you may not use this file except in compliance\n * with the License.  You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing,\n * software distributed under the License is distributed on an\n * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n * KIND, either express or implied.  See the License for the\n * specific language governing permissions and limitations\n * under the License.\n */\npackage org.apache.commons.compress.archivers.zip;\n\nimport java.io.ByteArrayInputStream;\nimport java.io.ByteArrayOutputStream;\nimport java.io.EOFException;\nimport java.io.IOException;\nimport java.io.InputStream;\nimport java.io.PushbackInputStream;\nimport java.nio.ByteBuffer;\nimport java.util.zip.CRC32;\nimport java.util.zip.DataFormatException;\nimport java.util.zip.Inflater;\nimport java.util.zip.ZipEntry;\nimport java.util.zip.ZipException;\n\nimport org.apache.commons.compress.archivers.ArchiveEntry;\nimport org.apache.commons.compress.archivers.ArchiveInputStream;\nimport org.apache.commons.compress.utils.IOUtils;\n\nimport static org.apache.commons.compress.archivers.zip.ZipConstants.DWORD;\nimport static org.apache.commons.compress.archivers.zip.ZipConstants.SHORT;\nimport static org.apache.commons.compress.archivers.zip.ZipConstants.WORD;\nimport static org.apache.commons.compress.archivers.zip.ZipConstants.ZIP64_MAGIC;\n\n/**\n * Implements an input stream that can read Zip archives.\n *\n * <p>Note that {@link ZipArchiveEntry#getSize()} may return -1 if the\n * DEFLATE algorithm is used, as the size information is not available\n * from the header.</p>\n *\n * <p>The {@link ZipFile} class is preferred when reading from files.</p>\n *\n * <p>As of Apache Commons Compress it transparently supports Zip64\n * extensions and thus individual entries and archives larger than 4\n * GB or with more than 65536 entries.</p>\n *\n * @see ZipFile\n * @NotThreadSafe\n */\npublic class ZipArchiveInputStream extends ArchiveInputStream {\n\n    /**\n     * The zip encoding to use for filenames and the file comment.\n     */\n    private final ZipEncoding zipEncoding;\n\n    /**\n     * Whether to look for and use Unicode extra fields.\n     */\n    private final boolean useUnicodeExtraFields;\n\n    /**\n     * Wrapped stream, will always be a PushbackInputStream.\n     */\n    private final InputStream in;\n\n    /**\n     * Inflater used for all deflated entries.\n     */\n    private final Inflater inf = new Inflater(true);\n\n    /**\n     * Calculates checkusms for all entries.\n     */\n    private final CRC32 crc = new CRC32();\n\n    /**\n     * Buffer used to read from the wrapped stream.\n     */\n    private final ByteBuffer buf = ByteBuffer.allocate(ZipArchiveOutputStream.BUFFER_SIZE);\n    /**\n     * The entry that is currently being read.\n     */\n    private CurrentEntry current = null;\n    /**\n     * Whether the stream has been closed.\n     */\n    private boolean closed = false;\n    /**\n     * Whether the stream has reached the central directory - and thus\n     * found all entries.\n     */\n    private boolean hitCentralDirectory = false;\n    /**\n     * When reading a stored entry that uses the data descriptor this\n     * stream has to read the full entry and caches it.  This is the\n     * cache.\n     */\n    private ByteArrayInputStream lastStoredEntry = null;\n\n    /**\n     * Whether the stream will try to read STORED entries that use a\n     * data descriptor.\n     */\n    private boolean allowStoredEntriesWithDataDescriptor = false;\n\n    private static final int LFH_LEN = 30;\n    /*\n      local file header signature     WORD\n      version needed to extract       SHORT\n      general purpose bit flag        SHORT\n      compression method              SHORT\n      last mod file time              SHORT\n      last mod file date              SHORT\n      crc-32                          WORD\n      compressed size                 WORD\n      uncompressed size               WORD\n      file name length                SHORT\n      extra field length              SHORT\n    */\n\n    private static final int CFH_LEN = 46;\n    /*\n        central file header signature   WORD\n        version made by                 SHORT\n        version needed to extract       SHORT\n        general purpose bit flag        SHORT\n        compression method              SHORT\n        last mod file time              SHORT\n        last mod file date              SHORT\n        crc-32                          WORD\n        compressed size                 WORD\n        uncompressed size               WORD\n        file name length                SHORT\n        extra field length              SHORT\n        file comment length             SHORT\n        disk number start               SHORT\n        internal file attributes        SHORT\n        external file attributes        WORD\n        relative offset of local header WORD\n    */\n\n    private static final long TWO_EXP_32 = ZIP64_MAGIC + 1;\n\n    // cached buffers - must only be used locally in the class (COMPRESS-172 - reduce garbage collection)\n    private final byte[] LFH_BUF = new byte[LFH_LEN];\n    private final byte[] SKIP_BUF = new byte[1024];\n    private final byte[] SHORT_BUF = new byte[SHORT];\n    private final byte[] WORD_BUF = new byte[WORD];\n    private final byte[] TWO_DWORD_BUF = new byte[2 * DWORD];\n\n    private int entriesRead = 0;\n\n    public ZipArchiveInputStream(InputStream inputStream) {\n        this(inputStream, ZipEncodingHelper.UTF8);\n    }\n\n    /**\n     * @param encoding the encoding to use for file names, use null\n     * for the platform's default encoding\n     * @since 1.5\n     */\n    public ZipArchiveInputStream(InputStream inputStream, String encoding) {\n        this(inputStream, encoding, true);\n    }\n\n    /**\n     * @param encoding the encoding to use for file names, use null\n     * for the platform's default encoding\n     * @param useUnicodeExtraFields whether to use InfoZIP Unicode\n     * Extra Fields (if present) to set the file names.\n     */\n    public ZipArchiveInputStream(InputStream inputStream,\n                                 String encoding,\n                                 boolean useUnicodeExtraFields) {\n        this(inputStream, encoding, useUnicodeExtraFields, false);\n    }\n\n    /**\n     * @param encoding the encoding to use for file names, use null\n     * for the platform's default encoding\n     * @param useUnicodeExtraFields whether to use InfoZIP Unicode\n     * Extra Fields (if present) to set the file names.\n     * @param allowStoredEntriesWithDataDescriptor whether the stream\n     * will try to read STORED entries that use a data descriptor\n     * @since 1.1\n     */\n    public ZipArchiveInputStream(InputStream inputStream,\n                                 String encoding,\n                                 boolean useUnicodeExtraFields,\n                                 boolean allowStoredEntriesWithDataDescriptor) {\n        zipEncoding = ZipEncodingHelper.getZipEncoding(encoding);\n        this.useUnicodeExtraFields = useUnicodeExtraFields;\n        in = new PushbackInputStream(inputStream, buf.capacity());\n        this.allowStoredEntriesWithDataDescriptor =\n            allowStoredEntriesWithDataDescriptor;\n    }\n\n    public ZipArchiveEntry getNextZipEntry() throws IOException {\n        boolean firstEntry = true;\n        if (closed || hitCentralDirectory) {\n            return null;\n        }\n        if (current != null) {\n            closeEntry();\n            firstEntry = false;\n        }\n\n        try {\n            if (firstEntry) {\n                // split archives have a special signature before the\n                // first local file header - look for it and fail with\n                // the appropriate error message if this is a split\n                // archive.\n                readFirstLocalFileHeader(LFH_BUF);\n            } else {\n                readFully(LFH_BUF);\n            }\n        } catch (EOFException e) {\n            return null;\n        }\n\n        ZipLong sig = new ZipLong(LFH_BUF);\n        if (sig.equals(ZipLong.CFH_SIG) || sig.equals(ZipLong.AED_SIG)) {\n            hitCentralDirectory = true;\n            skipRemainderOfArchive();\n        }\n        if (!sig.equals(ZipLong.LFH_SIG)) {\n            return null;\n        }\n\n        int off = WORD;\n        current = new CurrentEntry();\n\n        int versionMadeBy = ZipShort.getValue(LFH_BUF, off);\n        off += SHORT;\n        current.entry.setPlatform((versionMadeBy >> ZipFile.BYTE_SHIFT)\n                                  & ZipFile.NIBLET_MASK);\n\n        final GeneralPurposeBit gpFlag = GeneralPurposeBit.parse(LFH_BUF, off);\n        final boolean hasUTF8Flag = gpFlag.usesUTF8ForNames();\n        final ZipEncoding entryEncoding =\n            hasUTF8Flag ? ZipEncodingHelper.UTF8_ZIP_ENCODING : zipEncoding;\n        current.hasDataDescriptor = gpFlag.usesDataDescriptor();\n        current.entry.setGeneralPurposeBit(gpFlag);\n\n        off += SHORT;\n\n        current.entry.setMethod(ZipShort.getValue(LFH_BUF, off));\n        off += SHORT;\n\n        long time = ZipUtil.dosToJavaTime(ZipLong.getValue(LFH_BUF, off));\n        current.entry.setTime(time);\n        off += WORD;\n\n        ZipLong size = null, cSize = null;\n        if (!current.hasDataDescriptor) {\n            current.entry.setCrc(ZipLong.getValue(LFH_BUF, off));\n            off += WORD;\n\n            cSize = new ZipLong(LFH_BUF, off);\n            off += WORD;\n\n            size = new ZipLong(LFH_BUF, off);\n            off += WORD;\n        } else {\n            off += 3 * WORD;\n        }\n\n        int fileNameLen = ZipShort.getValue(LFH_BUF, off);\n\n        off += SHORT;\n\n        int extraLen = ZipShort.getValue(LFH_BUF, off);\n        off += SHORT;\n\n        byte[] fileName = new byte[fileNameLen];\n        readFully(fileName);\n        current.entry.setName(entryEncoding.decode(fileName), fileName);\n\n        byte[] extraData = new byte[extraLen];\n        readFully(extraData);\n        current.entry.setExtra(extraData);\n\n        if (!hasUTF8Flag && useUnicodeExtraFields) {\n            ZipUtil.setNameAndCommentFromExtraFields(current.entry, fileName,\n                                                     null);\n        }\n\n        processZip64Extra(size, cSize);\n        entriesRead++;\n        return current.entry;\n    }\n\n    /**\n     * Fills the given array with the first local file header and\n     * deals with splitting/spanning markers that may prefix the first\n     * LFH.\n     */\n    private void readFirstLocalFileHeader(byte[] lfh) throws IOException {\n        readFully(lfh);\n        ZipLong sig = new ZipLong(lfh);\n        if (sig.equals(ZipLong.DD_SIG)) {\n            throw new\n                UnsupportedZipFeatureException(UnsupportedZipFeatureException\n                                               .Feature.SPLITTING);\n        }\n        if (sig.equals(ZipLong.SINGLE_SEGMENT_SPLIT_MARKER)) {\n            // The archive is not really split as only one segment was\n            // needed in the end.  Just skip over the marker.\n            byte[] missedLfhBytes = new byte[4];\n            readFully(missedLfhBytes);\n            System.arraycopy(lfh, 4, lfh, 0, LFH_LEN - 4);\n            System.arraycopy(missedLfhBytes, 0, lfh, LFH_LEN - 4, 4);\n        }\n    }\n\n    /**\n     * Records whether a Zip64 extra is present and sets the size\n     * information from it if sizes are 0xFFFFFFFF and the entry\n     * doesn't use a data descriptor.\n     */\n    private void processZip64Extra(ZipLong size, ZipLong cSize) {\n        Zip64ExtendedInformationExtraField z64 =\n            (Zip64ExtendedInformationExtraField)\n            current.entry.getExtraField(Zip64ExtendedInformationExtraField\n                                        .HEADER_ID);\n        current.usesZip64 = z64 != null;\n        if (!current.hasDataDescriptor) {\n            if (z64 != null // same as current.usesZip64 but avoids NPE warning\n                    && (cSize.equals(ZipLong.ZIP64_MAGIC)\n                                      || size.equals(ZipLong.ZIP64_MAGIC))\n                ) {\n                current.entry.setCompressedSize(z64.getCompressedSize()\n                                                .getLongValue());\n                current.entry.setSize(z64.getSize().getLongValue());\n            } else {\n                current.entry.setCompressedSize(cSize.getValue());\n                current.entry.setSize(size.getValue());\n            }\n        }\n    }\n\n    @Override\n    public ArchiveEntry getNextEntry() throws IOException {\n        return getNextZipEntry();\n    }\n\n    /**\n     * Whether this class is able to read the given entry.\n     *\n     * <p>May return false if it is set up to use encryption or a\n     * compression method that hasn't been implemented yet.</p>\n     * @since 1.1\n     */\n    @Override\n    public boolean canReadEntryData(ArchiveEntry ae) {\n        if (ae instanceof ZipArchiveEntry) {\n            ZipArchiveEntry ze = (ZipArchiveEntry) ae;\n            return ZipUtil.canHandleEntryData(ze)\n                && ze.getMethod() != ZipMethod.UNSHRINKING.getCode()\n                && supportsDataDescriptorFor(ze);\n\n        }\n        return false;\n    }\n\n    @Override\n    public int read(byte[] buffer, int start, int length) throws IOException {\n        if (closed) {\n            throw new IOException(\"The stream is closed\");\n        }\n        if (inf.finished() || current == null) {\n            return -1;\n        }\n\n        // avoid int overflow, check null buffer\n        if (start <= buffer.length && length >= 0 && start >= 0\n            && buffer.length - start >= length) {\n            ZipUtil.checkRequestedFeatures(current.entry);\n            if (!supportsDataDescriptorFor(current.entry)) {\n                throw new UnsupportedZipFeatureException(UnsupportedZipFeatureException\n                                                         .Feature\n                                                         .DATA_DESCRIPTOR,\n                                                         current.entry);\n            }\n\n            if (current.entry.getMethod() == ZipArchiveOutputStream.STORED) {\n                return readStored(buffer, start, length);\n            }\n            if (current.entry.getMethod() == ZipMethod.UNSHRINKING.getCode()) {\n                throw new UnsupportedZipFeatureException(ZipMethod.UNSHRINKING,\n                                                         current.entry);\n            }\n            return readDeflated(buffer, start, length);\n        }\n        throw new ArrayIndexOutOfBoundsException();\n    }\n\n    /**\n     * Implementation of read for STORED entries.\n     */\n    private int readStored(byte[] buffer, int start, int length)\n        throws IOException {\n\n        if (current.hasDataDescriptor) {\n            if (lastStoredEntry == null) {\n                readStoredEntry();\n            }\n            return lastStoredEntry.read(buffer, start, length);\n        }\n\n        long csize = current.entry.getSize();\n        if (current.bytesRead >= csize) {\n            return -1;\n        }\n\n        if (buf.position() >= buf.limit()) {\n            buf.position(0);\n            int l = in.read(buf.array());\n            if (l == -1) {\n                return -1;\n            }\n            buf.limit(l);\n\n            count(buf.limit());\n            current.bytesReadFromStream += buf.limit();\n        }\n\n        int toRead = Math.min(buf.remaining(), length);\n        if ((csize - current.bytesRead) < toRead) {\n            // if it is smaller than toRead then it fits into an int\n            toRead = (int) (csize - current.bytesRead);\n        }\n        buf.get(buffer, start, toRead);\n        current.bytesRead += toRead;\n        crc.update(buffer, start, toRead);\n        return toRead;\n    }\n\n    /**\n     * Implementation of read for DEFLATED entries.\n     */\n    private int readDeflated(byte[] buffer, int start, int length)\n        throws IOException {\n        int read = readFromInflater(buffer, start, length);\n        if (read <= 0) {\n            if (inf.finished()) {\n                return -1;\n            } else if (inf.needsDictionary()) {\n                throw new ZipException(\"This archive needs a preset dictionary\"\n                                       + \" which is not supported by Commons\"\n                                       + \" Compress.\");\n            } else if (read == -1) {\n                throw new IOException(\"Truncated ZIP file\");\n            }\n        }\n        crc.update(buffer, start, read);\n        return read;\n    }\n\n    /**\n     * Potentially reads more bytes to fill the inflater's buffer and\n     * reads from it.\n     */\n    private int readFromInflater(byte[] buffer, int start, int length)\n        throws IOException {\n        int read = 0;\n        do {\n            if (inf.needsInput()) {\n                int l = fill();\n                if (l > 0) {\n                    current.bytesReadFromStream += buf.limit();\n                } else if (l == -1) {\n                    return -1;\n                } else {\n                    break;\n                }\n            }\n            try {\n                read = inf.inflate(buffer, start, length);\n            } catch (DataFormatException e) {\n                throw new ZipException(e.getMessage());\n            }\n        } while (read == 0 && inf.needsInput());\n        return read;\n    }\n\n    @Override\n    public void close() throws IOException {\n        if (!closed) {\n            closed = true;\n            in.close();\n            inf.end();\n        }\n    }\n\n    /**\n     * Skips over and discards value bytes of data from this input\n     * stream.\n     *\n     * <p>This implementation may end up skipping over some smaller\n     * number of bytes, possibly 0, if and only if it reaches the end\n     * of the underlying stream.</p>\n     *\n     * <p>The actual number of bytes skipped is returned.</p>\n     *\n     * @param value the number of bytes to be skipped.\n     * @return the actual number of bytes skipped.\n     * @throws IOException - if an I/O error occurs.\n     * @throws IllegalArgumentException - if value is negative.\n     */\n    @Override\n    public long skip(long value) throws IOException {\n        if (value >= 0) {\n            long skipped = 0;\n            while (skipped < value) {\n                long rem = value - skipped;\n                int x = read(SKIP_BUF, 0,\n                             (int) (SKIP_BUF.length > rem ? rem\n                                    : SKIP_BUF.length));\n                if (x == -1) {\n                    return skipped;\n                }\n                skipped += x;\n            }\n            return skipped;\n        }\n        throw new IllegalArgumentException();\n    }\n\n    /**\n     * Checks if the signature matches what is expected for a zip file.\n     * Does not currently handle self-extracting zips which may have arbitrary\n     * leading content.\n     *\n     * @param signature\n     *            the bytes to check\n     * @param length\n     *            the number of bytes to check\n     * @return true, if this stream is a zip archive stream, false otherwise\n     */\n    public static boolean matches(byte[] signature, int length) {\n        if (length < ZipArchiveOutputStream.LFH_SIG.length) {\n            return false;\n        }\n\n        return checksig(signature, ZipArchiveOutputStream.LFH_SIG) // normal file\n            || checksig(signature, ZipArchiveOutputStream.EOCD_SIG) // empty zip\n            || checksig(signature, ZipArchiveOutputStream.DD_SIG) // split zip\n            || checksig(signature,\n                        ZipLong.SINGLE_SEGMENT_SPLIT_MARKER.getBytes());\n    }\n\n    private static boolean checksig(byte[] signature, byte[] expected){\n        for (int i = 0; i < expected.length; i++) {\n            if (signature[i] != expected[i]) {\n                return false;\n            }\n        }\n        return true;\n    }\n\n    /**\n     * Closes the current ZIP archive entry and positions the underlying\n     * stream to the beginning of the next entry. All per-entry variables\n     * and data structures are cleared.\n     * <p>\n     * If the compressed size of this entry is included in the entry header,\n     * then any outstanding bytes are simply skipped from the underlying\n     * stream without uncompressing them. This allows an entry to be safely\n     * closed even if the compression method is unsupported.\n     * <p>\n     * In case we don't know the compressed size of this entry or have\n     * already buffered too much data from the underlying stream to support\n     * uncompression, then the uncompression process is completed and the\n     * end position of the stream is adjusted based on the result of that\n     * process.\n     *\n     * @throws IOException if an error occurs\n     */\n    private void closeEntry() throws IOException {\n        if (closed) {\n            throw new IOException(\"The stream is closed\");\n        }\n        if (current == null) {\n            return;\n        }\n\n        // Ensure all entry bytes are read\n        if (current.bytesReadFromStream <= current.entry.getCompressedSize()\n            && !current.hasDataDescriptor) {\n            drainCurrentEntryData();\n        } else {\n            skip(Long.MAX_VALUE);\n\n            long inB =\n                current.entry.getMethod() == ZipArchiveOutputStream.DEFLATED\n                ? getBytesInflated() : current.bytesRead;\n\n            // this is at most a single read() operation and can't\n            // exceed the range of int\n            int diff = (int) (current.bytesReadFromStream - inB);\n\n            // Pushback any required bytes\n            if (diff > 0) {\n                pushback(buf.array(), buf.limit() - diff, diff);\n            }\n        }\n\n        if (lastStoredEntry == null && current.hasDataDescriptor) {\n            readDataDescriptor();\n        }\n\n        inf.reset();\n        buf.clear().flip();\n        crc.reset();\n        current = null;\n        lastStoredEntry = null;\n    }\n\n    /**\n     * Read all data of the current entry from the underlying stream\n     * that hasn't been read, yet.\n     */\n    private void drainCurrentEntryData() throws IOException {\n        long remaining = current.entry.getCompressedSize()\n            - current.bytesReadFromStream;\n        while (remaining > 0) {\n            long n = in.read(buf.array(), 0, (int) Math.min(buf.capacity(), remaining));\n            if (n < 0) {\n                throw new EOFException(\n                                       \"Truncated ZIP entry: \" + current.entry.getName());\n            } else {\n                count(n);\n                remaining -= n;\n            }\n        }\n    }\n\n    /**\n     * Get the number of bytes Inflater has actually processed.\n     *\n     * <p>for Java &lt; Java7 the getBytes* methods in\n     * Inflater/Deflater seem to return unsigned ints rather than\n     * longs that start over with 0 at 2^32.</p>\n     *\n     * <p>The stream knows how many bytes it has read, but not how\n     * many the Inflater actually consumed - it should be between the\n     * total number of bytes read for the entry and the total number\n     * minus the last read operation.  Here we just try to make the\n     * value close enough to the bytes we've read by assuming the\n     * number of bytes consumed must be smaller than (or equal to) the\n     * number of bytes read but not smaller by more than 2^32.</p>\n     */\n    private long getBytesInflated() {\n        long inB = inf.getBytesRead();\n        if (current.bytesReadFromStream >= TWO_EXP_32) {\n            while (inB + TWO_EXP_32 <= current.bytesReadFromStream) {\n                inB += TWO_EXP_32;\n            }\n        }\n        return inB;\n    }\n\n    private int fill() throws IOException {\n        if (closed) {\n            throw new IOException(\"The stream is closed\");\n        }\n        int length = in.read(buf.array());\n        if (length > 0) {\n            buf.limit(length);\n            count(buf.limit());\n            inf.setInput(buf.array(), 0, buf.limit());\n        }\n        return length;\n    }\n\n    private void readFully(byte[] b) throws IOException {\n        int count = IOUtils.readFully(in, b);\n        count(count);\n        if (count < b.length) {\n            throw new EOFException();\n        }\n    }\n\n    private void readDataDescriptor() throws IOException {\n        readFully(WORD_BUF);\n        ZipLong val = new ZipLong(WORD_BUF);\n        if (ZipLong.DD_SIG.equals(val)) {\n            // data descriptor with signature, skip sig\n            readFully(WORD_BUF);\n            val = new ZipLong(WORD_BUF);\n        }\n        current.entry.setCrc(val.getValue());\n\n        // if there is a ZIP64 extra field, sizes are eight bytes\n        // each, otherwise four bytes each.  Unfortunately some\n        // implementations - namely Java7 - use eight bytes without\n        // using a ZIP64 extra field -\n        // http://bugs.sun.com/bugdatabase/view_bug.do?bug_id=7073588\n\n        // just read 16 bytes and check whether bytes nine to twelve\n        // look like one of the signatures of what could follow a data\n        // descriptor (ignoring archive decryption headers for now).\n        // If so, push back eight bytes and assume sizes are four\n        // bytes, otherwise sizes are eight bytes each.\n        readFully(TWO_DWORD_BUF);\n        ZipLong potentialSig = new ZipLong(TWO_DWORD_BUF, DWORD);\n        if (potentialSig.equals(ZipLong.CFH_SIG)\n            || potentialSig.equals(ZipLong.LFH_SIG)) {\n            pushback(TWO_DWORD_BUF, DWORD, DWORD);\n            current.entry.setCompressedSize(ZipLong.getValue(TWO_DWORD_BUF));\n            current.entry.setSize(ZipLong.getValue(TWO_DWORD_BUF, WORD));\n        } else {\n            current.entry\n                .setCompressedSize(ZipEightByteInteger\n                                   .getLongValue(TWO_DWORD_BUF));\n            current.entry.setSize(ZipEightByteInteger\n                                  .getLongValue(TWO_DWORD_BUF, DWORD));\n        }\n    }\n\n    /**\n     * Whether this entry requires a data descriptor this library can work with.\n     *\n     * @return true if allowStoredEntriesWithDataDescriptor is true,\n     * the entry doesn't require any data descriptor or the method is\n     * DEFLATED.\n     */\n    private boolean supportsDataDescriptorFor(ZipArchiveEntry entry) {\n        return allowStoredEntriesWithDataDescriptor ||\n            !entry.getGeneralPurposeBit().usesDataDescriptor()\n            || entry.getMethod() == ZipEntry.DEFLATED;\n    }\n\n    /**\n     * Caches a stored entry that uses the data descriptor.\n     *\n     * <ul>\n     *   <li>Reads a stored entry until the signature of a local file\n     *     header, central directory header or data descriptor has been\n     *     found.</li>\n     *   <li>Stores all entry data in lastStoredEntry.</p>\n     *   <li>Rewinds the stream to position at the data\n     *     descriptor.</li>\n     *   <li>reads the data descriptor</li>\n     * </ul>\n     *\n     * <p>After calling this method the entry should know its size,\n     * the entry's data is cached and the stream is positioned at the\n     * next local file or central directory header.</p>\n     */\n    private void readStoredEntry() throws IOException {\n        ByteArrayOutputStream bos = new ByteArrayOutputStream();\n        int off = 0;\n        boolean done = false;\n\n        // length of DD without signature\n        int ddLen = current.usesZip64 ? WORD + 2 * DWORD : 3 * WORD;\n\n        while (!done) {\n            int r = in.read(buf.array(), off, ZipArchiveOutputStream.BUFFER_SIZE - off);\n            if (r <= 0) {\n                // read the whole archive without ever finding a\n                // central directory\n                throw new IOException(\"Truncated ZIP file\");\n            }\n            if (r + off < 4) {\n                // buffer too small to check for a signature, loop\n                off += r;\n                continue;\n            }\n\n            done = bufferContainsSignature(bos, off, r, ddLen);\n            if (!done) {\n                off = cacheBytesRead(bos, off, r, ddLen);\n            }\n        }\n\n        byte[] b = bos.toByteArray();\n        lastStoredEntry = new ByteArrayInputStream(b);\n    }\n\n    private static final byte[] LFH = ZipLong.LFH_SIG.getBytes();\n    private static final byte[] CFH = ZipLong.CFH_SIG.getBytes();\n    private static final byte[] DD = ZipLong.DD_SIG.getBytes();\n\n    /**\n     * Checks whether the current buffer contains the signature of a\n     * &quot;data decsriptor&quot;, &quot;local file header&quot; or\n     * &quot;central directory entry&quot;.\n     *\n     * <p>If it contains such a signature, reads the data descriptor\n     * and positions the stream right after the data descriptor.</p>\n     */\n    private boolean bufferContainsSignature(ByteArrayOutputStream bos,\n                                            int offset, int lastRead,\n                                            int expectedDDLen)\n        throws IOException {\n        boolean done = false;\n        int readTooMuch = 0;\n        for (int i = 0; !done && i < lastRead - 4; i++) {\n            if (buf.array()[i] == LFH[0] && buf.array()[i + 1] == LFH[1]) {\n                if ((buf.array()[i + 2] == LFH[2] && buf.array()[i + 3] == LFH[3])\n                    || (buf.array()[i] == CFH[2] && buf.array()[i + 3] == CFH[3])) {\n                    // found a LFH or CFH:\n                    readTooMuch = offset + lastRead - i - expectedDDLen;\n                    done = true;\n                }\n                else if (buf.array()[i + 2] == DD[2] && buf.array()[i + 3] == DD[3]) {\n                    // found DD:\n                    readTooMuch = offset + lastRead - i;\n                    done = true;\n                }\n                if (done) {\n                    // * push back bytes read in excess as well as the data\n                    //   descriptor\n                    // * copy the remaining bytes to cache\n                    // * read data descriptor\n                    pushback(buf.array(), offset + lastRead - readTooMuch, readTooMuch);\n                    bos.write(buf.array(), 0, i);\n                    readDataDescriptor();\n                }\n            }\n        }\n        return done;\n    }\n\n    /**\n     * If the last read bytes could hold a data descriptor and an\n     * incomplete signature then save the last bytes to the front of\n     * the buffer and cache everything in front of the potential data\n     * descriptor into the given ByteArrayOutputStream.\n     *\n     * <p>Data descriptor plus incomplete signature (3 bytes in the\n     * worst case) can be 20 bytes max.</p>\n     */\n    private int cacheBytesRead(ByteArrayOutputStream bos, int offset,\n                               int lastRead, int expecteDDLen) {\n        final int cacheable = offset + lastRead - expecteDDLen - 3;\n        if (cacheable > 0) {\n            bos.write(buf.array(), 0, cacheable);\n            System.arraycopy(buf.array(), cacheable, buf.array(), 0, expecteDDLen + 3);\n            offset = expecteDDLen + 3;\n        } else {\n            offset += lastRead;\n        }\n        return offset;\n    }\n\n    private void pushback(byte[] buf, int offset, int length)\n        throws IOException {\n        ((PushbackInputStream) in).unread(buf, offset, length);\n        pushedBackBytes(length);\n    }\n\n    // End of Central Directory Record\n    //   end of central dir signature    WORD\n    //   number of this disk             SHORT\n    //   number of the disk with the\n    //   start of the central directory  SHORT\n    //   total number of entries in the\n    //   central directory on this disk  SHORT\n    //   total number of entries in\n    //   the central directory           SHORT\n    //   size of the central directory   WORD\n    //   offset of start of central\n    //   directory with respect to\n    //   the starting disk number        WORD\n    //   .ZIP file comment length        SHORT\n    //   .ZIP file comment               up to 64KB\n    //\n\n    /**\n     * Reads the stream until it find the \"End of central directory\n     * record\" and consumes it as well.\n     */\n    private void skipRemainderOfArchive() throws IOException {\n        // skip over central directory. One LFH has been read too much\n        // already.  The calculation discounts file names and extra\n        // data so it will be too short.\n        realSkip(entriesRead * CFH_LEN - LFH_LEN);\n        findEocdRecord();\n        realSkip(ZipFile.MIN_EOCD_SIZE\n                 - WORD /* signature */ - SHORT /* comment len */);\n        readFully(SHORT_BUF);\n        // file comment\n        realSkip(ZipShort.getValue(SHORT_BUF));\n    }\n\n    /**\n     * Reads forward until the signature of the &quot;End of central\n     * directory&quot; recod is found.\n     */\n    private void findEocdRecord() throws IOException {\n        int currentByte = -1;\n        boolean skipReadCall = false;\n        while (skipReadCall || (currentByte = readOneByte()) > -1) {\n            skipReadCall = false;\n            if (!isFirstByteOfEocdSig(currentByte)) {\n                continue;\n            }\n            currentByte = readOneByte();\n            if (currentByte != ZipArchiveOutputStream.EOCD_SIG[1]) {\n                if (currentByte == -1) {\n                    break;\n                }\n                skipReadCall = isFirstByteOfEocdSig(currentByte);\n                continue;\n            }\n            currentByte = readOneByte();\n            if (currentByte != ZipArchiveOutputStream.EOCD_SIG[2]) {\n                if (currentByte == -1) {\n                    break;\n                }\n                skipReadCall = isFirstByteOfEocdSig(currentByte);\n                continue;\n            }\n            currentByte = readOneByte();\n            if (currentByte == -1\n                || currentByte == ZipArchiveOutputStream.EOCD_SIG[3]) {\n                break;\n            }\n            skipReadCall = isFirstByteOfEocdSig(currentByte);\n        }\n    }\n\n    /**\n     * Skips bytes by reading from the underlying stream rather than\n     * the (potentially inflating) archive stream - which {@link\n     * #skip} would do.\n     *\n     * Also updates bytes-read counter.\n     */\n    private void realSkip(long value) throws IOException {\n        if (value >= 0) {\n            long skipped = 0;\n            while (skipped < value) {\n                long rem = value - skipped;\n                int x = in.read(SKIP_BUF, 0,\n                                (int) (SKIP_BUF.length > rem ? rem\n                                       : SKIP_BUF.length));\n                if (x == -1) {\n                    return;\n                }\n                count(x);\n                skipped += x;\n            }\n            return;\n        }\n        throw new IllegalArgumentException();\n    }\n\n    /**\n     * Reads bytes by reading from the underlying stream rather than\n     * the (potentially inflating) archive stream - which {@link\n     * #read} would do.\n     *\n     * Also updates bytes-read counter.\n     */\n    private int readOneByte() throws IOException {\n        int b = in.read();\n        if (b != -1) {\n            count(1);\n        }\n        return b;\n    }\n\n    private boolean isFirstByteOfEocdSig(int b) {\n        return b == ZipArchiveOutputStream.EOCD_SIG[0];\n    }\n\n    /**\n     * Structure collecting information for the entry that is\n     * currently being read.\n     */\n    private static final class CurrentEntry {\n        /**\n         * Current ZIP entry.\n         */\n        private final ZipArchiveEntry entry = new ZipArchiveEntry();\n        /**\n         * Does the entry use a data descriptor?\n         */\n        private boolean hasDataDescriptor;\n        /**\n         * Does the entry have a ZIP64 extended information extra field.\n         */\n        private boolean usesZip64;\n        /**\n         * Number of bytes of entry content read by the client if the\n         * entry is STORED.\n         */\n        private long bytesRead;\n        /**\n         * Number of bytes of entry content read so from the stream.\n         *\n         * <p>This may be more than the actual entry's length as some\n         * stuff gets buffered up and needs to be pushed back when the\n         * end of the entry has been reached.</p>\n         */\n        private long bytesReadFromStream;\n    }\n}",
    "target": 1,
    "language": "java",
    "dataset": "A-Manually-Curated-Dataset-of-Vulnerability-Introducing-Commits-in-Java",
    "idx": 800052,
    "RELATED_CWE": [
      "CWE-908",
      "CWE-362",
      "CWE-667"
    ]
  },
  {
    "CWE_ID": [
      "CWE-835"
    ],
    "code": "/*\n * Licensed to the Apache Software Foundation (ASF) under one\n * or more contributor license agreements.  See the NOTICE file\n * distributed with this work for additional information\n * regarding copyright ownership.  The ASF licenses this file\n * to you under the Apache License, Version 2.0 (the\n * \"License\"); you may not use this file except in compliance\n * with the License.  You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing,\n * software distributed under the License is distributed on an\n * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n * KIND, either express or implied.  See the License for the\n * specific language governing permissions and limitations\n * under the License.\n */\npackage org.apache.commons.compress.archivers.zip;\n\nimport java.io.ByteArrayInputStream;\nimport java.io.ByteArrayOutputStream;\nimport java.io.EOFException;\nimport java.io.IOException;\nimport java.io.InputStream;\nimport java.io.PushbackInputStream;\nimport java.math.BigInteger;\nimport java.nio.ByteBuffer;\nimport java.util.Arrays;\nimport java.util.zip.CRC32;\nimport java.util.zip.DataFormatException;\nimport java.util.zip.Inflater;\nimport java.util.zip.ZipEntry;\nimport java.util.zip.ZipException;\n\nimport org.apache.commons.compress.archivers.ArchiveEntry;\nimport org.apache.commons.compress.archivers.ArchiveInputStream;\nimport org.apache.commons.compress.compressors.bzip2.BZip2CompressorInputStream;\nimport org.apache.commons.compress.compressors.deflate64.Deflate64CompressorInputStream;\nimport org.apache.commons.compress.utils.ArchiveUtils;\nimport org.apache.commons.compress.utils.IOUtils;\nimport org.apache.commons.compress.utils.InputStreamStatistics;\n\nimport static org.apache.commons.compress.archivers.zip.ZipConstants.DWORD;\nimport static org.apache.commons.compress.archivers.zip.ZipConstants.SHORT;\nimport static org.apache.commons.compress.archivers.zip.ZipConstants.WORD;\nimport static org.apache.commons.compress.archivers.zip.ZipConstants.ZIP64_MAGIC;\n\n/**\n * Implements an input stream that can read Zip archives.\n *\n * <p>As of Apache Commons Compress it transparently supports Zip64\n * extensions and thus individual entries and archives larger than 4\n * GB or with more than 65536 entries.</p>\n *\n * <p>The {@link ZipFile} class is preferred when reading from files\n * as {@link ZipArchiveInputStream} is limited by not being able to\n * read the central directory header before returning entries.  In\n * particular {@link ZipArchiveInputStream}</p>\n *\n * <ul>\n *\n *  <li>may return entries that are not part of the central directory\n *  at all and shouldn't be considered part of the archive.</li>\n *\n *  <li>may return several entries with the same name.</li>\n *\n *  <li>will not return internal or external attributes.</li>\n *\n *  <li>may return incomplete extra field data.</li>\n *\n *  <li>may return unknown sizes and CRC values for entries until the\n *  next entry has been reached if the archive uses the data\n *  descriptor feature.</li>\n *\n * </ul>\n *\n * @see ZipFile\n * @NotThreadSafe\n */\npublic class ZipArchiveInputStream extends ArchiveInputStream implements InputStreamStatistics {\n\n    /** The zip encoding to use for filenames and the file comment. */\n    private final ZipEncoding zipEncoding;\n\n    // the provided encoding (for unit tests)\n    final String encoding;\n\n    /** Whether to look for and use Unicode extra fields. */\n    private final boolean useUnicodeExtraFields;\n\n    /** Wrapped stream, will always be a PushbackInputStream. */\n    private final InputStream in;\n\n    /** Inflater used for all deflated entries. */\n    private final Inflater inf = new Inflater(true);\n\n    /** Buffer used to read from the wrapped stream. */\n    private final ByteBuffer buf = ByteBuffer.allocate(ZipArchiveOutputStream.BUFFER_SIZE);\n\n    /** The entry that is currently being read. */\n    private CurrentEntry current = null;\n\n    /** Whether the stream has been closed. */\n    private boolean closed = false;\n\n    /** Whether the stream has reached the central directory - and thus found all entries. */\n    private boolean hitCentralDirectory = false;\n\n    /**\n     * When reading a stored entry that uses the data descriptor this\n     * stream has to read the full entry and caches it.  This is the\n     * cache.\n     */\n    private ByteArrayInputStream lastStoredEntry = null;\n\n    /** Whether the stream will try to read STORED entries that use a data descriptor. */\n    private boolean allowStoredEntriesWithDataDescriptor = false;\n\n    /** Count decompressed bytes for current entry */\n    private long uncompressedCount = 0;\n\n    private static final int LFH_LEN = 30;\n    /*\n      local file header signature     WORD\n      version needed to extract       SHORT\n      general purpose bit flag        SHORT\n      compression method              SHORT\n      last mod file time              SHORT\n      last mod file date              SHORT\n      crc-32                          WORD\n      compressed size                 WORD\n      uncompressed size               WORD\n      file name length                SHORT\n      extra field length              SHORT\n    */\n\n    private static final int CFH_LEN = 46;\n    /*\n        central file header signature   WORD\n        version made by                 SHORT\n        version needed to extract       SHORT\n        general purpose bit flag        SHORT\n        compression method              SHORT\n        last mod file time              SHORT\n        last mod file date              SHORT\n        crc-32                          WORD\n        compressed size                 WORD\n        uncompressed size               WORD\n        file name length                SHORT\n        extra field length              SHORT\n        file comment length             SHORT\n        disk number start               SHORT\n        internal file attributes        SHORT\n        external file attributes        WORD\n        relative offset of local header WORD\n    */\n\n    private static final long TWO_EXP_32 = ZIP64_MAGIC + 1;\n\n    // cached buffers - must only be used locally in the class (COMPRESS-172 - reduce garbage collection)\n    private final byte[] lfhBuf = new byte[LFH_LEN];\n    private final byte[] skipBuf = new byte[1024];\n    private final byte[] shortBuf = new byte[SHORT];\n    private final byte[] wordBuf = new byte[WORD];\n    private final byte[] twoDwordBuf = new byte[2 * DWORD];\n\n    private int entriesRead = 0;\n\n    /**\n     * Create an instance using UTF-8 encoding\n     * @param inputStream the stream to wrap\n     */\n    public ZipArchiveInputStream(final InputStream inputStream) {\n        this(inputStream, ZipEncodingHelper.UTF8);\n    }\n\n    /**\n     * Create an instance using the specified encoding\n     * @param inputStream the stream to wrap\n     * @param encoding the encoding to use for file names, use null\n     * for the platform's default encoding\n     * @since 1.5\n     */\n    public ZipArchiveInputStream(final InputStream inputStream, final String encoding) {\n        this(inputStream, encoding, true);\n    }\n\n    /**\n     * Create an instance using the specified encoding\n     * @param inputStream the stream to wrap\n     * @param encoding the encoding to use for file names, use null\n     * for the platform's default encoding\n     * @param useUnicodeExtraFields whether to use InfoZIP Unicode\n     * Extra Fields (if present) to set the file names.\n     */\n    public ZipArchiveInputStream(final InputStream inputStream, final String encoding, final boolean useUnicodeExtraFields) {\n        this(inputStream, encoding, useUnicodeExtraFields, false);\n    }\n\n    /**\n     * Create an instance using the specified encoding\n     * @param inputStream the stream to wrap\n     * @param encoding the encoding to use for file names, use null\n     * for the platform's default encoding\n     * @param useUnicodeExtraFields whether to use InfoZIP Unicode\n     * Extra Fields (if present) to set the file names.\n     * @param allowStoredEntriesWithDataDescriptor whether the stream\n     * will try to read STORED entries that use a data descriptor\n     * @since 1.1\n     */\n    public ZipArchiveInputStream(final InputStream inputStream,\n                                 final String encoding,\n                                 final boolean useUnicodeExtraFields,\n                                 final boolean allowStoredEntriesWithDataDescriptor) {\n        this.encoding = encoding;\n        zipEncoding = ZipEncodingHelper.getZipEncoding(encoding);\n        this.useUnicodeExtraFields = useUnicodeExtraFields;\n        in = new PushbackInputStream(inputStream, buf.capacity());\n        this.allowStoredEntriesWithDataDescriptor =\n            allowStoredEntriesWithDataDescriptor;\n        // haven't read anything so far\n        buf.limit(0);\n    }\n\n    public ZipArchiveEntry getNextZipEntry() throws IOException {\n        uncompressedCount = 0;\n\n        boolean firstEntry = true;\n        if (closed || hitCentralDirectory) {\n            return null;\n        }\n        if (current != null) {\n            closeEntry();\n            firstEntry = false;\n        }\n\n        long currentHeaderOffset = getBytesRead();\n        try {\n            if (firstEntry) {\n                // split archives have a special signature before the\n                // first local file header - look for it and fail with\n                // the appropriate error message if this is a split\n                // archive.\n                readFirstLocalFileHeader(lfhBuf);\n            } else {\n                readFully(lfhBuf);\n            }\n        } catch (final EOFException e) {\n            return null;\n        }\n\n        final ZipLong sig = new ZipLong(lfhBuf);\n        if (!sig.equals(ZipLong.LFH_SIG)) {\n            if (sig.equals(ZipLong.CFH_SIG) || sig.equals(ZipLong.AED_SIG) || isApkSigningBlock(lfhBuf)) {\n                hitCentralDirectory = true;\n                skipRemainderOfArchive();\n                return null;\n            }\n            throw new ZipException(String.format(\"Unexpected record signature: 0X%X\", sig.getValue()));\n        }\n\n        int off = WORD;\n        current = new CurrentEntry();\n\n        final int versionMadeBy = ZipShort.getValue(lfhBuf, off);\n        off += SHORT;\n        current.entry.setPlatform((versionMadeBy >> ZipFile.BYTE_SHIFT) & ZipFile.NIBLET_MASK);\n\n        final GeneralPurposeBit gpFlag = GeneralPurposeBit.parse(lfhBuf, off);\n        final boolean hasUTF8Flag = gpFlag.usesUTF8ForNames();\n        final ZipEncoding entryEncoding = hasUTF8Flag ? ZipEncodingHelper.UTF8_ZIP_ENCODING : zipEncoding;\n        current.hasDataDescriptor = gpFlag.usesDataDescriptor();\n        current.entry.setGeneralPurposeBit(gpFlag);\n\n        off += SHORT;\n\n        current.entry.setMethod(ZipShort.getValue(lfhBuf, off));\n        off += SHORT;\n\n        final long time = ZipUtil.dosToJavaTime(ZipLong.getValue(lfhBuf, off));\n        current.entry.setTime(time);\n        off += WORD;\n\n        ZipLong size = null, cSize = null;\n        if (!current.hasDataDescriptor) {\n            current.entry.setCrc(ZipLong.getValue(lfhBuf, off));\n            off += WORD;\n\n            cSize = new ZipLong(lfhBuf, off);\n            off += WORD;\n\n            size = new ZipLong(lfhBuf, off);\n            off += WORD;\n        } else {\n            off += 3 * WORD;\n        }\n\n        final int fileNameLen = ZipShort.getValue(lfhBuf, off);\n\n        off += SHORT;\n\n        final int extraLen = ZipShort.getValue(lfhBuf, off);\n        off += SHORT; // NOSONAR - assignment as documentation\n\n        final byte[] fileName = new byte[fileNameLen];\n        readFully(fileName);\n        current.entry.setName(entryEncoding.decode(fileName), fileName);\n        if (hasUTF8Flag) {\n            current.entry.setNameSource(ZipArchiveEntry.NameSource.NAME_WITH_EFS_FLAG);\n        }\n\n        final byte[] extraData = new byte[extraLen];\n        readFully(extraData);\n        current.entry.setExtra(extraData);\n\n        if (!hasUTF8Flag && useUnicodeExtraFields) {\n            ZipUtil.setNameAndCommentFromExtraFields(current.entry, fileName, null);\n        }\n\n        processZip64Extra(size, cSize);\n\n        current.entry.setLocalHeaderOffset(currentHeaderOffset);\n        current.entry.setDataOffset(getBytesRead());\n        current.entry.setStreamContiguous(true);\n\n        ZipMethod m = ZipMethod.getMethodByCode(current.entry.getMethod());\n        if (current.entry.getCompressedSize() != ArchiveEntry.SIZE_UNKNOWN) {\n            if (ZipUtil.canHandleEntryData(current.entry) && m != ZipMethod.STORED && m != ZipMethod.DEFLATED) {\n                InputStream bis = new BoundedInputStream(in, current.entry.getCompressedSize());\n                switch (m) {\n                case UNSHRINKING:\n                    current.in = new UnshrinkingInputStream(bis);\n                    break;\n                case IMPLODING:\n                    current.in = new ExplodingInputStream(\n                        current.entry.getGeneralPurposeBit().getSlidingDictionarySize(),\n                        current.entry.getGeneralPurposeBit().getNumberOfShannonFanoTrees(),\n                        bis);\n                    break;\n                case BZIP2:\n                    current.in = new BZip2CompressorInputStream(bis);\n                    break;\n                case ENHANCED_DEFLATED:\n                    current.in = new Deflate64CompressorInputStream(bis);\n                    break;\n                default:\n                    // we should never get here as all supported methods have been covered\n                    // will cause an error when read is invoked, don't throw an exception here so people can\n                    // skip unsupported entries\n                    break;\n                }\n            }\n        } else if (m == ZipMethod.ENHANCED_DEFLATED) {\n            current.in = new Deflate64CompressorInputStream(in);\n        }\n\n        entriesRead++;\n        return current.entry;\n    }\n\n    /**\n     * Fills the given array with the first local file header and\n     * deals with splitting/spanning markers that may prefix the first\n     * LFH.\n     */\n    private void readFirstLocalFileHeader(final byte[] lfh) throws IOException {\n        readFully(lfh);\n        final ZipLong sig = new ZipLong(lfh);\n        if (sig.equals(ZipLong.DD_SIG)) {\n            throw new UnsupportedZipFeatureException(UnsupportedZipFeatureException.Feature.SPLITTING);\n        }\n\n        if (sig.equals(ZipLong.SINGLE_SEGMENT_SPLIT_MARKER)) {\n            // The archive is not really split as only one segment was\n            // needed in the end.  Just skip over the marker.\n            final byte[] missedLfhBytes = new byte[4];\n            readFully(missedLfhBytes);\n            System.arraycopy(lfh, 4, lfh, 0, LFH_LEN - 4);\n            System.arraycopy(missedLfhBytes, 0, lfh, LFH_LEN - 4, 4);\n        }\n    }\n\n    /**\n     * Records whether a Zip64 extra is present and sets the size\n     * information from it if sizes are 0xFFFFFFFF and the entry\n     * doesn't use a data descriptor.\n     */\n    private void processZip64Extra(final ZipLong size, final ZipLong cSize) {\n        final Zip64ExtendedInformationExtraField z64 =\n            (Zip64ExtendedInformationExtraField)\n            current.entry.getExtraField(Zip64ExtendedInformationExtraField.HEADER_ID);\n        current.usesZip64 = z64 != null;\n        if (!current.hasDataDescriptor) {\n            if (z64 != null // same as current.usesZip64 but avoids NPE warning\n                    && (cSize.equals(ZipLong.ZIP64_MAGIC) || size.equals(ZipLong.ZIP64_MAGIC)) ) {\n                current.entry.setCompressedSize(z64.getCompressedSize().getLongValue());\n                current.entry.setSize(z64.getSize().getLongValue());\n            } else {\n                current.entry.setCompressedSize(cSize.getValue());\n                current.entry.setSize(size.getValue());\n            }\n        }\n    }\n\n    @Override\n    public ArchiveEntry getNextEntry() throws IOException {\n        return getNextZipEntry();\n    }\n\n    /**\n     * Whether this class is able to read the given entry.\n     *\n     * <p>May return false if it is set up to use encryption or a\n     * compression method that hasn't been implemented yet.</p>\n     * @since 1.1\n     */\n    @Override\n    public boolean canReadEntryData(final ArchiveEntry ae) {\n        if (ae instanceof ZipArchiveEntry) {\n            final ZipArchiveEntry ze = (ZipArchiveEntry) ae;\n            return ZipUtil.canHandleEntryData(ze)\n                && supportsDataDescriptorFor(ze)\n                && supportsCompressedSizeFor(ze);\n        }\n        return false;\n    }\n\n    @Override\n    public int read(final byte[] buffer, final int offset, final int length) throws IOException {\n        if (closed) {\n            throw new IOException(\"The stream is closed\");\n        }\n\n        if (current == null) {\n            return -1;\n        }\n\n        // avoid int overflow, check null buffer\n        if (offset > buffer.length || length < 0 || offset < 0 || buffer.length - offset < length) {\n            throw new ArrayIndexOutOfBoundsException();\n        }\n\n        ZipUtil.checkRequestedFeatures(current.entry);\n        if (!supportsDataDescriptorFor(current.entry)) {\n            throw new UnsupportedZipFeatureException(UnsupportedZipFeatureException.Feature.DATA_DESCRIPTOR,\n                    current.entry);\n        }\n        if (!supportsCompressedSizeFor(current.entry)) {\n            throw new UnsupportedZipFeatureException(UnsupportedZipFeatureException.Feature.UNKNOWN_COMPRESSED_SIZE,\n                    current.entry);\n        }\n\n        int read;\n        if (current.entry.getMethod() == ZipArchiveOutputStream.STORED) {\n            read = readStored(buffer, offset, length);\n        } else if (current.entry.getMethod() == ZipArchiveOutputStream.DEFLATED) {\n            read = readDeflated(buffer, offset, length);\n        } else if (current.entry.getMethod() == ZipMethod.UNSHRINKING.getCode()\n                || current.entry.getMethod() == ZipMethod.IMPLODING.getCode()\n                || current.entry.getMethod() == ZipMethod.ENHANCED_DEFLATED.getCode()\n                || current.entry.getMethod() == ZipMethod.BZIP2.getCode()) {\n            read = current.in.read(buffer, offset, length);\n        } else {\n            throw new UnsupportedZipFeatureException(ZipMethod.getMethodByCode(current.entry.getMethod()),\n                    current.entry);\n        }\n\n        if (read >= 0) {\n            current.crc.update(buffer, offset, read);\n            uncompressedCount += read;\n        }\n\n        return read;\n    }\n\n    /**\n     * @since 1.17\n     */\n    @Override\n    public long getCompressedCount() {\n        if (current.entry.getMethod() == ZipArchiveOutputStream.STORED) {\n            return current.bytesRead;\n        } else if (current.entry.getMethod() == ZipArchiveOutputStream.DEFLATED) {\n            return getBytesInflated();\n        } else if (current.entry.getMethod() == ZipMethod.UNSHRINKING.getCode()) {\n            return ((UnshrinkingInputStream) current.in).getCompressedCount();\n        } else if (current.entry.getMethod() == ZipMethod.IMPLODING.getCode()) {\n            return ((ExplodingInputStream) current.in).getCompressedCount();\n        } else if (current.entry.getMethod() == ZipMethod.ENHANCED_DEFLATED.getCode()) {\n            return ((Deflate64CompressorInputStream) current.in).getCompressedCount();\n        } else if (current.entry.getMethod() == ZipMethod.BZIP2.getCode()) {\n            return ((BZip2CompressorInputStream) current.in).getCompressedCount();\n        } else {\n            return -1;\n        }\n    }\n\n    /**\n     * @since 1.17\n     */\n    @Override\n    public long getUncompressedCount() {\n        return uncompressedCount;\n    }\n\n    /**\n     * Implementation of read for STORED entries.\n     */\n    private int readStored(final byte[] buffer, final int offset, final int length) throws IOException {\n\n        if (current.hasDataDescriptor) {\n            if (lastStoredEntry == null) {\n                readStoredEntry();\n            }\n            return lastStoredEntry.read(buffer, offset, length);\n        }\n\n        final long csize = current.entry.getSize();\n        if (current.bytesRead >= csize) {\n            return -1;\n        }\n\n        if (buf.position() >= buf.limit()) {\n            buf.position(0);\n            final int l = in.read(buf.array());\n            if (l == -1) {\n                buf.limit(0);\n                throw new IOException(\"Truncated ZIP file\");\n            }\n            buf.limit(l);\n\n            count(l);\n            current.bytesReadFromStream += l;\n        }\n\n        int toRead = Math.min(buf.remaining(), length);\n        if ((csize - current.bytesRead) < toRead) {\n            // if it is smaller than toRead then it fits into an int\n            toRead = (int) (csize - current.bytesRead);\n        }\n        buf.get(buffer, offset, toRead);\n        current.bytesRead += toRead;\n        return toRead;\n    }\n\n    /**\n     * Implementation of read for DEFLATED entries.\n     */\n    private int readDeflated(final byte[] buffer, final int offset, final int length) throws IOException {\n        final int read = readFromInflater(buffer, offset, length);\n        if (read <= 0) {\n            if (inf.finished()) {\n                return -1;\n            } else if (inf.needsDictionary()) {\n                throw new ZipException(\"This archive needs a preset dictionary\"\n                                       + \" which is not supported by Commons\"\n                                       + \" Compress.\");\n            } else if (read == -1) {\n                throw new IOException(\"Truncated ZIP file\");\n            }\n        }\n        return read;\n    }\n\n    /**\n     * Potentially reads more bytes to fill the inflater's buffer and\n     * reads from it.\n     */\n    private int readFromInflater(final byte[] buffer, final int offset, final int length) throws IOException {\n        int read = 0;\n        do {\n            if (inf.needsInput()) {\n                final int l = fill();\n                if (l > 0) {\n                    current.bytesReadFromStream += buf.limit();\n                } else if (l == -1) {\n                    return -1;\n                } else {\n                    break;\n                }\n            }\n            try {\n                read = inf.inflate(buffer, offset, length);\n            } catch (final DataFormatException e) {\n                throw (IOException) new ZipException(e.getMessage()).initCause(e);\n            }\n        } while (read == 0 && inf.needsInput());\n        return read;\n    }\n\n    @Override\n    public void close() throws IOException {\n        if (!closed) {\n            closed = true;\n            try {\n                in.close();\n            } finally {\n                inf.end();\n            }\n        }\n    }\n\n    /**\n     * Skips over and discards value bytes of data from this input\n     * stream.\n     *\n     * <p>This implementation may end up skipping over some smaller\n     * number of bytes, possibly 0, if and only if it reaches the end\n     * of the underlying stream.</p>\n     *\n     * <p>The actual number of bytes skipped is returned.</p>\n     *\n     * @param value the number of bytes to be skipped.\n     * @return the actual number of bytes skipped.\n     * @throws IOException - if an I/O error occurs.\n     * @throws IllegalArgumentException - if value is negative.\n     */\n    @Override\n    public long skip(final long value) throws IOException {\n        if (value >= 0) {\n            long skipped = 0;\n            while (skipped < value) {\n                final long rem = value - skipped;\n                final int x = read(skipBuf, 0, (int) (skipBuf.length > rem ? rem : skipBuf.length));\n                if (x == -1) {\n                    return skipped;\n                }\n                skipped += x;\n            }\n            return skipped;\n        }\n        throw new IllegalArgumentException();\n    }\n\n    /**\n     * Checks if the signature matches what is expected for a zip file.\n     * Does not currently handle self-extracting zips which may have arbitrary\n     * leading content.\n     *\n     * @param signature the bytes to check\n     * @param length    the number of bytes to check\n     * @return true, if this stream is a zip archive stream, false otherwise\n     */\n    public static boolean matches(final byte[] signature, final int length) {\n        if (length < ZipArchiveOutputStream.LFH_SIG.length) {\n            return false;\n        }\n\n        return checksig(signature, ZipArchiveOutputStream.LFH_SIG) // normal file\n            || checksig(signature, ZipArchiveOutputStream.EOCD_SIG) // empty zip\n            || checksig(signature, ZipArchiveOutputStream.DD_SIG) // split zip\n            || checksig(signature, ZipLong.SINGLE_SEGMENT_SPLIT_MARKER.getBytes());\n    }\n\n    private static boolean checksig(final byte[] signature, final byte[] expected) {\n        for (int i = 0; i < expected.length; i++) {\n            if (signature[i] != expected[i]) {\n                return false;\n            }\n        }\n        return true;\n    }\n\n    /**\n     * Closes the current ZIP archive entry and positions the underlying\n     * stream to the beginning of the next entry. All per-entry variables\n     * and data structures are cleared.\n     * <p>\n     * If the compressed size of this entry is included in the entry header,\n     * then any outstanding bytes are simply skipped from the underlying\n     * stream without uncompressing them. This allows an entry to be safely\n     * closed even if the compression method is unsupported.\n     * <p>\n     * In case we don't know the compressed size of this entry or have\n     * already buffered too much data from the underlying stream to support\n     * uncompression, then the uncompression process is completed and the\n     * end position of the stream is adjusted based on the result of that\n     * process.\n     *\n     * @throws IOException if an error occurs\n     */\n    private void closeEntry() throws IOException {\n        if (closed) {\n            throw new IOException(\"The stream is closed\");\n        }\n        if (current == null) {\n            return;\n        }\n\n        // Ensure all entry bytes are read\n        if (currentEntryHasOutstandingBytes()) {\n            drainCurrentEntryData();\n        } else {\n            // this is guaranteed to exhaust the stream\n            skip(Long.MAX_VALUE); //NOSONAR\n\n            final long inB = current.entry.getMethod() == ZipArchiveOutputStream.DEFLATED\n                       ? getBytesInflated() : current.bytesRead;\n\n            // this is at most a single read() operation and can't\n            // exceed the range of int\n            final int diff = (int) (current.bytesReadFromStream - inB);\n\n            // Pushback any required bytes\n            if (diff > 0) {\n                pushback(buf.array(), buf.limit() - diff, diff);\n                current.bytesReadFromStream -= diff;\n            }\n\n            // Drain remainder of entry if not all data bytes were required\n            if (currentEntryHasOutstandingBytes()) {\n                drainCurrentEntryData();\n            }\n        }\n\n        if (lastStoredEntry == null && current.hasDataDescriptor) {\n            readDataDescriptor();\n        }\n\n        inf.reset();\n        buf.clear().flip();\n        current = null;\n        lastStoredEntry = null;\n    }\n\n    /**\n     * If the compressed size of the current entry is included in the entry header\n     * and there are any outstanding bytes in the underlying stream, then\n     * this returns true.\n     *\n     * @return true, if current entry is determined to have outstanding bytes, false otherwise\n     */\n    private boolean currentEntryHasOutstandingBytes() {\n        return current.bytesReadFromStream <= current.entry.getCompressedSize()\n                && !current.hasDataDescriptor;\n    }\n\n    /**\n     * Read all data of the current entry from the underlying stream\n     * that hasn't been read, yet.\n     */\n    private void drainCurrentEntryData() throws IOException {\n        long remaining = current.entry.getCompressedSize() - current.bytesReadFromStream;\n        while (remaining > 0) {\n            final long n = in.read(buf.array(), 0, (int) Math.min(buf.capacity(), remaining));\n            if (n < 0) {\n                throw new EOFException(\"Truncated ZIP entry: \"\n                                       + ArchiveUtils.sanitize(current.entry.getName()));\n            }\n            count(n);\n            remaining -= n;\n        }\n    }\n\n    /**\n     * Get the number of bytes Inflater has actually processed.\n     *\n     * <p>for Java &lt; Java7 the getBytes* methods in\n     * Inflater/Deflater seem to return unsigned ints rather than\n     * longs that start over with 0 at 2^32.</p>\n     *\n     * <p>The stream knows how many bytes it has read, but not how\n     * many the Inflater actually consumed - it should be between the\n     * total number of bytes read for the entry and the total number\n     * minus the last read operation.  Here we just try to make the\n     * value close enough to the bytes we've read by assuming the\n     * number of bytes consumed must be smaller than (or equal to) the\n     * number of bytes read but not smaller by more than 2^32.</p>\n     */\n    private long getBytesInflated() {\n        long inB = inf.getBytesRead();\n        if (current.bytesReadFromStream >= TWO_EXP_32) {\n            while (inB + TWO_EXP_32 <= current.bytesReadFromStream) {\n                inB += TWO_EXP_32;\n            }\n        }\n        return inB;\n    }\n\n    private int fill() throws IOException {\n        if (closed) {\n            throw new IOException(\"The stream is closed\");\n        }\n        final int length = in.read(buf.array());\n        if (length > 0) {\n            buf.limit(length);\n            count(buf.limit());\n            inf.setInput(buf.array(), 0, buf.limit());\n        }\n        return length;\n    }\n\n    private void readFully(final byte[] b) throws IOException {\n        readFully(b, 0);\n    }\n\n    private void readFully(final byte[] b, final int off) throws IOException {\n        final int len = b.length - off;\n        final int count = IOUtils.readFully(in, b, off, len);\n        count(count);\n        if (count < len) {\n            throw new EOFException();\n        }\n    }\n\n    private void readDataDescriptor() throws IOException {\n        readFully(wordBuf);\n        ZipLong val = new ZipLong(wordBuf);\n        if (ZipLong.DD_SIG.equals(val)) {\n            // data descriptor with signature, skip sig\n            readFully(wordBuf);\n            val = new ZipLong(wordBuf);\n        }\n        current.entry.setCrc(val.getValue());\n\n        // if there is a ZIP64 extra field, sizes are eight bytes\n        // each, otherwise four bytes each.  Unfortunately some\n        // implementations - namely Java7 - use eight bytes without\n        // using a ZIP64 extra field -\n        // https://bugs.sun.com/bugdatabase/view_bug.do?bug_id=7073588\n\n        // just read 16 bytes and check whether bytes nine to twelve\n        // look like one of the signatures of what could follow a data\n        // descriptor (ignoring archive decryption headers for now).\n        // If so, push back eight bytes and assume sizes are four\n        // bytes, otherwise sizes are eight bytes each.\n        readFully(twoDwordBuf);\n        final ZipLong potentialSig = new ZipLong(twoDwordBuf, DWORD);\n        if (potentialSig.equals(ZipLong.CFH_SIG) || potentialSig.equals(ZipLong.LFH_SIG)) {\n            pushback(twoDwordBuf, DWORD, DWORD);\n            current.entry.setCompressedSize(ZipLong.getValue(twoDwordBuf));\n            current.entry.setSize(ZipLong.getValue(twoDwordBuf, WORD));\n        } else {\n            current.entry.setCompressedSize(ZipEightByteInteger.getLongValue(twoDwordBuf));\n            current.entry.setSize(ZipEightByteInteger.getLongValue(twoDwordBuf, DWORD));\n        }\n    }\n\n    /**\n     * Whether this entry requires a data descriptor this library can work with.\n     *\n     * @return true if allowStoredEntriesWithDataDescriptor is true,\n     * the entry doesn't require any data descriptor or the method is\n     * DEFLATED or ENHANCED_DEFLATED.\n     */\n    private boolean supportsDataDescriptorFor(final ZipArchiveEntry entry) {\n        return !entry.getGeneralPurposeBit().usesDataDescriptor()\n\n                || (allowStoredEntriesWithDataDescriptor && entry.getMethod() == ZipEntry.STORED)\n                || entry.getMethod() == ZipEntry.DEFLATED\n                || entry.getMethod() == ZipMethod.ENHANCED_DEFLATED.getCode();\n    }\n\n    /**\n     * Whether the compressed size for the entry is either known or\n     * not required by the compression method being used.\n     */\n    private boolean supportsCompressedSizeFor(final ZipArchiveEntry entry) {\n        return entry.getCompressedSize() != ArchiveEntry.SIZE_UNKNOWN\n            || entry.getMethod() == ZipEntry.DEFLATED\n            || entry.getMethod() == ZipMethod.ENHANCED_DEFLATED.getCode()\n            || (entry.getGeneralPurposeBit().usesDataDescriptor()\n                && allowStoredEntriesWithDataDescriptor\n                && entry.getMethod() == ZipEntry.STORED);\n    }\n\n    /**\n     * Caches a stored entry that uses the data descriptor.\n     *\n     * <ul>\n     *   <li>Reads a stored entry until the signature of a local file\n     *     header, central directory header or data descriptor has been\n     *     found.</li>\n     *   <li>Stores all entry data in lastStoredEntry.</p>\n     *   <li>Rewinds the stream to position at the data\n     *     descriptor.</li>\n     *   <li>reads the data descriptor</li>\n     * </ul>\n     *\n     * <p>After calling this method the entry should know its size,\n     * the entry's data is cached and the stream is positioned at the\n     * next local file or central directory header.</p>\n     */\n    private void readStoredEntry() throws IOException {\n        final ByteArrayOutputStream bos = new ByteArrayOutputStream();\n        int off = 0;\n        boolean done = false;\n\n        // length of DD without signature\n        final int ddLen = current.usesZip64 ? WORD + 2 * DWORD : 3 * WORD;\n\n        while (!done) {\n            final int r = in.read(buf.array(), off, ZipArchiveOutputStream.BUFFER_SIZE - off);\n            if (r <= 0) {\n                // read the whole archive without ever finding a\n                // central directory\n                throw new IOException(\"Truncated ZIP file\");\n            }\n            if (r + off < 4) {\n                // buffer too small to check for a signature, loop\n                off += r;\n                continue;\n            }\n\n            done = bufferContainsSignature(bos, off, r, ddLen);\n            if (!done) {\n                off = cacheBytesRead(bos, off, r, ddLen);\n            }\n        }\n\n        final byte[] b = bos.toByteArray();\n        lastStoredEntry = new ByteArrayInputStream(b);\n    }\n\n    private static final byte[] LFH = ZipLong.LFH_SIG.getBytes();\n    private static final byte[] CFH = ZipLong.CFH_SIG.getBytes();\n    private static final byte[] DD = ZipLong.DD_SIG.getBytes();\n\n    /**\n     * Checks whether the current buffer contains the signature of a\n     * &quot;data descriptor&quot;, &quot;local file header&quot; or\n     * &quot;central directory entry&quot;.\n     *\n     * <p>If it contains such a signature, reads the data descriptor\n     * and positions the stream right after the data descriptor.</p>\n     */\n    private boolean bufferContainsSignature(final ByteArrayOutputStream bos, final int offset, final int lastRead, final int expectedDDLen)\n            throws IOException {\n\n        boolean done = false;\n        int readTooMuch = 0;\n        for (int i = 0; !done && i < offset + lastRead - 4; i++) {\n            if (buf.array()[i] == LFH[0] && buf.array()[i + 1] == LFH[1]) {\n                if ((buf.array()[i + 2] == LFH[2] && buf.array()[i + 3] == LFH[3])\n                    || (buf.array()[i] == CFH[2] && buf.array()[i + 3] == CFH[3])) {\n                    // found a LFH or CFH:\n                    readTooMuch = offset + lastRead - i - expectedDDLen;\n                    done = true;\n                }\n                else if (buf.array()[i + 2] == DD[2] && buf.array()[i + 3] == DD[3]) {\n                    // found DD:\n                    readTooMuch = offset + lastRead - i;\n                    done = true;\n                }\n                if (done) {\n                    // * push back bytes read in excess as well as the data\n                    //   descriptor\n                    // * copy the remaining bytes to cache\n                    // * read data descriptor\n                    pushback(buf.array(), offset + lastRead - readTooMuch, readTooMuch);\n                    bos.write(buf.array(), 0, i);\n                    readDataDescriptor();\n                }\n            }\n        }\n        return done;\n    }\n\n    /**\n     * If the last read bytes could hold a data descriptor and an\n     * incomplete signature then save the last bytes to the front of\n     * the buffer and cache everything in front of the potential data\n     * descriptor into the given ByteArrayOutputStream.\n     *\n     * <p>Data descriptor plus incomplete signature (3 bytes in the\n     * worst case) can be 20 bytes max.</p>\n     */\n    private int cacheBytesRead(final ByteArrayOutputStream bos, int offset, final int lastRead, final int expecteDDLen) {\n        final int cacheable = offset + lastRead - expecteDDLen - 3;\n        if (cacheable > 0) {\n            bos.write(buf.array(), 0, cacheable);\n            System.arraycopy(buf.array(), cacheable, buf.array(), 0, expecteDDLen + 3);\n            offset = expecteDDLen + 3;\n        } else {\n            offset += lastRead;\n        }\n        return offset;\n    }\n\n    private void pushback(final byte[] buf, final int offset, final int length) throws IOException {\n        ((PushbackInputStream) in).unread(buf, offset, length);\n        pushedBackBytes(length);\n    }\n\n    // End of Central Directory Record\n    //   end of central dir signature    WORD\n    //   number of this disk             SHORT\n    //   number of the disk with the\n    //   start of the central directory  SHORT\n    //   total number of entries in the\n    //   central directory on this disk  SHORT\n    //   total number of entries in\n    //   the central directory           SHORT\n    //   size of the central directory   WORD\n    //   offset of start of central\n    //   directory with respect to\n    //   the starting disk number        WORD\n    //   .ZIP file comment length        SHORT\n    //   .ZIP file comment               up to 64KB\n    //\n\n    /**\n     * Reads the stream until it find the \"End of central directory\n     * record\" and consumes it as well.\n     */\n    private void skipRemainderOfArchive() throws IOException {\n        // skip over central directory. One LFH has been read too much\n        // already.  The calculation discounts file names and extra\n        // data so it will be too short.\n        realSkip((long) entriesRead * CFH_LEN - LFH_LEN);\n        findEocdRecord();\n        realSkip((long) ZipFile.MIN_EOCD_SIZE - WORD /* signature */ - SHORT /* comment len */);\n        readFully(shortBuf);\n        // file comment\n        realSkip(ZipShort.getValue(shortBuf));\n    }\n\n    /**\n     * Reads forward until the signature of the &quot;End of central\n     * directory&quot; record is found.\n     */\n    private void findEocdRecord() throws IOException {\n        int currentByte = -1;\n        boolean skipReadCall = false;\n        while (skipReadCall || (currentByte = readOneByte()) > -1) {\n            skipReadCall = false;\n            if (!isFirstByteOfEocdSig(currentByte)) {\n                continue;\n            }\n            currentByte = readOneByte();\n            if (currentByte != ZipArchiveOutputStream.EOCD_SIG[1]) {\n                if (currentByte == -1) {\n                    break;\n                }\n                skipReadCall = isFirstByteOfEocdSig(currentByte);\n                continue;\n            }\n            currentByte = readOneByte();\n            if (currentByte != ZipArchiveOutputStream.EOCD_SIG[2]) {\n                if (currentByte == -1) {\n                    break;\n                }\n                skipReadCall = isFirstByteOfEocdSig(currentByte);\n                continue;\n            }\n            currentByte = readOneByte();\n            if (currentByte == -1\n                || currentByte == ZipArchiveOutputStream.EOCD_SIG[3]) {\n                break;\n            }\n            skipReadCall = isFirstByteOfEocdSig(currentByte);\n        }\n    }\n\n    /**\n     * Skips bytes by reading from the underlying stream rather than\n     * the (potentially inflating) archive stream - which {@link\n     * #skip} would do.\n     *\n     * Also updates bytes-read counter.\n     */\n    private void realSkip(final long value) throws IOException {\n        if (value >= 0) {\n            long skipped = 0;\n            while (skipped < value) {\n                final long rem = value - skipped;\n                final int x = in.read(skipBuf, 0, (int) (skipBuf.length > rem ? rem : skipBuf.length));\n                if (x == -1) {\n                    return;\n                }\n                count(x);\n                skipped += x;\n            }\n            return;\n        }\n        throw new IllegalArgumentException();\n    }\n\n    /**\n     * Reads bytes by reading from the underlying stream rather than\n     * the (potentially inflating) archive stream - which {@link #read} would do.\n     *\n     * Also updates bytes-read counter.\n     */\n    private int readOneByte() throws IOException {\n        final int b = in.read();\n        if (b != -1) {\n            count(1);\n        }\n        return b;\n    }\n\n    private boolean isFirstByteOfEocdSig(final int b) {\n        return b == ZipArchiveOutputStream.EOCD_SIG[0];\n    }\n\n    private static final byte[] APK_SIGNING_BLOCK_MAGIC = new byte[] {\n        'A', 'P', 'K', ' ', 'S', 'i', 'g', ' ', 'B', 'l', 'o', 'c', 'k', ' ', '4', '2',\n    };\n    private static final BigInteger LONG_MAX = BigInteger.valueOf(Long.MAX_VALUE);\n\n    /**\n     * Checks whether this might be an APK Signing Block.\n     *\n     * <p>Unfortunately the APK signing block does not start with some kind of signature, it rather ends with one. It\n     * starts with a length, so what we do is parse the suspect length, skip ahead far enough, look for the signature\n     * and if we've found it, return true.</p>\n     *\n     * @param suspectLocalFileHeader the bytes read from the underlying stream in the expectation that they would hold\n     * the local file header of the next entry.\n     *\n     * @return true if this looks like a APK signing block\n     *\n     * @see <a href=\"https://source.android.com/security/apksigning/v2\">https://source.android.com/security/apksigning/v2</a>\n     */\n    private boolean isApkSigningBlock(byte[] suspectLocalFileHeader) throws IOException {\n        // length of block excluding the size field itself\n        BigInteger len = ZipEightByteInteger.getValue(suspectLocalFileHeader);\n        // LFH has already been read and all but the first eight bytes contain (part of) the APK signing block,\n        // also subtract 16 bytes in order to position us at the magic string\n        BigInteger toSkip = len.add(BigInteger.valueOf(DWORD - suspectLocalFileHeader.length\n            - APK_SIGNING_BLOCK_MAGIC.length));\n        byte[] magic = new byte[APK_SIGNING_BLOCK_MAGIC.length];\n\n        try {\n            if (toSkip.signum() < 0) {\n                // suspectLocalFileHeader contains the start of suspect magic string\n                int off = suspectLocalFileHeader.length + toSkip.intValue();\n                // length was shorter than magic length\n                if (off < DWORD) {\n                    return false;\n                }\n                int bytesInBuffer = Math.abs(toSkip.intValue());\n                System.arraycopy(suspectLocalFileHeader, off, magic, 0, Math.min(bytesInBuffer, magic.length));\n                if (bytesInBuffer < magic.length) {\n                    readFully(magic, bytesInBuffer);\n                }\n            } else {\n                while (toSkip.compareTo(LONG_MAX) > 0) {\n                    realSkip(Long.MAX_VALUE);\n                    toSkip = toSkip.add(LONG_MAX.negate());\n                }\n                realSkip(toSkip.longValue());\n                readFully(magic);\n            }\n        } catch (EOFException ex) {\n            // length was invalid\n            return false;\n        }\n        return Arrays.equals(magic, APK_SIGNING_BLOCK_MAGIC);\n    }\n\n    /**\n     * Structure collecting information for the entry that is\n     * currently being read.\n     */\n    private static final class CurrentEntry {\n\n        /**\n         * Current ZIP entry.\n         */\n        private final ZipArchiveEntry entry = new ZipArchiveEntry();\n\n        /**\n         * Does the entry use a data descriptor?\n         */\n        private boolean hasDataDescriptor;\n\n        /**\n         * Does the entry have a ZIP64 extended information extra field.\n         */\n        private boolean usesZip64;\n\n        /**\n         * Number of bytes of entry content read by the client if the\n         * entry is STORED.\n         */\n        private long bytesRead;\n\n        /**\n         * Number of bytes of entry content read from the stream.\n         *\n         * <p>This may be more than the actual entry's length as some\n         * stuff gets buffered up and needs to be pushed back when the\n         * end of the entry has been reached.</p>\n         */\n        private long bytesReadFromStream;\n\n        /**\n         * The checksum calculated as the current entry is read.\n         */\n        private final CRC32 crc = new CRC32();\n\n        /**\n         * The input stream decompressing the data for shrunk and imploded entries.\n         */\n        private InputStream in;\n    }\n\n    /**\n     * Bounded input stream adapted from commons-io\n     */\n    private class BoundedInputStream extends InputStream {\n\n        /** the wrapped input stream */\n        private final InputStream in;\n\n        /** the max length to provide */\n        private final long max;\n\n        /** the number of bytes already returned */\n        private long pos = 0;\n\n        /**\n         * Creates a new <code>BoundedInputStream</code> that wraps the given input\n         * stream and limits it to a certain size.\n         *\n         * @param in The wrapped input stream\n         * @param size The maximum number of bytes to return\n         */\n        public BoundedInputStream(final InputStream in, final long size) {\n            this.max = size;\n            this.in = in;\n        }\n\n        @Override\n        public int read() throws IOException {\n            if (max >= 0 && pos >= max) {\n                return -1;\n            }\n            final int result = in.read();\n            pos++;\n            count(1);\n            current.bytesReadFromStream++;\n            return result;\n        }\n\n        @Override\n        public int read(final byte[] b) throws IOException {\n            return this.read(b, 0, b.length);\n        }\n\n        @Override\n        public int read(final byte[] b, final int off, final int len) throws IOException {\n            if (max >= 0 && pos >= max) {\n                return -1;\n            }\n            final long maxRead = max >= 0 ? Math.min(len, max - pos) : len;\n            final int bytesRead = in.read(b, off, (int) maxRead);\n\n            if (bytesRead == -1) {\n                return -1;\n            }\n\n            pos += bytesRead;\n            count(bytesRead);\n            current.bytesReadFromStream += bytesRead;\n            return bytesRead;\n        }\n\n        @Override\n        public long skip(final long n) throws IOException {\n            final long toSkip = max >= 0 ? Math.min(n, max - pos) : n;\n            final long skippedBytes = IOUtils.skip(in, toSkip);\n            pos += skippedBytes;\n            return skippedBytes;\n        }\n\n        @Override\n        public int available() throws IOException {\n            if (max >= 0 && pos >= max) {\n                return 0;\n            }\n            return in.available();\n        }\n    }\n}",
    "target": 0,
    "language": "java",
    "dataset": "A-Manually-Curated-Dataset-of-Vulnerability-Introducing-Commits-in-Java",
    "idx": 800053,
    "RELATED_CWE": [
      "CWE-908",
      "CWE-362",
      "CWE-667"
    ]
  },
  {
    "CWE_ID": [
      "CWE-835"
    ],
    "code": "/*\n * Licensed to the Apache Software Foundation (ASF) under one\n * or more contributor license agreements.  See the NOTICE file\n * distributed with this work for additional information\n * regarding copyright ownership.  The ASF licenses this file\n * to you under the Apache License, Version 2.0 (the\n * \"License\"); you may not use this file except in compliance\n * with the License.  You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing,\n * software distributed under the License is distributed on an\n * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n * KIND, either express or implied.  See the License for the\n * specific language governing permissions and limitations\n * under the License.\n */\npackage org.apache.commons.compress.archivers.zip;\n\n/**\n * Strong Encryption Header (0x0017)\n *\n * Certificate-based encryption:\n *\n * <pre>\n * Value     Size     Description\n * -----     ----     -----------\n * 0x0017    2 bytes  Tag for this \"extra\" block type\n * TSize     2 bytes  Size of data that follows\n * Format    2 bytes  Format definition for this record\n * AlgID     2 bytes  Encryption algorithm identifier\n * Bitlen    2 bytes  Bit length of encryption key (32-448 bits)\n * Flags     2 bytes  Processing flags\n * RCount    4 bytes  Number of recipients. \n * HashAlg   2 bytes  Hash algorithm identifier\n * HSize     2 bytes  Hash size\n * SRList    (var)    Simple list of recipients hashed public keys\n * \n * Flags -   This defines the processing flags.\n * \n *           <ul>\n *           <li>0x0007 - reserved for future use\n *           <li>0x000F - reserved for future use\n *           <li>0x0100 - Indicates non-OAEP key wrapping was used.  If this\n *                        this field is set, the version needed to extract must\n *                        be at least 61.  This means OAEP key wrapping is not\n *                        used when generating a Master Session Key using\n *                        ErdData.\n *           <li>0x4000 - ErdData must be decrypted using 3DES-168, otherwise use the\n *                        same algorithm used for encrypting the file contents.\n *           <li>0x8000 - reserved for future use\n *           </ul>\n *        \n * RCount - This defines the number intended recipients whose\n *          public keys were used for encryption.  This identifies\n *          the number of elements in the SRList.\n *          \n *          see also: reserved1\n * \n * HashAlg - This defines the hash algorithm used to calculate\n *           the public key hash of each public key used\n *           for encryption. This field currently supports\n *           only the following value for SHA-1\n * \n *           0x8004 - SHA1\n * \n * HSize -   This defines the size of a hashed public key.\n * \n * SRList -  This is a variable length list of the hashed\n *           public keys for each intended recipient.  Each\n *           element in this list is HSize.  The total size of\n *           SRList is determined using RCount * HSize.\n * </pre>\n * \n * Password-based Extra Field 0x0017 in central header only.\n * \n * <pre>\n * Value     Size     Description\n * -----     ----     -----------\n * 0x0017    2 bytes  Tag for this \"extra\" block type\n * TSize     2 bytes  Size of data that follows\n * Format    2 bytes  Format definition for this record\n * AlgID     2 bytes  Encryption algorithm identifier\n * Bitlen    2 bytes  Bit length of encryption key (32-448 bits)\n * Flags     2 bytes  Processing flags\n * (more?)\n * </pre>\n *\n * <b>Format</b> - the data format identifier for this record. The only value\n * allowed at this time is the integer value 2.\n * \n * Password-based Extra Field 0x0017 preceding compressed file data.\n * \n * <pre>\n * Value     Size     Description\n * -----     ----     -----------\n * 0x0017    2 bytes  Tag for this \"extra\" block type\n * IVSize    2 bytes  Size of initialization vector (IV)\n * IVData    IVSize   Initialization vector for this file\n * Size      4 bytes  Size of remaining decryption header data\n * Format    2 bytes  Format definition for this record\n * AlgID     2 bytes  Encryption algorithm identifier\n * Bitlen    2 bytes  Bit length of encryption key (32-448 bits)\n * Flags     2 bytes  Processing flags\n * ErdSize   2 bytes  Size of Encrypted Random Data\n * ErdData   ErdSize  Encrypted Random Data\n * Reserved1 4 bytes  Reserved certificate processing data\n * Reserved2 (var)    Reserved for certificate processing data\n * VSize     2 bytes  Size of password validation data\n * VData     VSize-4  Password validation data\n * VCRC32    4 bytes  Standard ZIP CRC32 of password validation data\n *     \n * IVData - The size of the IV should match the algorithm block size.\n *          The IVData can be completely random data.  If the size of\n *          the randomly generated data does not match the block size\n *          it should be complemented with zero's or truncated as\n *          necessary.  If IVSize is 0,then IV = CRC32 + Uncompressed\n *          File Size (as a 64 bit little-endian, unsigned integer value).\n * \n * Format -  the data format identifier for this record.  The only\n *           value allowed at this time is the integer value 2.\n * \n * ErdData - Encrypted random data is used to store random data that\n *           is used to generate a file session key for encrypting\n *           each file.  SHA1 is used to calculate hash data used to\n *           derive keys.  File session keys are derived from a master\n *           session key generated from the user-supplied password.\n *           If the Flags field in the decryption header contains\n *           the value 0x4000, then the ErdData field must be\n *           decrypted using 3DES. If the value 0x4000 is not set,\n *           then the ErdData field must be decrypted using AlgId.\n * \n * Reserved1 - Reserved for certificate processing, if value is\n *           zero, then Reserved2 data is absent.  See the explanation\n *           under the Certificate Processing Method for details on\n *           this data structure.\n * \n * Reserved2 - If present, the size of the Reserved2 data structure\n *           is located by skipping the first 4 bytes of this field\n *           and using the next 2 bytes as the remaining size.  See\n *           the explanation under the Certificate Processing Method\n *           for details on this data structure.\n * \n * VSize - This size value will always include the 4 bytes of the\n *         VCRC32 data and will be greater than 4 bytes.\n * \n * VData - Random data for password validation.  This data is VSize\n *         in length and VSize must be a multiple of the encryption\n *         block size.  VCRC32 is a checksum value of VData. \n *         VData and VCRC32 are stored encrypted and start the\n *         stream of encrypted data for a file.\n * </pre>\n * \n * \n * Reserved1 - Certificate Decryption Header Reserved1 Data:\n * \n * <pre>\n * Value     Size     Description\n * -----     ----     -----------\n * RCount    4 bytes  Number of recipients.\n * </pre>\n * \n * RCount - This defines the number intended recipients whose public keys were\n * used for encryption. This defines the number of elements in the REList field\n * defined below.\n * \n * \n * Reserved2 - Certificate Decryption Header Reserved2 Data Structures:\n * \n * <pre>\n * Value     Size     Description\n * -----     ----     -----------\n * HashAlg   2 bytes  Hash algorithm identifier\n * HSize     2 bytes  Hash size\n * REList    (var)    List of recipient data elements\n * \n * HashAlg - This defines the hash algorithm used to calculate\n *           the public key hash of each public key used\n *           for encryption. This field currently supports\n *           only the following value for SHA-1\n *    \n *               0x8004 - SHA1\n *                \n * HSize -   This defines the size of a hashed public key\n *           defined in REHData.\n * \n * REList -  This is a variable length of list of recipient data. \n *           Each element in this list consists of a Recipient\n *           Element data structure as follows:\n * </pre>\n * \n * Recipient Element (REList) Data Structure:\n *\n * <pre>\n * Value     Size     Description\n * -----     ----     -----------\n * RESize    2 bytes  Size of REHData + REKData\n * REHData   HSize    Hash of recipients public key\n * REKData   (var)    Simple key blob\n * \n * \n * RESize -  This defines the size of an individual REList\n *           element.  This value is the combined size of the\n *           REHData field + REKData field.  REHData is defined by\n *           HSize.  REKData is variable and can be calculated\n *           for each REList element using RESize and HSize.\n * \n * REHData - Hashed public key for this recipient.\n * \n * REKData - Simple Key Blob.  The format of this data structure\n *           is identical to that defined in the Microsoft\n *           CryptoAPI and generated using the CryptExportKey()\n *           function.  The version of the Simple Key Blob\n *           supported at this time is 0x02 as defined by\n *           Microsoft.\n *           \n *           For more details see https://msdn.microsoft.com/en-us/library/aa920051.aspx\n * </pre>\n * \n * <b>Flags</b> - Processing flags needed for decryption\n * \n * <ul>\n * <li>0x0001 - Password is required to decrypt</li>\n * <li>0x0002 - Certificates only</li>\n * <li>0x0003 - Password or certificate required to decrypt</li>\n * <li>0x0007 - reserved for future use\n * <li>0x000F - reserved for future use\n * <li>0x0100 - indicates non-OAEP key wrapping was used. If this field is set\n * the version needed to extract must be at least 61. This means OAEP key\n * wrapping is not used when generating a Master Session Key using ErdData.\n * <li>0x4000 - ErdData must be decrypted using 3DES-168, otherwise use the same\n * algorithm used for encrypting the file contents.\n * <li>0x8000 - reserved for future use.\n * </ul>\n *\n * <b>See the section describing the Strong Encryption Specification for\n * details. Refer to the section in this document entitled\n * \"Incorporating PKWARE Proprietary Technology into Your Product\" for more\n * information.</b>\n *\n * @NotThreadSafe\n */\npublic class X0017_StrongEncryptionHeader extends PKWareExtraHeader implements ZipExtraField {\n    private static final ZipShort HEADER_ID = new ZipShort(0x0017);\n    private static final long serialVersionUID = 1L;\n\n    /**\n     * Get the header id.\n     * \n     * @return the header id\n     */\n    public ZipShort getHeaderId() {\n        return HEADER_ID;\n    }\n\n    /**\n     * Extra field data in local file data - without Header-ID or length\n     * specifier.\n     */\n    private byte[] localData;\n\n    private int format;\n    private EncryptionAlgorithm algId;\n    private int bitlen;\n    private int flags;\n    private long rcount;\n    private HashAlgorithm hashAlg;\n    private int hashSize;\n\n    // encryption data\n    private byte ivData[];\n    private byte erdData[];\n    \n    // encryption key\n    private byte recipientKeyHash[];\n    private byte keyBlob[];\n    \n    // password verification data\n    private byte vData[];\n    private byte vCRC32[];\n\n    /**\n     * Get record count.\n     * @return\n     */\n    public long getRecordCount() {\n        return rcount;\n    }\n    \n    /**\n     * Get hash algorithm.\n     * @return\n     */\n    public HashAlgorithm getHashAlgorithm() {\n        return hashAlg;\n    }\n    \n    /**\n     * Get encryption algorithm.\n     * @return\n     */\n    public EncryptionAlgorithm getEncryptionAlgorithm() {\n        return algId;\n    }\n    \n    /**\n     * Set the extra field data in the local file data - without Header-ID or\n     * length specifier.\n     * \n     * @param data\n     *            the field data to use\n     */\n    public void setLocalFileDataData(byte[] data) {\n        localData = ZipUtil.copy(data);\n    }\n\n    /**\n     * Get the length of the local data.\n     * \n     * @return the length of the local data\n     */\n    public ZipShort getLocalFileDataLength() {\n        return new ZipShort(localData != null ? localData.length : 0);\n    }\n\n    /**\n     * Get the local data.\n     * \n     * @return the local data\n     */\n    public byte[] getLocalFileDataData() {\n        return ZipUtil.copy(localData);\n    }\n\n    /**\n     * Extra field data in central directory - without Header-ID or length\n     * specifier.\n     */\n    private byte[] centralData;\n\n    /**\n     * Set the extra field data in central directory.\n     * \n     * @param data\n     *            the data to use\n     */\n    public void setCentralDirectoryData(byte[] data) {\n        centralData = ZipUtil.copy(data);\n    }\n\n    /**\n     * Get the central data length. If there is no central data, get the local\n     * file data length.\n     * \n     * @return the central data length\n     */\n    public ZipShort getCentralDirectoryLength() {\n        if (centralData != null) {\n            return new ZipShort(centralData.length);\n        }\n        return getLocalFileDataLength();\n    }\n\n    /**\n     * Get the central data.\n     * \n     * @return the central data if present, else return the local file data\n     */\n    public byte[] getCentralDirectoryData() {\n        if (centralData != null) {\n            return ZipUtil.copy(centralData);\n        }\n        return getLocalFileDataData();\n    }\n\n    /**\n     * Parse central directory format.\n     * \n     * @param data\n     * @param offset\n     * @param length\n     */\n    public void parseCentralDirectoryFormat(byte[] data, int offset, int length) {\n        this.format = ZipShort.getValue(data, offset);\n        this.algId = EncryptionAlgorithm.getAlgorithmByCode(ZipShort.getValue(data, offset + 2));\n        this.bitlen = ZipShort.getValue(data, offset + 4);\n        this.flags = ZipShort.getValue(data, offset + 6);\n        this.rcount = ZipLong.getValue(data, offset + 8);\n\n        if (rcount > 0) {\n            this.hashAlg = HashAlgorithm.getAlgorithmByCode(ZipShort.getValue(data, offset + 12));\n            this.hashSize = ZipShort.getValue(data, offset + 14);\n            // srlist... hashed public keys\n            for (int i = 0; i < this.rcount; i++) {\n                for (int j = 0; j < this.hashSize; j++) {\n                    //  ZipUtil.signedByteToUnsignedInt(data[offset + 16 + (i * this.hashSize) + j]));\n                }\n            }\n        }\n    }\n\n    /**\n     * Parse file header format. (Password only?)\n     * \n     * @param data\n     * @param offset\n     * @param length\n     */\n    public void parseFileFormat(byte[] data, int offset, int length) {\n        int ivSize = ZipShort.getValue(data, offset);\n        this.ivData = new byte[ivSize];\n        System.arraycopy(data, offset + 4, this.ivData, 0, ivSize);\n\n        long size = ZipLong.getValue(data, offset + ivSize + 2);\n        this.format = ZipShort.getValue(data, offset + ivSize + 6);\n        this.algId = EncryptionAlgorithm.getAlgorithmByCode(ZipShort.getValue(data, offset + ivSize + 8));\n        this.bitlen = ZipShort.getValue(data, offset + ivSize + 10);\n        this.flags = ZipShort.getValue(data, offset + ivSize + 12);\n\n        int erdSize = ZipShort.getValue(data, offset + ivSize + 14);\n        this.erdData = new byte[erdSize];\n        System.arraycopy(data, offset + ivSize + 16, this.erdData, 0, erdSize);\n        \n        this.rcount = ZipLong.getValue(data, offset + ivSize + 16 + erdSize);\n        System.out.println(\"rcount: \" + rcount);\n        if (rcount == 0) {\n            int vSize = ZipShort.getValue(data, offset + ivSize + 20 + erdSize);\n            this.vData = new byte[vSize - 4];\n            this.vCRC32 = new byte[4];\n            System.arraycopy(data, offset + ivSize + 22 + erdSize , this.vData, 0, vSize - 4);\n            System.arraycopy(data, offset + ivSize + 22 + erdSize + vSize - 4, vCRC32, 0, 4);\n        } else {\n            this.hashAlg = HashAlgorithm.getAlgorithmByCode(ZipShort.getValue(data, offset + ivSize + 20 + erdSize));\n            this.hashSize = ZipShort.getValue(data, offset + ivSize + 22 + erdSize);\n            int resize = ZipShort.getValue(data, offset + ivSize + 24 + erdSize);\n            this.recipientKeyHash = new byte[this.hashSize];\n            this.keyBlob = new byte[resize - this.hashSize];\n            System.arraycopy(data, offset + ivSize + 24 + erdSize, this.recipientKeyHash, 0, this.hashSize);\n            System.arraycopy(data, offset + ivSize + 24 + erdSize + this.hashSize, this.keyBlob, 0, resize - this.hashSize);\n\n            int vSize = ZipShort.getValue(data, offset + ivSize + 26 + erdSize + resize);\n            this.vData = new byte[vSize - 4];\n            this.vCRC32 = new byte[4];\n            System.arraycopy(data, offset + ivSize + 22 + erdSize + resize, this.vData, 0, vSize - 4);\n            System.arraycopy(data, offset + ivSize + 22 + erdSize + resize + vSize - 4, vCRC32, 0, 4);\n        }\n        \n        // validate values?\n    }\n\n    /**\n     * @param data\n     *            the array of bytes.\n     * @param offset\n     *            the source location in the data array.\n     * @param length\n     *            the number of bytes to use in the data array.\n     * @see ZipExtraField#parseFromLocalFileData(byte[], int, int)\n     */\n    public void parseFromLocalFileData(byte[] data, int offset, int length) {\n        byte[] tmp = new byte[length];\n        System.arraycopy(data, offset, tmp, 0, length);\n        parseFileFormat(data, offset, length);\n    }\n\n    /**\n     * @param data\n     *            the array of bytes.\n     * @param offset\n     *            the source location in the data array.\n     * @param length\n     *            the number of bytes to use in the data array.\n     * @see ZipExtraField#parseFromCentralDirectoryData(byte[], int, int)\n     */\n    public void parseFromCentralDirectoryData(byte[] data, int offset, int length) {\n        byte[] tmp = new byte[length];\n        System.arraycopy(data, offset, tmp, 0, length);\n        setCentralDirectoryData(tmp);\n        parseCentralDirectoryFormat(data, offset, length);\n    }\n}",
    "target": 1,
    "language": "java",
    "dataset": "A-Manually-Curated-Dataset-of-Vulnerability-Introducing-Commits-in-Java",
    "idx": 800090,
    "RELATED_CWE": [
      "CWE-908",
      "CWE-362",
      "CWE-667"
    ]
  },
  {
    "CWE_ID": [
      "CWE-835"
    ],
    "code": "/*\n * Licensed to the Apache Software Foundation (ASF) under one\n * or more contributor license agreements.  See the NOTICE file\n * distributed with this work for additional information\n * regarding copyright ownership.  The ASF licenses this file\n * to you under the Apache License, Version 2.0 (the\n * \"License\"); you may not use this file except in compliance\n * with the License.  You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing,\n * software distributed under the License is distributed on an\n * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n * KIND, either express or implied.  See the License for the\n * specific language governing permissions and limitations\n * under the License.\n */\npackage org.apache.commons.compress.archivers.zip;\n\n/**\n * Strong Encryption Header (0x0017).\n *\n * <p>Certificate-based encryption:</p>\n *\n * <pre>\n * Value     Size     Description\n * -----     ----     -----------\n * 0x0017    2 bytes  Tag for this \"extra\" block type\n * TSize     2 bytes  Size of data that follows\n * Format    2 bytes  Format definition for this record\n * AlgID     2 bytes  Encryption algorithm identifier\n * Bitlen    2 bytes  Bit length of encryption key (32-448 bits)\n * Flags     2 bytes  Processing flags\n * RCount    4 bytes  Number of recipients.\n * HashAlg   2 bytes  Hash algorithm identifier\n * HSize     2 bytes  Hash size\n * SRList    (var)    Simple list of recipients hashed public keys\n *\n * Flags -   This defines the processing flags.\n * </pre>\n *\n *           <ul>\n *           <li>0x0007 - reserved for future use\n *           <li>0x000F - reserved for future use\n *           <li>0x0100 - Indicates non-OAEP key wrapping was used.  If this\n *                        this field is set, the version needed to extract must\n *                        be at least 61.  This means OAEP key wrapping is not\n *                        used when generating a Master Session Key using\n *                        ErdData.\n *           <li>0x4000 - ErdData must be decrypted using 3DES-168, otherwise use the\n *                        same algorithm used for encrypting the file contents.\n *           <li>0x8000 - reserved for future use\n *           </ul>\n *\n * <pre>\n * RCount - This defines the number intended recipients whose\n *          public keys were used for encryption.  This identifies\n *          the number of elements in the SRList.\n *\n *          see also: reserved1\n *\n * HashAlg - This defines the hash algorithm used to calculate\n *           the public key hash of each public key used\n *           for encryption. This field currently supports\n *           only the following value for SHA-1\n *\n *           0x8004 - SHA1\n *\n * HSize -   This defines the size of a hashed public key.\n *\n * SRList -  This is a variable length list of the hashed\n *           public keys for each intended recipient.  Each\n *           element in this list is HSize.  The total size of\n *           SRList is determined using RCount * HSize.\n * </pre>\n *\n * <p>Password-based Extra Field 0x0017 in central header only.</p>\n *\n * <pre>\n * Value     Size     Description\n * -----     ----     -----------\n * 0x0017    2 bytes  Tag for this \"extra\" block type\n * TSize     2 bytes  Size of data that follows\n * Format    2 bytes  Format definition for this record\n * AlgID     2 bytes  Encryption algorithm identifier\n * Bitlen    2 bytes  Bit length of encryption key (32-448 bits)\n * Flags     2 bytes  Processing flags\n * (more?)\n * </pre>\n *\n * <p><b>Format</b> - the data format identifier for this record. The only value\n * allowed at this time is the integer value 2.</p>\n *\n * <p>Password-based Extra Field 0x0017 preceding compressed file data.</p>\n *\n * <pre>\n * Value     Size     Description\n * -----     ----     -----------\n * 0x0017    2 bytes  Tag for this \"extra\" block type\n * IVSize    2 bytes  Size of initialization vector (IV)\n * IVData    IVSize   Initialization vector for this file\n * Size      4 bytes  Size of remaining decryption header data\n * Format    2 bytes  Format definition for this record\n * AlgID     2 bytes  Encryption algorithm identifier\n * Bitlen    2 bytes  Bit length of encryption key (32-448 bits)\n * Flags     2 bytes  Processing flags\n * ErdSize   2 bytes  Size of Encrypted Random Data\n * ErdData   ErdSize  Encrypted Random Data\n * Reserved1 4 bytes  Reserved certificate processing data\n * Reserved2 (var)    Reserved for certificate processing data\n * VSize     2 bytes  Size of password validation data\n * VData     VSize-4  Password validation data\n * VCRC32    4 bytes  Standard ZIP CRC32 of password validation data\n *\n * IVData - The size of the IV should match the algorithm block size.\n *          The IVData can be completely random data.  If the size of\n *          the randomly generated data does not match the block size\n *          it should be complemented with zero's or truncated as\n *          necessary.  If IVSize is 0,then IV = CRC32 + Uncompressed\n *          File Size (as a 64 bit little-endian, unsigned integer value).\n *\n * Format -  the data format identifier for this record.  The only\n *           value allowed at this time is the integer value 2.\n *\n * ErdData - Encrypted random data is used to store random data that\n *           is used to generate a file session key for encrypting\n *           each file.  SHA1 is used to calculate hash data used to\n *           derive keys.  File session keys are derived from a master\n *           session key generated from the user-supplied password.\n *           If the Flags field in the decryption header contains\n *           the value 0x4000, then the ErdData field must be\n *           decrypted using 3DES. If the value 0x4000 is not set,\n *           then the ErdData field must be decrypted using AlgId.\n *\n * Reserved1 - Reserved for certificate processing, if value is\n *           zero, then Reserved2 data is absent.  See the explanation\n *           under the Certificate Processing Method for details on\n *           this data structure.\n *\n * Reserved2 - If present, the size of the Reserved2 data structure\n *           is located by skipping the first 4 bytes of this field\n *           and using the next 2 bytes as the remaining size.  See\n *           the explanation under the Certificate Processing Method\n *           for details on this data structure.\n *\n * VSize - This size value will always include the 4 bytes of the\n *         VCRC32 data and will be greater than 4 bytes.\n *\n * VData - Random data for password validation.  This data is VSize\n *         in length and VSize must be a multiple of the encryption\n *         block size.  VCRC32 is a checksum value of VData.\n *         VData and VCRC32 are stored encrypted and start the\n *         stream of encrypted data for a file.\n * </pre>\n *\n * <p>Reserved1 - Certificate Decryption Header Reserved1 Data:</p>\n *\n * <pre>\n * Value     Size     Description\n * -----     ----     -----------\n * RCount    4 bytes  Number of recipients.\n * </pre>\n *\n * <p>RCount - This defines the number intended recipients whose public keys were\n * used for encryption. This defines the number of elements in the REList field\n * defined below.</p>\n *\n * <p>Reserved2 - Certificate Decryption Header Reserved2 Data Structures:</p>\n *\n * <pre>\n * Value     Size     Description\n * -----     ----     -----------\n * HashAlg   2 bytes  Hash algorithm identifier\n * HSize     2 bytes  Hash size\n * REList    (var)    List of recipient data elements\n *\n * HashAlg - This defines the hash algorithm used to calculate\n *           the public key hash of each public key used\n *           for encryption. This field currently supports\n *           only the following value for SHA-1\n *\n *               0x8004 - SHA1\n *\n * HSize -   This defines the size of a hashed public key\n *           defined in REHData.\n *\n * REList -  This is a variable length of list of recipient data.\n *           Each element in this list consists of a Recipient\n *           Element data structure as follows:\n * </pre>\n *\n * <p>Recipient Element (REList) Data Structure:</p>\n *\n * <pre>\n * Value     Size     Description\n * -----     ----     -----------\n * RESize    2 bytes  Size of REHData + REKData\n * REHData   HSize    Hash of recipients public key\n * REKData   (var)    Simple key blob\n *\n *\n * RESize -  This defines the size of an individual REList\n *           element.  This value is the combined size of the\n *           REHData field + REKData field.  REHData is defined by\n *           HSize.  REKData is variable and can be calculated\n *           for each REList element using RESize and HSize.\n *\n * REHData - Hashed public key for this recipient.\n *\n * REKData - Simple Key Blob.  The format of this data structure\n *           is identical to that defined in the Microsoft\n *           CryptoAPI and generated using the CryptExportKey()\n *           function.  The version of the Simple Key Blob\n *           supported at this time is 0x02 as defined by\n *           Microsoft.\n *\n *           For more details see https://msdn.microsoft.com/en-us/library/aa920051.aspx\n * </pre>\n *\n * <p><b>Flags</b> - Processing flags needed for decryption</p>\n *\n * <ul>\n * <li>0x0001 - Password is required to decrypt</li>\n * <li>0x0002 - Certificates only</li>\n * <li>0x0003 - Password or certificate required to decrypt</li>\n * <li>0x0007 - reserved for future use\n * <li>0x000F - reserved for future use\n * <li>0x0100 - indicates non-OAEP key wrapping was used. If this field is set\n * the version needed to extract must be at least 61. This means OAEP key\n * wrapping is not used when generating a Master Session Key using ErdData.\n * <li>0x4000 - ErdData must be decrypted using 3DES-168, otherwise use the same\n * algorithm used for encrypting the file contents.\n * <li>0x8000 - reserved for future use.\n * </ul>\n *\n * <p><b>See the section describing the Strong Encryption Specification for\n * details. Refer to the section in this document entitled\n * \"Incorporating PKWARE Proprietary Technology into Your Product\" for more\n * information.</b></p>\n *\n * @NotThreadSafe\n * @since 1.11\n */\npublic class X0017_StrongEncryptionHeader extends PKWareExtraHeader {\n\n    public X0017_StrongEncryptionHeader() {\n        super(new ZipShort(0x0017));\n    }\n\n    private int format; // TODO written but not read\n    private EncryptionAlgorithm algId;\n    private int bitlen; // TODO written but not read\n    private int flags; // TODO written but not read\n    private long rcount;\n    private HashAlgorithm hashAlg;\n    private int hashSize;\n\n    // encryption data\n    private byte ivData[];\n    private byte erdData[];\n\n    // encryption key\n    private byte recipientKeyHash[];\n    private byte keyBlob[];\n\n    // password verification data\n    private byte vData[];\n    private byte vCRC32[];\n\n    /**\n     * Get record count.\n     * @return the record count\n     */\n    public long getRecordCount() {\n        return rcount;\n    }\n\n    /**\n     * Get hash algorithm.\n     * @return the hash algorithm\n     */\n    public HashAlgorithm getHashAlgorithm() {\n        return hashAlg;\n    }\n\n    /**\n     * Get encryption algorithm.\n     * @return the encryption algorithm\n     */\n    public EncryptionAlgorithm getEncryptionAlgorithm() {\n        return algId;\n    }\n\n    /**\n     * Parse central directory format.\n     *\n     * @param data the buffer to read data from\n     * @param offset offset into buffer to read data\n     * @param length the length of data\n     */\n    public void parseCentralDirectoryFormat(final byte[] data, final int offset, final int length) {\n        this.format = ZipShort.getValue(data, offset);\n        this.algId = EncryptionAlgorithm.getAlgorithmByCode(ZipShort.getValue(data, offset + 2));\n        this.bitlen = ZipShort.getValue(data, offset + 4);\n        this.flags = ZipShort.getValue(data, offset + 6);\n        this.rcount = ZipLong.getValue(data, offset + 8);\n\n        if (rcount > 0) {\n            this.hashAlg = HashAlgorithm.getAlgorithmByCode(ZipShort.getValue(data, offset + 12));\n            this.hashSize = ZipShort.getValue(data, offset + 14);\n            // srlist... hashed public keys\n            for (long i = 0; i < this.rcount; i++) {\n                for (int j = 0; j < this.hashSize; j++) {\n                    //  ZipUtil.signedByteToUnsignedInt(data[offset + 16 + (i * this.hashSize) + j]));\n                }\n            }\n        }\n    }\n\n    /**\n     * Parse file header format.\n     *\n     * <p>(Password only?)</p>\n     *\n     * @param data the buffer to read data from\n     * @param offset offset into buffer to read data\n     * @param length the length of data\n     */\n    public void parseFileFormat(final byte[] data, final int offset, final int length) {\n        final int ivSize = ZipShort.getValue(data, offset);\n        this.ivData = new byte[ivSize];\n        System.arraycopy(data, offset + 4, this.ivData, 0, ivSize);\n\n        this.format = ZipShort.getValue(data, offset + ivSize + 6);\n        this.algId = EncryptionAlgorithm.getAlgorithmByCode(ZipShort.getValue(data, offset + ivSize + 8));\n        this.bitlen = ZipShort.getValue(data, offset + ivSize + 10);\n        this.flags = ZipShort.getValue(data, offset + ivSize + 12);\n\n        final int erdSize = ZipShort.getValue(data, offset + ivSize + 14);\n        this.erdData = new byte[erdSize];\n        System.arraycopy(data, offset + ivSize + 16, this.erdData, 0, erdSize);\n\n        this.rcount = ZipLong.getValue(data, offset + ivSize + 16 + erdSize);\n        System.out.println(\"rcount: \" + rcount);\n        if (rcount == 0) {\n            final int vSize = ZipShort.getValue(data, offset + ivSize + 20 + erdSize);\n            this.vData = new byte[vSize - 4];\n            this.vCRC32 = new byte[4];\n            System.arraycopy(data, offset + ivSize + 22 + erdSize , this.vData, 0, vSize - 4);\n            System.arraycopy(data, offset + ivSize + 22 + erdSize + vSize - 4, vCRC32, 0, 4);\n        } else {\n            this.hashAlg = HashAlgorithm.getAlgorithmByCode(ZipShort.getValue(data, offset + ivSize + 20 + erdSize));\n            this.hashSize = ZipShort.getValue(data, offset + ivSize + 22 + erdSize);\n            final int resize = ZipShort.getValue(data, offset + ivSize + 24 + erdSize);\n            this.recipientKeyHash = new byte[this.hashSize];\n            this.keyBlob = new byte[resize - this.hashSize];\n            System.arraycopy(data, offset + ivSize + 24 + erdSize, this.recipientKeyHash, 0, this.hashSize);\n            System.arraycopy(data, offset + ivSize + 24 + erdSize + this.hashSize, this.keyBlob, 0, resize - this.hashSize);\n\n            final int vSize = ZipShort.getValue(data, offset + ivSize + 26 + erdSize + resize);\n            this.vData = new byte[vSize - 4];\n            this.vCRC32 = new byte[4];\n            System.arraycopy(data, offset + ivSize + 22 + erdSize + resize, this.vData, 0, vSize - 4);\n            System.arraycopy(data, offset + ivSize + 22 + erdSize + resize + vSize - 4, vCRC32, 0, 4);\n        }\n\n        // validate values?\n    }\n\n    @Override\n    public void parseFromLocalFileData(final byte[] data, final int offset, final int length) {\n        super.parseFromLocalFileData(data, offset, length);\n        parseFileFormat(data, offset, length);\n    }\n\n    @Override\n    public void parseFromCentralDirectoryData(final byte[] data, final int offset, final int length) {\n        super.parseFromCentralDirectoryData(data, offset, length);\n        parseCentralDirectoryFormat(data, offset, length);\n    }\n}",
    "target": 0,
    "language": "java",
    "dataset": "A-Manually-Curated-Dataset-of-Vulnerability-Introducing-Commits-in-Java",
    "idx": 800091,
    "RELATED_CWE": [
      "CWE-908",
      "CWE-362",
      "CWE-667"
    ]
  },
  {
    "CWE_ID": [
      "CWE-835"
    ],
    "code": "/*\n * Licensed to the Apache Software Foundation (ASF) under one\n * or more contributor license agreements.  See the NOTICE file\n * distributed with this work for additional information\n * regarding copyright ownership.  The ASF licenses this file\n * to you under the Apache License, Version 2.0 (the\n * \"License\"); you may not use this file except in compliance\n * with the License.  You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing,\n * software distributed under the License is distributed on an\n * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n * KIND, either express or implied.  See the License for the\n * specific language governing permissions and limitations\n * under the License.\n */\npackage org.apache.commons.compress.archivers.zip;\n\n/**\n * Strong Encryption Header (0x0017).\n *\n * <p>Certificate-based encryption:</p>\n *\n * <pre>\n * Value     Size     Description\n * -----     ----     -----------\n * 0x0017    2 bytes  Tag for this \"extra\" block type\n * TSize     2 bytes  Size of data that follows\n * Format    2 bytes  Format definition for this record\n * AlgID     2 bytes  Encryption algorithm identifier\n * Bitlen    2 bytes  Bit length of encryption key (32-448 bits)\n * Flags     2 bytes  Processing flags\n * RCount    4 bytes  Number of recipients.\n * HashAlg   2 bytes  Hash algorithm identifier\n * HSize     2 bytes  Hash size\n * SRList    (var)    Simple list of recipients hashed public keys\n *\n * Flags -   This defines the processing flags.\n * </pre>\n *\n *           <ul>\n *           <li>0x0007 - reserved for future use\n *           <li>0x000F - reserved for future use\n *           <li>0x0100 - Indicates non-OAEP key wrapping was used.  If this\n *                        this field is set, the version needed to extract must\n *                        be at least 61.  This means OAEP key wrapping is not\n *                        used when generating a Master Session Key using\n *                        ErdData.\n *           <li>0x4000 - ErdData must be decrypted using 3DES-168, otherwise use the\n *                        same algorithm used for encrypting the file contents.\n *           <li>0x8000 - reserved for future use\n *           </ul>\n *\n * <pre>\n * RCount - This defines the number intended recipients whose\n *          public keys were used for encryption.  This identifies\n *          the number of elements in the SRList.\n *\n *          see also: reserved1\n *\n * HashAlg - This defines the hash algorithm used to calculate\n *           the public key hash of each public key used\n *           for encryption. This field currently supports\n *           only the following value for SHA-1\n *\n *           0x8004 - SHA1\n *\n * HSize -   This defines the size of a hashed public key.\n *\n * SRList -  This is a variable length list of the hashed\n *           public keys for each intended recipient.  Each\n *           element in this list is HSize.  The total size of\n *           SRList is determined using RCount * HSize.\n * </pre>\n *\n * <p>Password-based Extra Field 0x0017 in central header only.</p>\n *\n * <pre>\n * Value     Size     Description\n * -----     ----     -----------\n * 0x0017    2 bytes  Tag for this \"extra\" block type\n * TSize     2 bytes  Size of data that follows\n * Format    2 bytes  Format definition for this record\n * AlgID     2 bytes  Encryption algorithm identifier\n * Bitlen    2 bytes  Bit length of encryption key (32-448 bits)\n * Flags     2 bytes  Processing flags\n * (more?)\n * </pre>\n *\n * <p><b>Format</b> - the data format identifier for this record. The only value\n * allowed at this time is the integer value 2.</p>\n *\n * <p>Password-based Extra Field 0x0017 preceding compressed file data.</p>\n *\n * <pre>\n * Value     Size     Description\n * -----     ----     -----------\n * 0x0017    2 bytes  Tag for this \"extra\" block type\n * IVSize    2 bytes  Size of initialization vector (IV)\n * IVData    IVSize   Initialization vector for this file\n * Size      4 bytes  Size of remaining decryption header data\n * Format    2 bytes  Format definition for this record\n * AlgID     2 bytes  Encryption algorithm identifier\n * Bitlen    2 bytes  Bit length of encryption key (32-448 bits)\n * Flags     2 bytes  Processing flags\n * ErdSize   2 bytes  Size of Encrypted Random Data\n * ErdData   ErdSize  Encrypted Random Data\n * Reserved1 4 bytes  Reserved certificate processing data\n * Reserved2 (var)    Reserved for certificate processing data\n * VSize     2 bytes  Size of password validation data\n * VData     VSize-4  Password validation data\n * VCRC32    4 bytes  Standard ZIP CRC32 of password validation data\n *\n * IVData - The size of the IV should match the algorithm block size.\n *          The IVData can be completely random data.  If the size of\n *          the randomly generated data does not match the block size\n *          it should be complemented with zero's or truncated as\n *          necessary.  If IVSize is 0,then IV = CRC32 + Uncompressed\n *          File Size (as a 64 bit little-endian, unsigned integer value).\n *\n * Format -  the data format identifier for this record.  The only\n *           value allowed at this time is the integer value 2.\n *\n * ErdData - Encrypted random data is used to store random data that\n *           is used to generate a file session key for encrypting\n *           each file.  SHA1 is used to calculate hash data used to\n *           derive keys.  File session keys are derived from a master\n *           session key generated from the user-supplied password.\n *           If the Flags field in the decryption header contains\n *           the value 0x4000, then the ErdData field must be\n *           decrypted using 3DES. If the value 0x4000 is not set,\n *           then the ErdData field must be decrypted using AlgId.\n *\n * Reserved1 - Reserved for certificate processing, if value is\n *           zero, then Reserved2 data is absent.  See the explanation\n *           under the Certificate Processing Method for details on\n *           this data structure.\n *\n * Reserved2 - If present, the size of the Reserved2 data structure\n *           is located by skipping the first 4 bytes of this field\n *           and using the next 2 bytes as the remaining size.  See\n *           the explanation under the Certificate Processing Method\n *           for details on this data structure.\n *\n * VSize - This size value will always include the 4 bytes of the\n *         VCRC32 data and will be greater than 4 bytes.\n *\n * VData - Random data for password validation.  This data is VSize\n *         in length and VSize must be a multiple of the encryption\n *         block size.  VCRC32 is a checksum value of VData.\n *         VData and VCRC32 are stored encrypted and start the\n *         stream of encrypted data for a file.\n * </pre>\n *\n * <p>Reserved1 - Certificate Decryption Header Reserved1 Data:</p>\n *\n * <pre>\n * Value     Size     Description\n * -----     ----     -----------\n * RCount    4 bytes  Number of recipients.\n * </pre>\n *\n * <p>RCount - This defines the number intended recipients whose public keys were\n * used for encryption. This defines the number of elements in the REList field\n * defined below.</p>\n *\n * <p>Reserved2 - Certificate Decryption Header Reserved2 Data Structures:</p>\n *\n * <pre>\n * Value     Size     Description\n * -----     ----     -----------\n * HashAlg   2 bytes  Hash algorithm identifier\n * HSize     2 bytes  Hash size\n * REList    (var)    List of recipient data elements\n *\n * HashAlg - This defines the hash algorithm used to calculate\n *           the public key hash of each public key used\n *           for encryption. This field currently supports\n *           only the following value for SHA-1\n *\n *               0x8004 - SHA1\n *\n * HSize -   This defines the size of a hashed public key\n *           defined in REHData.\n *\n * REList -  This is a variable length of list of recipient data.\n *           Each element in this list consists of a Recipient\n *           Element data structure as follows:\n * </pre>\n *\n * <p>Recipient Element (REList) Data Structure:</p>\n *\n * <pre>\n * Value     Size     Description\n * -----     ----     -----------\n * RESize    2 bytes  Size of REHData + REKData\n * REHData   HSize    Hash of recipients public key\n * REKData   (var)    Simple key blob\n *\n *\n * RESize -  This defines the size of an individual REList\n *           element.  This value is the combined size of the\n *           REHData field + REKData field.  REHData is defined by\n *           HSize.  REKData is variable and can be calculated\n *           for each REList element using RESize and HSize.\n *\n * REHData - Hashed public key for this recipient.\n *\n * REKData - Simple Key Blob.  The format of this data structure\n *           is identical to that defined in the Microsoft\n *           CryptoAPI and generated using the CryptExportKey()\n *           function.  The version of the Simple Key Blob\n *           supported at this time is 0x02 as defined by\n *           Microsoft.\n *\n *           For more details see https://msdn.microsoft.com/en-us/library/aa920051.aspx\n * </pre>\n *\n * <p><b>Flags</b> - Processing flags needed for decryption</p>\n *\n * <ul>\n * <li>0x0001 - Password is required to decrypt</li>\n * <li>0x0002 - Certificates only</li>\n * <li>0x0003 - Password or certificate required to decrypt</li>\n * <li>0x0007 - reserved for future use\n * <li>0x000F - reserved for future use\n * <li>0x0100 - indicates non-OAEP key wrapping was used. If this field is set\n * the version needed to extract must be at least 61. This means OAEP key\n * wrapping is not used when generating a Master Session Key using ErdData.\n * <li>0x4000 - ErdData must be decrypted using 3DES-168, otherwise use the same\n * algorithm used for encrypting the file contents.\n * <li>0x8000 - reserved for future use.\n * </ul>\n *\n * <p><b>See the section describing the Strong Encryption Specification for\n * details. Refer to the section in this document entitled\n * \"Incorporating PKWARE Proprietary Technology into Your Product\" for more\n * information.</b></p>\n *\n * @NotThreadSafe\n * @since 1.11\n */\npublic class X0017_StrongEncryptionHeader extends PKWareExtraHeader {\n\n    public X0017_StrongEncryptionHeader() {\n        super(new ZipShort(0x0017));\n    }\n\n    private int format; // TODO written but not read\n    private EncryptionAlgorithm algId;\n    private int bitlen; // TODO written but not read\n    private int flags; // TODO written but not read\n    private long rcount;\n    private HashAlgorithm hashAlg;\n    private int hashSize;\n\n    // encryption data\n    private byte ivData[];\n    private byte erdData[];\n\n    // encryption key\n    private byte recipientKeyHash[];\n    private byte keyBlob[];\n\n    // password verification data\n    private byte vData[];\n    private byte vCRC32[];\n\n    /**\n     * Get record count.\n     * @return the record count\n     */\n    public long getRecordCount() {\n        return rcount;\n    }\n\n    /**\n     * Get hash algorithm.\n     * @return the hash algorithm\n     */\n    public HashAlgorithm getHashAlgorithm() {\n        return hashAlg;\n    }\n\n    /**\n     * Get encryption algorithm.\n     * @return the encryption algorithm\n     */\n    public EncryptionAlgorithm getEncryptionAlgorithm() {\n        return algId;\n    }\n\n    /**\n     * Parse central directory format.\n     *\n     * @param data the buffer to read data from\n     * @param offset offset into buffer to read data\n     * @param length the length of data\n     */\n    public void parseCentralDirectoryFormat(final byte[] data, final int offset, final int length) {\n        this.format = ZipShort.getValue(data, offset);\n        this.algId = EncryptionAlgorithm.getAlgorithmByCode(ZipShort.getValue(data, offset + 2));\n        this.bitlen = ZipShort.getValue(data, offset + 4);\n        this.flags = ZipShort.getValue(data, offset + 6);\n        this.rcount = ZipLong.getValue(data, offset + 8);\n\n        if (rcount > 0) {\n            this.hashAlg = HashAlgorithm.getAlgorithmByCode(ZipShort.getValue(data, offset + 12));\n            this.hashSize = ZipShort.getValue(data, offset + 14);\n            // srlist... hashed public keys\n            for (int i = 0; i < this.rcount; i++) {\n                for (int j = 0; j < this.hashSize; j++) {\n                    //  ZipUtil.signedByteToUnsignedInt(data[offset + 16 + (i * this.hashSize) + j]));\n                }\n            }\n        }\n    }\n\n    /**\n     * Parse file header format.\n     *\n     * <p>(Password only?)</p>\n     *\n     * @param data the buffer to read data from\n     * @param offset offset into buffer to read data\n     * @param length the length of data\n     */\n    public void parseFileFormat(final byte[] data, final int offset, final int length) {\n        final int ivSize = ZipShort.getValue(data, offset);\n        this.ivData = new byte[ivSize];\n        System.arraycopy(data, offset + 4, this.ivData, 0, ivSize);\n\n        this.format = ZipShort.getValue(data, offset + ivSize + 6);\n        this.algId = EncryptionAlgorithm.getAlgorithmByCode(ZipShort.getValue(data, offset + ivSize + 8));\n        this.bitlen = ZipShort.getValue(data, offset + ivSize + 10);\n        this.flags = ZipShort.getValue(data, offset + ivSize + 12);\n\n        final int erdSize = ZipShort.getValue(data, offset + ivSize + 14);\n        this.erdData = new byte[erdSize];\n        System.arraycopy(data, offset + ivSize + 16, this.erdData, 0, erdSize);\n\n        this.rcount = ZipLong.getValue(data, offset + ivSize + 16 + erdSize);\n        System.out.println(\"rcount: \" + rcount);\n        if (rcount == 0) {\n            final int vSize = ZipShort.getValue(data, offset + ivSize + 20 + erdSize);\n            this.vData = new byte[vSize - 4];\n            this.vCRC32 = new byte[4];\n            System.arraycopy(data, offset + ivSize + 22 + erdSize , this.vData, 0, vSize - 4);\n            System.arraycopy(data, offset + ivSize + 22 + erdSize + vSize - 4, vCRC32, 0, 4);\n        } else {\n            this.hashAlg = HashAlgorithm.getAlgorithmByCode(ZipShort.getValue(data, offset + ivSize + 20 + erdSize));\n            this.hashSize = ZipShort.getValue(data, offset + ivSize + 22 + erdSize);\n            final int resize = ZipShort.getValue(data, offset + ivSize + 24 + erdSize);\n            this.recipientKeyHash = new byte[this.hashSize];\n            this.keyBlob = new byte[resize - this.hashSize];\n            System.arraycopy(data, offset + ivSize + 24 + erdSize, this.recipientKeyHash, 0, this.hashSize);\n            System.arraycopy(data, offset + ivSize + 24 + erdSize + this.hashSize, this.keyBlob, 0, resize - this.hashSize);\n\n            final int vSize = ZipShort.getValue(data, offset + ivSize + 26 + erdSize + resize);\n            this.vData = new byte[vSize - 4];\n            this.vCRC32 = new byte[4];\n            System.arraycopy(data, offset + ivSize + 22 + erdSize + resize, this.vData, 0, vSize - 4);\n            System.arraycopy(data, offset + ivSize + 22 + erdSize + resize + vSize - 4, vCRC32, 0, 4);\n        }\n\n        // validate values?\n    }\n\n    @Override\n    public void parseFromLocalFileData(final byte[] data, final int offset, final int length) {\n        super.parseFromLocalFileData(data, offset, length);\n        parseFileFormat(data, offset, length);\n    }\n\n    @Override\n    public void parseFromCentralDirectoryData(final byte[] data, final int offset, final int length) {\n        super.parseFromCentralDirectoryData(data, offset, length);\n        parseCentralDirectoryFormat(data, offset, length);\n    }\n}\n",
    "target": 1,
    "language": "java",
    "dataset": "vul4j",
    "idx": 200094,
    "RELATED_CWE": [
      "CWE-908",
      "CWE-362",
      "CWE-667"
    ]
  },
  {
    "CWE_ID": [
      "CWE-835"
    ],
    "code": "/*\n * Licensed to the Apache Software Foundation (ASF) under one\n * or more contributor license agreements.  See the NOTICE file\n * distributed with this work for additional information\n * regarding copyright ownership.  The ASF licenses this file\n * to you under the Apache License, Version 2.0 (the\n * \"License\"); you may not use this file except in compliance\n * with the License.  You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing,\n * software distributed under the License is distributed on an\n * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n * KIND, either express or implied.  See the License for the\n * specific language governing permissions and limitations\n * under the License.\n */\npackage org.apache.commons.compress.archivers.zip;\n\n/**\n * Strong Encryption Header (0x0017).\n *\n * <p>Certificate-based encryption:</p>\n *\n * <pre>\n * Value     Size     Description\n * -----     ----     -----------\n * 0x0017    2 bytes  Tag for this \"extra\" block type\n * TSize     2 bytes  Size of data that follows\n * Format    2 bytes  Format definition for this record\n * AlgID     2 bytes  Encryption algorithm identifier\n * Bitlen    2 bytes  Bit length of encryption key (32-448 bits)\n * Flags     2 bytes  Processing flags\n * RCount    4 bytes  Number of recipients.\n * HashAlg   2 bytes  Hash algorithm identifier\n * HSize     2 bytes  Hash size\n * SRList    (var)    Simple list of recipients hashed public keys\n *\n * Flags -   This defines the processing flags.\n * </pre>\n *\n *           <ul>\n *           <li>0x0007 - reserved for future use\n *           <li>0x000F - reserved for future use\n *           <li>0x0100 - Indicates non-OAEP key wrapping was used.  If this\n *                        this field is set, the version needed to extract must\n *                        be at least 61.  This means OAEP key wrapping is not\n *                        used when generating a Master Session Key using\n *                        ErdData.\n *           <li>0x4000 - ErdData must be decrypted using 3DES-168, otherwise use the\n *                        same algorithm used for encrypting the file contents.\n *           <li>0x8000 - reserved for future use\n *           </ul>\n *\n * <pre>\n * RCount - This defines the number intended recipients whose\n *          public keys were used for encryption.  This identifies\n *          the number of elements in the SRList.\n *\n *          see also: reserved1\n *\n * HashAlg - This defines the hash algorithm used to calculate\n *           the public key hash of each public key used\n *           for encryption. This field currently supports\n *           only the following value for SHA-1\n *\n *           0x8004 - SHA1\n *\n * HSize -   This defines the size of a hashed public key.\n *\n * SRList -  This is a variable length list of the hashed\n *           public keys for each intended recipient.  Each\n *           element in this list is HSize.  The total size of\n *           SRList is determined using RCount * HSize.\n * </pre>\n *\n * <p>Password-based Extra Field 0x0017 in central header only.</p>\n *\n * <pre>\n * Value     Size     Description\n * -----     ----     -----------\n * 0x0017    2 bytes  Tag for this \"extra\" block type\n * TSize     2 bytes  Size of data that follows\n * Format    2 bytes  Format definition for this record\n * AlgID     2 bytes  Encryption algorithm identifier\n * Bitlen    2 bytes  Bit length of encryption key (32-448 bits)\n * Flags     2 bytes  Processing flags\n * (more?)\n * </pre>\n *\n * <p><b>Format</b> - the data format identifier for this record. The only value\n * allowed at this time is the integer value 2.</p>\n *\n * <p>Password-based Extra Field 0x0017 preceding compressed file data.</p>\n *\n * <pre>\n * Value     Size     Description\n * -----     ----     -----------\n * 0x0017    2 bytes  Tag for this \"extra\" block type\n * IVSize    2 bytes  Size of initialization vector (IV)\n * IVData    IVSize   Initialization vector for this file\n * Size      4 bytes  Size of remaining decryption header data\n * Format    2 bytes  Format definition for this record\n * AlgID     2 bytes  Encryption algorithm identifier\n * Bitlen    2 bytes  Bit length of encryption key (32-448 bits)\n * Flags     2 bytes  Processing flags\n * ErdSize   2 bytes  Size of Encrypted Random Data\n * ErdData   ErdSize  Encrypted Random Data\n * Reserved1 4 bytes  Reserved certificate processing data\n * Reserved2 (var)    Reserved for certificate processing data\n * VSize     2 bytes  Size of password validation data\n * VData     VSize-4  Password validation data\n * VCRC32    4 bytes  Standard ZIP CRC32 of password validation data\n *\n * IVData - The size of the IV should match the algorithm block size.\n *          The IVData can be completely random data.  If the size of\n *          the randomly generated data does not match the block size\n *          it should be complemented with zero's or truncated as\n *          necessary.  If IVSize is 0,then IV = CRC32 + Uncompressed\n *          File Size (as a 64 bit little-endian, unsigned integer value).\n *\n * Format -  the data format identifier for this record.  The only\n *           value allowed at this time is the integer value 2.\n *\n * ErdData - Encrypted random data is used to store random data that\n *           is used to generate a file session key for encrypting\n *           each file.  SHA1 is used to calculate hash data used to\n *           derive keys.  File session keys are derived from a master\n *           session key generated from the user-supplied password.\n *           If the Flags field in the decryption header contains\n *           the value 0x4000, then the ErdData field must be\n *           decrypted using 3DES. If the value 0x4000 is not set,\n *           then the ErdData field must be decrypted using AlgId.\n *\n * Reserved1 - Reserved for certificate processing, if value is\n *           zero, then Reserved2 data is absent.  See the explanation\n *           under the Certificate Processing Method for details on\n *           this data structure.\n *\n * Reserved2 - If present, the size of the Reserved2 data structure\n *           is located by skipping the first 4 bytes of this field\n *           and using the next 2 bytes as the remaining size.  See\n *           the explanation under the Certificate Processing Method\n *           for details on this data structure.\n *\n * VSize - This size value will always include the 4 bytes of the\n *         VCRC32 data and will be greater than 4 bytes.\n *\n * VData - Random data for password validation.  This data is VSize\n *         in length and VSize must be a multiple of the encryption\n *         block size.  VCRC32 is a checksum value of VData.\n *         VData and VCRC32 are stored encrypted and start the\n *         stream of encrypted data for a file.\n * </pre>\n *\n * <p>Reserved1 - Certificate Decryption Header Reserved1 Data:</p>\n *\n * <pre>\n * Value     Size     Description\n * -----     ----     -----------\n * RCount    4 bytes  Number of recipients.\n * </pre>\n *\n * <p>RCount - This defines the number intended recipients whose public keys were\n * used for encryption. This defines the number of elements in the REList field\n * defined below.</p>\n *\n * <p>Reserved2 - Certificate Decryption Header Reserved2 Data Structures:</p>\n *\n * <pre>\n * Value     Size     Description\n * -----     ----     -----------\n * HashAlg   2 bytes  Hash algorithm identifier\n * HSize     2 bytes  Hash size\n * REList    (var)    List of recipient data elements\n *\n * HashAlg - This defines the hash algorithm used to calculate\n *           the public key hash of each public key used\n *           for encryption. This field currently supports\n *           only the following value for SHA-1\n *\n *               0x8004 - SHA1\n *\n * HSize -   This defines the size of a hashed public key\n *           defined in REHData.\n *\n * REList -  This is a variable length of list of recipient data.\n *           Each element in this list consists of a Recipient\n *           Element data structure as follows:\n * </pre>\n *\n * <p>Recipient Element (REList) Data Structure:</p>\n *\n * <pre>\n * Value     Size     Description\n * -----     ----     -----------\n * RESize    2 bytes  Size of REHData + REKData\n * REHData   HSize    Hash of recipients public key\n * REKData   (var)    Simple key blob\n *\n *\n * RESize -  This defines the size of an individual REList\n *           element.  This value is the combined size of the\n *           REHData field + REKData field.  REHData is defined by\n *           HSize.  REKData is variable and can be calculated\n *           for each REList element using RESize and HSize.\n *\n * REHData - Hashed public key for this recipient.\n *\n * REKData - Simple Key Blob.  The format of this data structure\n *           is identical to that defined in the Microsoft\n *           CryptoAPI and generated using the CryptExportKey()\n *           function.  The version of the Simple Key Blob\n *           supported at this time is 0x02 as defined by\n *           Microsoft.\n *\n *           For more details see https://msdn.microsoft.com/en-us/library/aa920051.aspx\n * </pre>\n *\n * <p><b>Flags</b> - Processing flags needed for decryption</p>\n *\n * <ul>\n * <li>0x0001 - Password is required to decrypt</li>\n * <li>0x0002 - Certificates only</li>\n * <li>0x0003 - Password or certificate required to decrypt</li>\n * <li>0x0007 - reserved for future use\n * <li>0x000F - reserved for future use\n * <li>0x0100 - indicates non-OAEP key wrapping was used. If this field is set\n * the version needed to extract must be at least 61. This means OAEP key\n * wrapping is not used when generating a Master Session Key using ErdData.\n * <li>0x4000 - ErdData must be decrypted using 3DES-168, otherwise use the same\n * algorithm used for encrypting the file contents.\n * <li>0x8000 - reserved for future use.\n * </ul>\n *\n * <p><b>See the section describing the Strong Encryption Specification for\n * details. Refer to the section in this document entitled\n * \"Incorporating PKWARE Proprietary Technology into Your Product\" for more\n * information.</b></p>\n *\n * @NotThreadSafe\n * @since 1.11\n */\npublic class X0017_StrongEncryptionHeader extends PKWareExtraHeader {\n\n    public X0017_StrongEncryptionHeader() {\n        super(new ZipShort(0x0017));\n    }\n\n    private int format; // TODO written but not read\n    private EncryptionAlgorithm algId;\n    private int bitlen; // TODO written but not read\n    private int flags; // TODO written but not read\n    private long rcount;\n    private HashAlgorithm hashAlg;\n    private int hashSize;\n\n    // encryption data\n    private byte ivData[];\n    private byte erdData[];\n\n    // encryption key\n    private byte recipientKeyHash[];\n    private byte keyBlob[];\n\n    // password verification data\n    private byte vData[];\n    private byte vCRC32[];\n\n    /**\n     * Get record count.\n     * @return the record count\n     */\n    public long getRecordCount() {\n        return rcount;\n    }\n\n    /**\n     * Get hash algorithm.\n     * @return the hash algorithm\n     */\n    public HashAlgorithm getHashAlgorithm() {\n        return hashAlg;\n    }\n\n    /**\n     * Get encryption algorithm.\n     * @return the encryption algorithm\n     */\n    public EncryptionAlgorithm getEncryptionAlgorithm() {\n        return algId;\n    }\n\n    /**\n     * Parse central directory format.\n     *\n     * @param data the buffer to read data from\n     * @param offset offset into buffer to read data\n     * @param length the length of data\n     */\n    public void parseCentralDirectoryFormat(final byte[] data, final int offset, final int length) {\n        this.format = ZipShort.getValue(data, offset);\n        this.algId = EncryptionAlgorithm.getAlgorithmByCode(ZipShort.getValue(data, offset + 2));\n        this.bitlen = ZipShort.getValue(data, offset + 4);\n        this.flags = ZipShort.getValue(data, offset + 6);\n        this.rcount = ZipLong.getValue(data, offset + 8);\n\n        if (rcount > 0) {\n            this.hashAlg = HashAlgorithm.getAlgorithmByCode(ZipShort.getValue(data, offset + 12));\n            this.hashSize = ZipShort.getValue(data, offset + 14);\n            // srlist... hashed public keys\n            for (long i = 0; i < this.rcount; i++) {\n                for (int j = 0; j < this.hashSize; j++) {\n                    //  ZipUtil.signedByteToUnsignedInt(data[offset + 16 + (i * this.hashSize) + j]));\n                }\n            }\n        }\n    }\n\n    /**\n     * Parse file header format.\n     *\n     * <p>(Password only?)</p>\n     *\n     * @param data the buffer to read data from\n     * @param offset offset into buffer to read data\n     * @param length the length of data\n     */\n    public void parseFileFormat(final byte[] data, final int offset, final int length) {\n        final int ivSize = ZipShort.getValue(data, offset);\n        this.ivData = new byte[ivSize];\n        System.arraycopy(data, offset + 4, this.ivData, 0, ivSize);\n\n        this.format = ZipShort.getValue(data, offset + ivSize + 6);\n        this.algId = EncryptionAlgorithm.getAlgorithmByCode(ZipShort.getValue(data, offset + ivSize + 8));\n        this.bitlen = ZipShort.getValue(data, offset + ivSize + 10);\n        this.flags = ZipShort.getValue(data, offset + ivSize + 12);\n\n        final int erdSize = ZipShort.getValue(data, offset + ivSize + 14);\n        this.erdData = new byte[erdSize];\n        System.arraycopy(data, offset + ivSize + 16, this.erdData, 0, erdSize);\n\n        this.rcount = ZipLong.getValue(data, offset + ivSize + 16 + erdSize);\n        System.out.println(\"rcount: \" + rcount);\n        if (rcount == 0) {\n            final int vSize = ZipShort.getValue(data, offset + ivSize + 20 + erdSize);\n            this.vData = new byte[vSize - 4];\n            this.vCRC32 = new byte[4];\n            System.arraycopy(data, offset + ivSize + 22 + erdSize , this.vData, 0, vSize - 4);\n            System.arraycopy(data, offset + ivSize + 22 + erdSize + vSize - 4, vCRC32, 0, 4);\n        } else {\n            this.hashAlg = HashAlgorithm.getAlgorithmByCode(ZipShort.getValue(data, offset + ivSize + 20 + erdSize));\n            this.hashSize = ZipShort.getValue(data, offset + ivSize + 22 + erdSize);\n            final int resize = ZipShort.getValue(data, offset + ivSize + 24 + erdSize);\n            this.recipientKeyHash = new byte[this.hashSize];\n            this.keyBlob = new byte[resize - this.hashSize];\n            System.arraycopy(data, offset + ivSize + 24 + erdSize, this.recipientKeyHash, 0, this.hashSize);\n            System.arraycopy(data, offset + ivSize + 24 + erdSize + this.hashSize, this.keyBlob, 0, resize - this.hashSize);\n\n            final int vSize = ZipShort.getValue(data, offset + ivSize + 26 + erdSize + resize);\n            this.vData = new byte[vSize - 4];\n            this.vCRC32 = new byte[4];\n            System.arraycopy(data, offset + ivSize + 22 + erdSize + resize, this.vData, 0, vSize - 4);\n            System.arraycopy(data, offset + ivSize + 22 + erdSize + resize + vSize - 4, vCRC32, 0, 4);\n        }\n\n        // validate values?\n    }\n\n    @Override\n    public void parseFromLocalFileData(final byte[] data, final int offset, final int length) {\n        super.parseFromLocalFileData(data, offset, length);\n        parseFileFormat(data, offset, length);\n    }\n\n    @Override\n    public void parseFromCentralDirectoryData(final byte[] data, final int offset, final int length) {\n        super.parseFromCentralDirectoryData(data, offset, length);\n        parseCentralDirectoryFormat(data, offset, length);\n    }\n}\n",
    "target": 0,
    "language": "java",
    "dataset": "vul4j",
    "idx": 200095,
    "RELATED_CWE": [
      "CWE-908",
      "CWE-362",
      "CWE-667"
    ]
  },
  {
    "CWE_ID": [
      "CWE-835"
    ],
    "code": "/*\n * Licensed to the Apache Software Foundation (ASF) under one\n * or more contributor license agreements.  See the NOTICE file\n * distributed with this work for additional information\n * regarding copyright ownership.  The ASF licenses this file\n * to you under the Apache License, Version 2.0 (the\n * \"License\"); you may not use this file except in compliance\n * with the License.  You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing,\n * software distributed under the License is distributed on an\n * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n * KIND, either express or implied.  See the License for the\n * specific language governing permissions and limitations\n * under the License.\n */\npackage org.apache.commons.compress.archivers.zip;\n\nimport java.io.ByteArrayInputStream;\nimport java.io.ByteArrayOutputStream;\nimport java.io.EOFException;\nimport java.io.IOException;\nimport java.io.InputStream;\nimport java.io.PushbackInputStream;\nimport java.math.BigInteger;\nimport java.nio.ByteBuffer;\nimport java.util.Arrays;\nimport java.util.zip.CRC32;\nimport java.util.zip.DataFormatException;\nimport java.util.zip.Inflater;\nimport java.util.zip.ZipEntry;\nimport java.util.zip.ZipException;\n\nimport org.apache.commons.compress.archivers.ArchiveEntry;\nimport org.apache.commons.compress.archivers.ArchiveInputStream;\nimport org.apache.commons.compress.compressors.bzip2.BZip2CompressorInputStream;\nimport org.apache.commons.compress.compressors.deflate64.Deflate64CompressorInputStream;\nimport org.apache.commons.compress.utils.ArchiveUtils;\nimport org.apache.commons.compress.utils.IOUtils;\nimport org.apache.commons.compress.utils.InputStreamStatistics;\n\nimport static org.apache.commons.compress.archivers.zip.ZipConstants.DWORD;\nimport static org.apache.commons.compress.archivers.zip.ZipConstants.SHORT;\nimport static org.apache.commons.compress.archivers.zip.ZipConstants.WORD;\nimport static org.apache.commons.compress.archivers.zip.ZipConstants.ZIP64_MAGIC;\n\n/**\n * Implements an input stream that can read Zip archives.\n *\n * <p>As of Apache Commons Compress it transparently supports Zip64\n * extensions and thus individual entries and archives larger than 4\n * GB or with more than 65536 entries.</p>\n *\n * <p>The {@link ZipFile} class is preferred when reading from files\n * as {@link ZipArchiveInputStream} is limited by not being able to\n * read the central directory header before returning entries.  In\n * particular {@link ZipArchiveInputStream}</p>\n *\n * <ul>\n *\n *  <li>may return entries that are not part of the central directory\n *  at all and shouldn't be considered part of the archive.</li>\n *\n *  <li>may return several entries with the same name.</li>\n *\n *  <li>will not return internal or external attributes.</li>\n *\n *  <li>may return incomplete extra field data.</li>\n *\n *  <li>may return unknown sizes and CRC values for entries until the\n *  next entry has been reached if the archive uses the data\n *  descriptor feature.</li>\n *\n * </ul>\n *\n * @see ZipFile\n * @NotThreadSafe\n */\npublic class ZipArchiveInputStream extends ArchiveInputStream implements InputStreamStatistics {\n\n    /** The zip encoding to use for filenames and the file comment. */\n    private final ZipEncoding zipEncoding;\n\n    // the provided encoding (for unit tests)\n    final String encoding;\n\n    /** Whether to look for and use Unicode extra fields. */\n    private final boolean useUnicodeExtraFields;\n\n    /** Wrapped stream, will always be a PushbackInputStream. */\n    private final InputStream in;\n\n    /** Inflater used for all deflated entries. */\n    private final Inflater inf = new Inflater(true);\n\n    /** Buffer used to read from the wrapped stream. */\n    private final ByteBuffer buf = ByteBuffer.allocate(ZipArchiveOutputStream.BUFFER_SIZE);\n\n    /** The entry that is currently being read. */\n    private CurrentEntry current = null;\n\n    /** Whether the stream has been closed. */\n    private boolean closed = false;\n\n    /** Whether the stream has reached the central directory - and thus found all entries. */\n    private boolean hitCentralDirectory = false;\n\n    /**\n     * When reading a stored entry that uses the data descriptor this\n     * stream has to read the full entry and caches it.  This is the\n     * cache.\n     */\n    private ByteArrayInputStream lastStoredEntry = null;\n\n    /** Whether the stream will try to read STORED entries that use a data descriptor. */\n    private boolean allowStoredEntriesWithDataDescriptor = false;\n\n    /** Count decompressed bytes for current entry */\n    private long uncompressedCount = 0;\n\n    private static final int LFH_LEN = 30;\n    /*\n      local file header signature     WORD\n      version needed to extract       SHORT\n      general purpose bit flag        SHORT\n      compression method              SHORT\n      last mod file time              SHORT\n      last mod file date              SHORT\n      crc-32                          WORD\n      compressed size                 WORD\n      uncompressed size               WORD\n      file name length                SHORT\n      extra field length              SHORT\n    */\n\n    private static final int CFH_LEN = 46;\n    /*\n        central file header signature   WORD\n        version made by                 SHORT\n        version needed to extract       SHORT\n        general purpose bit flag        SHORT\n        compression method              SHORT\n        last mod file time              SHORT\n        last mod file date              SHORT\n        crc-32                          WORD\n        compressed size                 WORD\n        uncompressed size               WORD\n        file name length                SHORT\n        extra field length              SHORT\n        file comment length             SHORT\n        disk number start               SHORT\n        internal file attributes        SHORT\n        external file attributes        WORD\n        relative offset of local header WORD\n    */\n\n    private static final long TWO_EXP_32 = ZIP64_MAGIC + 1;\n\n    // cached buffers - must only be used locally in the class (COMPRESS-172 - reduce garbage collection)\n    private final byte[] lfhBuf = new byte[LFH_LEN];\n    private final byte[] skipBuf = new byte[1024];\n    private final byte[] shortBuf = new byte[SHORT];\n    private final byte[] wordBuf = new byte[WORD];\n    private final byte[] twoDwordBuf = new byte[2 * DWORD];\n\n    private int entriesRead = 0;\n\n    /**\n     * Create an instance using UTF-8 encoding\n     * @param inputStream the stream to wrap\n     */\n    public ZipArchiveInputStream(final InputStream inputStream) {\n        this(inputStream, ZipEncodingHelper.UTF8);\n    }\n\n    /**\n     * Create an instance using the specified encoding\n     * @param inputStream the stream to wrap\n     * @param encoding the encoding to use for file names, use null\n     * for the platform's default encoding\n     * @since 1.5\n     */\n    public ZipArchiveInputStream(final InputStream inputStream, final String encoding) {\n        this(inputStream, encoding, true);\n    }\n\n    /**\n     * Create an instance using the specified encoding\n     * @param inputStream the stream to wrap\n     * @param encoding the encoding to use for file names, use null\n     * for the platform's default encoding\n     * @param useUnicodeExtraFields whether to use InfoZIP Unicode\n     * Extra Fields (if present) to set the file names.\n     */\n    public ZipArchiveInputStream(final InputStream inputStream, final String encoding, final boolean useUnicodeExtraFields) {\n        this(inputStream, encoding, useUnicodeExtraFields, false);\n    }\n\n    /**\n     * Create an instance using the specified encoding\n     * @param inputStream the stream to wrap\n     * @param encoding the encoding to use for file names, use null\n     * for the platform's default encoding\n     * @param useUnicodeExtraFields whether to use InfoZIP Unicode\n     * Extra Fields (if present) to set the file names.\n     * @param allowStoredEntriesWithDataDescriptor whether the stream\n     * will try to read STORED entries that use a data descriptor\n     * @since 1.1\n     */\n    public ZipArchiveInputStream(final InputStream inputStream,\n                                 final String encoding,\n                                 final boolean useUnicodeExtraFields,\n                                 final boolean allowStoredEntriesWithDataDescriptor) {\n        this.encoding = encoding;\n        zipEncoding = ZipEncodingHelper.getZipEncoding(encoding);\n        this.useUnicodeExtraFields = useUnicodeExtraFields;\n        in = new PushbackInputStream(inputStream, buf.capacity());\n        this.allowStoredEntriesWithDataDescriptor =\n            allowStoredEntriesWithDataDescriptor;\n        // haven't read anything so far\n        buf.limit(0);\n    }\n\n    public ZipArchiveEntry getNextZipEntry() throws IOException {\n        uncompressedCount = 0;\n\n        boolean firstEntry = true;\n        if (closed || hitCentralDirectory) {\n            return null;\n        }\n        if (current != null) {\n            closeEntry();\n            firstEntry = false;\n        }\n\n        long currentHeaderOffset = getBytesRead();\n        try {\n            if (firstEntry) {\n                // split archives have a special signature before the\n                // first local file header - look for it and fail with\n                // the appropriate error message if this is a split\n                // archive.\n                readFirstLocalFileHeader(lfhBuf);\n            } else {\n                readFully(lfhBuf);\n            }\n        } catch (final EOFException e) {\n            return null;\n        }\n\n        final ZipLong sig = new ZipLong(lfhBuf);\n        if (!sig.equals(ZipLong.LFH_SIG)) {\n            if (sig.equals(ZipLong.CFH_SIG) || sig.equals(ZipLong.AED_SIG) || isApkSigningBlock(lfhBuf)) {\n                hitCentralDirectory = true;\n                skipRemainderOfArchive();\n                return null;\n            }\n            throw new ZipException(String.format(\"Unexpected record signature: 0X%X\", sig.getValue()));\n        }\n\n        int off = WORD;\n        current = new CurrentEntry();\n\n        final int versionMadeBy = ZipShort.getValue(lfhBuf, off);\n        off += SHORT;\n        current.entry.setPlatform((versionMadeBy >> ZipFile.BYTE_SHIFT) & ZipFile.NIBLET_MASK);\n\n        final GeneralPurposeBit gpFlag = GeneralPurposeBit.parse(lfhBuf, off);\n        final boolean hasUTF8Flag = gpFlag.usesUTF8ForNames();\n        final ZipEncoding entryEncoding = hasUTF8Flag ? ZipEncodingHelper.UTF8_ZIP_ENCODING : zipEncoding;\n        current.hasDataDescriptor = gpFlag.usesDataDescriptor();\n        current.entry.setGeneralPurposeBit(gpFlag);\n\n        off += SHORT;\n\n        current.entry.setMethod(ZipShort.getValue(lfhBuf, off));\n        off += SHORT;\n\n        final long time = ZipUtil.dosToJavaTime(ZipLong.getValue(lfhBuf, off));\n        current.entry.setTime(time);\n        off += WORD;\n\n        ZipLong size = null, cSize = null;\n        if (!current.hasDataDescriptor) {\n            current.entry.setCrc(ZipLong.getValue(lfhBuf, off));\n            off += WORD;\n\n            cSize = new ZipLong(lfhBuf, off);\n            off += WORD;\n\n            size = new ZipLong(lfhBuf, off);\n            off += WORD;\n        } else {\n            off += 3 * WORD;\n        }\n\n        final int fileNameLen = ZipShort.getValue(lfhBuf, off);\n\n        off += SHORT;\n\n        final int extraLen = ZipShort.getValue(lfhBuf, off);\n        off += SHORT; // NOSONAR - assignment as documentation\n\n        final byte[] fileName = new byte[fileNameLen];\n        readFully(fileName);\n        current.entry.setName(entryEncoding.decode(fileName), fileName);\n        if (hasUTF8Flag) {\n            current.entry.setNameSource(ZipArchiveEntry.NameSource.NAME_WITH_EFS_FLAG);\n        }\n\n        final byte[] extraData = new byte[extraLen];\n        readFully(extraData);\n        current.entry.setExtra(extraData);\n\n        if (!hasUTF8Flag && useUnicodeExtraFields) {\n            ZipUtil.setNameAndCommentFromExtraFields(current.entry, fileName, null);\n        }\n\n        processZip64Extra(size, cSize);\n\n        current.entry.setLocalHeaderOffset(currentHeaderOffset);\n        current.entry.setDataOffset(getBytesRead());\n        current.entry.setStreamContiguous(true);\n\n        ZipMethod m = ZipMethod.getMethodByCode(current.entry.getMethod());\n        if (current.entry.getCompressedSize() != ArchiveEntry.SIZE_UNKNOWN) {\n            if (ZipUtil.canHandleEntryData(current.entry) && m != ZipMethod.STORED && m != ZipMethod.DEFLATED) {\n                InputStream bis = new BoundedInputStream(in, current.entry.getCompressedSize());\n                switch (m) {\n                case UNSHRINKING:\n                    current.in = new UnshrinkingInputStream(bis);\n                    break;\n                case IMPLODING:\n                    current.in = new ExplodingInputStream(\n                        current.entry.getGeneralPurposeBit().getSlidingDictionarySize(),\n                        current.entry.getGeneralPurposeBit().getNumberOfShannonFanoTrees(),\n                        bis);\n                    break;\n                case BZIP2:\n                    current.in = new BZip2CompressorInputStream(bis);\n                    break;\n                case ENHANCED_DEFLATED:\n                    current.in = new Deflate64CompressorInputStream(bis);\n                    break;\n                default:\n                    // we should never get here as all supported methods have been covered\n                    // will cause an error when read is invoked, don't throw an exception here so people can\n                    // skip unsupported entries\n                    break;\n                }\n            }\n        } else if (m == ZipMethod.ENHANCED_DEFLATED) {\n            current.in = new Deflate64CompressorInputStream(in);\n        }\n\n        entriesRead++;\n        return current.entry;\n    }\n\n    /**\n     * Fills the given array with the first local file header and\n     * deals with splitting/spanning markers that may prefix the first\n     * LFH.\n     */\n    private void readFirstLocalFileHeader(final byte[] lfh) throws IOException {\n        readFully(lfh);\n        final ZipLong sig = new ZipLong(lfh);\n        if (sig.equals(ZipLong.DD_SIG)) {\n            throw new UnsupportedZipFeatureException(UnsupportedZipFeatureException.Feature.SPLITTING);\n        }\n\n        if (sig.equals(ZipLong.SINGLE_SEGMENT_SPLIT_MARKER)) {\n            // The archive is not really split as only one segment was\n            // needed in the end.  Just skip over the marker.\n            final byte[] missedLfhBytes = new byte[4];\n            readFully(missedLfhBytes);\n            System.arraycopy(lfh, 4, lfh, 0, LFH_LEN - 4);\n            System.arraycopy(missedLfhBytes, 0, lfh, LFH_LEN - 4, 4);\n        }\n    }\n\n    /**\n     * Records whether a Zip64 extra is present and sets the size\n     * information from it if sizes are 0xFFFFFFFF and the entry\n     * doesn't use a data descriptor.\n     */\n    private void processZip64Extra(final ZipLong size, final ZipLong cSize) {\n        final Zip64ExtendedInformationExtraField z64 =\n            (Zip64ExtendedInformationExtraField)\n            current.entry.getExtraField(Zip64ExtendedInformationExtraField.HEADER_ID);\n        current.usesZip64 = z64 != null;\n        if (!current.hasDataDescriptor) {\n            if (z64 != null // same as current.usesZip64 but avoids NPE warning\n                    && (cSize.equals(ZipLong.ZIP64_MAGIC) || size.equals(ZipLong.ZIP64_MAGIC)) ) {\n                current.entry.setCompressedSize(z64.getCompressedSize().getLongValue());\n                current.entry.setSize(z64.getSize().getLongValue());\n            } else {\n                current.entry.setCompressedSize(cSize.getValue());\n                current.entry.setSize(size.getValue());\n            }\n        }\n    }\n\n    @Override\n    public ArchiveEntry getNextEntry() throws IOException {\n        return getNextZipEntry();\n    }\n\n    /**\n     * Whether this class is able to read the given entry.\n     *\n     * <p>May return false if it is set up to use encryption or a\n     * compression method that hasn't been implemented yet.</p>\n     * @since 1.1\n     */\n    @Override\n    public boolean canReadEntryData(final ArchiveEntry ae) {\n        if (ae instanceof ZipArchiveEntry) {\n            final ZipArchiveEntry ze = (ZipArchiveEntry) ae;\n            return ZipUtil.canHandleEntryData(ze)\n                && supportsDataDescriptorFor(ze)\n                && supportsCompressedSizeFor(ze);\n        }\n        return false;\n    }\n\n    @Override\n    public int read(final byte[] buffer, final int offset, final int length) throws IOException {\n        if (closed) {\n            throw new IOException(\"The stream is closed\");\n        }\n\n        if (current == null) {\n            return -1;\n        }\n\n        // avoid int overflow, check null buffer\n        if (offset > buffer.length || length < 0 || offset < 0 || buffer.length - offset < length) {\n            throw new ArrayIndexOutOfBoundsException();\n        }\n\n        ZipUtil.checkRequestedFeatures(current.entry);\n        if (!supportsDataDescriptorFor(current.entry)) {\n            throw new UnsupportedZipFeatureException(UnsupportedZipFeatureException.Feature.DATA_DESCRIPTOR,\n                    current.entry);\n        }\n        if (!supportsCompressedSizeFor(current.entry)) {\n            throw new UnsupportedZipFeatureException(UnsupportedZipFeatureException.Feature.UNKNOWN_COMPRESSED_SIZE,\n                    current.entry);\n        }\n\n        int read;\n        if (current.entry.getMethod() == ZipArchiveOutputStream.STORED) {\n            read = readStored(buffer, offset, length);\n        } else if (current.entry.getMethod() == ZipArchiveOutputStream.DEFLATED) {\n            read = readDeflated(buffer, offset, length);\n        } else if (current.entry.getMethod() == ZipMethod.UNSHRINKING.getCode()\n                || current.entry.getMethod() == ZipMethod.IMPLODING.getCode()\n                || current.entry.getMethod() == ZipMethod.ENHANCED_DEFLATED.getCode()\n                || current.entry.getMethod() == ZipMethod.BZIP2.getCode()) {\n            read = current.in.read(buffer, offset, length);\n        } else {\n            throw new UnsupportedZipFeatureException(ZipMethod.getMethodByCode(current.entry.getMethod()),\n                    current.entry);\n        }\n\n        if (read >= 0) {\n            current.crc.update(buffer, offset, read);\n            uncompressedCount += read;\n        }\n\n        return read;\n    }\n\n    /**\n     * @since 1.17\n     */\n    @Override\n    public long getCompressedCount() {\n        if (current.entry.getMethod() == ZipArchiveOutputStream.STORED) {\n            return current.bytesRead;\n        } else if (current.entry.getMethod() == ZipArchiveOutputStream.DEFLATED) {\n            return getBytesInflated();\n        } else if (current.entry.getMethod() == ZipMethod.UNSHRINKING.getCode()) {\n            return ((UnshrinkingInputStream) current.in).getCompressedCount();\n        } else if (current.entry.getMethod() == ZipMethod.IMPLODING.getCode()) {\n            return ((ExplodingInputStream) current.in).getCompressedCount();\n        } else if (current.entry.getMethod() == ZipMethod.ENHANCED_DEFLATED.getCode()) {\n            return ((Deflate64CompressorInputStream) current.in).getCompressedCount();\n        } else if (current.entry.getMethod() == ZipMethod.BZIP2.getCode()) {\n            return ((BZip2CompressorInputStream) current.in).getCompressedCount();\n        } else {\n            return -1;\n        }\n    }\n\n    /**\n     * @since 1.17\n     */\n    @Override\n    public long getUncompressedCount() {\n        return uncompressedCount;\n    }\n\n    /**\n     * Implementation of read for STORED entries.\n     */\n    private int readStored(final byte[] buffer, final int offset, final int length) throws IOException {\n\n        if (current.hasDataDescriptor) {\n            if (lastStoredEntry == null) {\n                readStoredEntry();\n            }\n            return lastStoredEntry.read(buffer, offset, length);\n        }\n\n        final long csize = current.entry.getSize();\n        if (current.bytesRead >= csize) {\n            return -1;\n        }\n\n        if (buf.position() >= buf.limit()) {\n            buf.position(0);\n            final int l = in.read(buf.array());\n            if (l == -1) {\n                return -1;\n            }\n            buf.limit(l);\n\n            count(l);\n            current.bytesReadFromStream += l;\n        }\n\n        int toRead = Math.min(buf.remaining(), length);\n        if ((csize - current.bytesRead) < toRead) {\n            // if it is smaller than toRead then it fits into an int\n            toRead = (int) (csize - current.bytesRead);\n        }\n        buf.get(buffer, offset, toRead);\n        current.bytesRead += toRead;\n        return toRead;\n    }\n\n    /**\n     * Implementation of read for DEFLATED entries.\n     */\n    private int readDeflated(final byte[] buffer, final int offset, final int length) throws IOException {\n        final int read = readFromInflater(buffer, offset, length);\n        if (read <= 0) {\n            if (inf.finished()) {\n                return -1;\n            } else if (inf.needsDictionary()) {\n                throw new ZipException(\"This archive needs a preset dictionary\"\n                                       + \" which is not supported by Commons\"\n                                       + \" Compress.\");\n            } else if (read == -1) {\n                throw new IOException(\"Truncated ZIP file\");\n            }\n        }\n        return read;\n    }\n\n    /**\n     * Potentially reads more bytes to fill the inflater's buffer and\n     * reads from it.\n     */\n    private int readFromInflater(final byte[] buffer, final int offset, final int length) throws IOException {\n        int read = 0;\n        do {\n            if (inf.needsInput()) {\n                final int l = fill();\n                if (l > 0) {\n                    current.bytesReadFromStream += buf.limit();\n                } else if (l == -1) {\n                    return -1;\n                } else {\n                    break;\n                }\n            }\n            try {\n                read = inf.inflate(buffer, offset, length);\n            } catch (final DataFormatException e) {\n                throw (IOException) new ZipException(e.getMessage()).initCause(e);\n            }\n        } while (read == 0 && inf.needsInput());\n        return read;\n    }\n\n    @Override\n    public void close() throws IOException {\n        if (!closed) {\n            closed = true;\n            try {\n                in.close();\n            } finally {\n                inf.end();\n            }\n        }\n    }\n\n    /**\n     * Skips over and discards value bytes of data from this input\n     * stream.\n     *\n     * <p>This implementation may end up skipping over some smaller\n     * number of bytes, possibly 0, if and only if it reaches the end\n     * of the underlying stream.</p>\n     *\n     * <p>The actual number of bytes skipped is returned.</p>\n     *\n     * @param value the number of bytes to be skipped.\n     * @return the actual number of bytes skipped.\n     * @throws IOException - if an I/O error occurs.\n     * @throws IllegalArgumentException - if value is negative.\n     */\n    @Override\n    public long skip(final long value) throws IOException {\n        if (value >= 0) {\n            long skipped = 0;\n            while (skipped < value) {\n                final long rem = value - skipped;\n                final int x = read(skipBuf, 0, (int) (skipBuf.length > rem ? rem : skipBuf.length));\n                if (x == -1) {\n                    return skipped;\n                }\n                skipped += x;\n            }\n            return skipped;\n        }\n        throw new IllegalArgumentException();\n    }\n\n    /**\n     * Checks if the signature matches what is expected for a zip file.\n     * Does not currently handle self-extracting zips which may have arbitrary\n     * leading content.\n     *\n     * @param signature the bytes to check\n     * @param length    the number of bytes to check\n     * @return true, if this stream is a zip archive stream, false otherwise\n     */\n    public static boolean matches(final byte[] signature, final int length) {\n        if (length < ZipArchiveOutputStream.LFH_SIG.length) {\n            return false;\n        }\n\n        return checksig(signature, ZipArchiveOutputStream.LFH_SIG) // normal file\n            || checksig(signature, ZipArchiveOutputStream.EOCD_SIG) // empty zip\n            || checksig(signature, ZipArchiveOutputStream.DD_SIG) // split zip\n            || checksig(signature, ZipLong.SINGLE_SEGMENT_SPLIT_MARKER.getBytes());\n    }\n\n    private static boolean checksig(final byte[] signature, final byte[] expected) {\n        for (int i = 0; i < expected.length; i++) {\n            if (signature[i] != expected[i]) {\n                return false;\n            }\n        }\n        return true;\n    }\n\n    /**\n     * Closes the current ZIP archive entry and positions the underlying\n     * stream to the beginning of the next entry. All per-entry variables\n     * and data structures are cleared.\n     * <p>\n     * If the compressed size of this entry is included in the entry header,\n     * then any outstanding bytes are simply skipped from the underlying\n     * stream without uncompressing them. This allows an entry to be safely\n     * closed even if the compression method is unsupported.\n     * <p>\n     * In case we don't know the compressed size of this entry or have\n     * already buffered too much data from the underlying stream to support\n     * uncompression, then the uncompression process is completed and the\n     * end position of the stream is adjusted based on the result of that\n     * process.\n     *\n     * @throws IOException if an error occurs\n     */\n    private void closeEntry() throws IOException {\n        if (closed) {\n            throw new IOException(\"The stream is closed\");\n        }\n        if (current == null) {\n            return;\n        }\n\n        // Ensure all entry bytes are read\n        if (currentEntryHasOutstandingBytes()) {\n            drainCurrentEntryData();\n        } else {\n            // this is guaranteed to exhaust the stream\n            skip(Long.MAX_VALUE); //NOSONAR\n\n            final long inB = current.entry.getMethod() == ZipArchiveOutputStream.DEFLATED\n                       ? getBytesInflated() : current.bytesRead;\n\n            // this is at most a single read() operation and can't\n            // exceed the range of int\n            final int diff = (int) (current.bytesReadFromStream - inB);\n\n            // Pushback any required bytes\n            if (diff > 0) {\n                pushback(buf.array(), buf.limit() - diff, diff);\n                current.bytesReadFromStream -= diff;\n            }\n\n            // Drain remainder of entry if not all data bytes were required\n            if (currentEntryHasOutstandingBytes()) {\n                drainCurrentEntryData();\n            }\n        }\n\n        if (lastStoredEntry == null && current.hasDataDescriptor) {\n            readDataDescriptor();\n        }\n\n        inf.reset();\n        buf.clear().flip();\n        current = null;\n        lastStoredEntry = null;\n    }\n\n    /**\n     * If the compressed size of the current entry is included in the entry header\n     * and there are any outstanding bytes in the underlying stream, then\n     * this returns true.\n     *\n     * @return true, if current entry is determined to have outstanding bytes, false otherwise\n     */\n    private boolean currentEntryHasOutstandingBytes() {\n        return current.bytesReadFromStream <= current.entry.getCompressedSize()\n                && !current.hasDataDescriptor;\n    }\n\n    /**\n     * Read all data of the current entry from the underlying stream\n     * that hasn't been read, yet.\n     */\n    private void drainCurrentEntryData() throws IOException {\n        long remaining = current.entry.getCompressedSize() - current.bytesReadFromStream;\n        while (remaining > 0) {\n            final long n = in.read(buf.array(), 0, (int) Math.min(buf.capacity(), remaining));\n            if (n < 0) {\n                throw new EOFException(\"Truncated ZIP entry: \"\n                                       + ArchiveUtils.sanitize(current.entry.getName()));\n            }\n            count(n);\n            remaining -= n;\n        }\n    }\n\n    /**\n     * Get the number of bytes Inflater has actually processed.\n     *\n     * <p>for Java &lt; Java7 the getBytes* methods in\n     * Inflater/Deflater seem to return unsigned ints rather than\n     * longs that start over with 0 at 2^32.</p>\n     *\n     * <p>The stream knows how many bytes it has read, but not how\n     * many the Inflater actually consumed - it should be between the\n     * total number of bytes read for the entry and the total number\n     * minus the last read operation.  Here we just try to make the\n     * value close enough to the bytes we've read by assuming the\n     * number of bytes consumed must be smaller than (or equal to) the\n     * number of bytes read but not smaller by more than 2^32.</p>\n     */\n    private long getBytesInflated() {\n        long inB = inf.getBytesRead();\n        if (current.bytesReadFromStream >= TWO_EXP_32) {\n            while (inB + TWO_EXP_32 <= current.bytesReadFromStream) {\n                inB += TWO_EXP_32;\n            }\n        }\n        return inB;\n    }\n\n    private int fill() throws IOException {\n        if (closed) {\n            throw new IOException(\"The stream is closed\");\n        }\n        final int length = in.read(buf.array());\n        if (length > 0) {\n            buf.limit(length);\n            count(buf.limit());\n            inf.setInput(buf.array(), 0, buf.limit());\n        }\n        return length;\n    }\n\n    private void readFully(final byte[] b) throws IOException {\n        readFully(b, 0);\n    }\n\n    private void readFully(final byte[] b, final int off) throws IOException {\n        final int len = b.length - off;\n        final int count = IOUtils.readFully(in, b, off, len);\n        count(count);\n        if (count < len) {\n            throw new EOFException();\n        }\n    }\n\n    private void readDataDescriptor() throws IOException {\n        readFully(wordBuf);\n        ZipLong val = new ZipLong(wordBuf);\n        if (ZipLong.DD_SIG.equals(val)) {\n            // data descriptor with signature, skip sig\n            readFully(wordBuf);\n            val = new ZipLong(wordBuf);\n        }\n        current.entry.setCrc(val.getValue());\n\n        // if there is a ZIP64 extra field, sizes are eight bytes\n        // each, otherwise four bytes each.  Unfortunately some\n        // implementations - namely Java7 - use eight bytes without\n        // using a ZIP64 extra field -\n        // https://bugs.sun.com/bugdatabase/view_bug.do?bug_id=7073588\n\n        // just read 16 bytes and check whether bytes nine to twelve\n        // look like one of the signatures of what could follow a data\n        // descriptor (ignoring archive decryption headers for now).\n        // If so, push back eight bytes and assume sizes are four\n        // bytes, otherwise sizes are eight bytes each.\n        readFully(twoDwordBuf);\n        final ZipLong potentialSig = new ZipLong(twoDwordBuf, DWORD);\n        if (potentialSig.equals(ZipLong.CFH_SIG) || potentialSig.equals(ZipLong.LFH_SIG)) {\n            pushback(twoDwordBuf, DWORD, DWORD);\n            current.entry.setCompressedSize(ZipLong.getValue(twoDwordBuf));\n            current.entry.setSize(ZipLong.getValue(twoDwordBuf, WORD));\n        } else {\n            current.entry.setCompressedSize(ZipEightByteInteger.getLongValue(twoDwordBuf));\n            current.entry.setSize(ZipEightByteInteger.getLongValue(twoDwordBuf, DWORD));\n        }\n    }\n\n    /**\n     * Whether this entry requires a data descriptor this library can work with.\n     *\n     * @return true if allowStoredEntriesWithDataDescriptor is true,\n     * the entry doesn't require any data descriptor or the method is\n     * DEFLATED or ENHANCED_DEFLATED.\n     */\n    private boolean supportsDataDescriptorFor(final ZipArchiveEntry entry) {\n        return !entry.getGeneralPurposeBit().usesDataDescriptor()\n\n                || (allowStoredEntriesWithDataDescriptor && entry.getMethod() == ZipEntry.STORED)\n                || entry.getMethod() == ZipEntry.DEFLATED\n                || entry.getMethod() == ZipMethod.ENHANCED_DEFLATED.getCode();\n    }\n\n    /**\n     * Whether the compressed size for the entry is either known or\n     * not required by the compression method being used.\n     */\n    private boolean supportsCompressedSizeFor(final ZipArchiveEntry entry) {\n        return entry.getCompressedSize() != ArchiveEntry.SIZE_UNKNOWN\n            || entry.getMethod() == ZipEntry.DEFLATED\n            || entry.getMethod() == ZipMethod.ENHANCED_DEFLATED.getCode()\n            || (entry.getGeneralPurposeBit().usesDataDescriptor()\n                && allowStoredEntriesWithDataDescriptor\n                && entry.getMethod() == ZipEntry.STORED);\n    }\n\n    /**\n     * Caches a stored entry that uses the data descriptor.\n     *\n     * <ul>\n     *   <li>Reads a stored entry until the signature of a local file\n     *     header, central directory header or data descriptor has been\n     *     found.</li>\n     *   <li>Stores all entry data in lastStoredEntry.</p>\n     *   <li>Rewinds the stream to position at the data\n     *     descriptor.</li>\n     *   <li>reads the data descriptor</li>\n     * </ul>\n     *\n     * <p>After calling this method the entry should know its size,\n     * the entry's data is cached and the stream is positioned at the\n     * next local file or central directory header.</p>\n     */\n    private void readStoredEntry() throws IOException {\n        final ByteArrayOutputStream bos = new ByteArrayOutputStream();\n        int off = 0;\n        boolean done = false;\n\n        // length of DD without signature\n        final int ddLen = current.usesZip64 ? WORD + 2 * DWORD : 3 * WORD;\n\n        while (!done) {\n            final int r = in.read(buf.array(), off, ZipArchiveOutputStream.BUFFER_SIZE - off);\n            if (r <= 0) {\n                // read the whole archive without ever finding a\n                // central directory\n                throw new IOException(\"Truncated ZIP file\");\n            }\n            if (r + off < 4) {\n                // buffer too small to check for a signature, loop\n                off += r;\n                continue;\n            }\n\n            done = bufferContainsSignature(bos, off, r, ddLen);\n            if (!done) {\n                off = cacheBytesRead(bos, off, r, ddLen);\n            }\n        }\n\n        final byte[] b = bos.toByteArray();\n        lastStoredEntry = new ByteArrayInputStream(b);\n    }\n\n    private static final byte[] LFH = ZipLong.LFH_SIG.getBytes();\n    private static final byte[] CFH = ZipLong.CFH_SIG.getBytes();\n    private static final byte[] DD = ZipLong.DD_SIG.getBytes();\n\n    /**\n     * Checks whether the current buffer contains the signature of a\n     * &quot;data descriptor&quot;, &quot;local file header&quot; or\n     * &quot;central directory entry&quot;.\n     *\n     * <p>If it contains such a signature, reads the data descriptor\n     * and positions the stream right after the data descriptor.</p>\n     */\n    private boolean bufferContainsSignature(final ByteArrayOutputStream bos, final int offset, final int lastRead, final int expectedDDLen)\n            throws IOException {\n\n        boolean done = false;\n        int readTooMuch = 0;\n        for (int i = 0; !done && i < offset + lastRead - 4; i++) {\n            if (buf.array()[i] == LFH[0] && buf.array()[i + 1] == LFH[1]) {\n                if ((buf.array()[i + 2] == LFH[2] && buf.array()[i + 3] == LFH[3])\n                    || (buf.array()[i] == CFH[2] && buf.array()[i + 3] == CFH[3])) {\n                    // found a LFH or CFH:\n                    readTooMuch = offset + lastRead - i - expectedDDLen;\n                    done = true;\n                }\n                else if (buf.array()[i + 2] == DD[2] && buf.array()[i + 3] == DD[3]) {\n                    // found DD:\n                    readTooMuch = offset + lastRead - i;\n                    done = true;\n                }\n                if (done) {\n                    // * push back bytes read in excess as well as the data\n                    //   descriptor\n                    // * copy the remaining bytes to cache\n                    // * read data descriptor\n                    pushback(buf.array(), offset + lastRead - readTooMuch, readTooMuch);\n                    bos.write(buf.array(), 0, i);\n                    readDataDescriptor();\n                }\n            }\n        }\n        return done;\n    }\n\n    /**\n     * If the last read bytes could hold a data descriptor and an\n     * incomplete signature then save the last bytes to the front of\n     * the buffer and cache everything in front of the potential data\n     * descriptor into the given ByteArrayOutputStream.\n     *\n     * <p>Data descriptor plus incomplete signature (3 bytes in the\n     * worst case) can be 20 bytes max.</p>\n     */\n    private int cacheBytesRead(final ByteArrayOutputStream bos, int offset, final int lastRead, final int expecteDDLen) {\n        final int cacheable = offset + lastRead - expecteDDLen - 3;\n        if (cacheable > 0) {\n            bos.write(buf.array(), 0, cacheable);\n            System.arraycopy(buf.array(), cacheable, buf.array(), 0, expecteDDLen + 3);\n            offset = expecteDDLen + 3;\n        } else {\n            offset += lastRead;\n        }\n        return offset;\n    }\n\n    private void pushback(final byte[] buf, final int offset, final int length) throws IOException {\n        ((PushbackInputStream) in).unread(buf, offset, length);\n        pushedBackBytes(length);\n    }\n\n    // End of Central Directory Record\n    //   end of central dir signature    WORD\n    //   number of this disk             SHORT\n    //   number of the disk with the\n    //   start of the central directory  SHORT\n    //   total number of entries in the\n    //   central directory on this disk  SHORT\n    //   total number of entries in\n    //   the central directory           SHORT\n    //   size of the central directory   WORD\n    //   offset of start of central\n    //   directory with respect to\n    //   the starting disk number        WORD\n    //   .ZIP file comment length        SHORT\n    //   .ZIP file comment               up to 64KB\n    //\n\n    /**\n     * Reads the stream until it find the \"End of central directory\n     * record\" and consumes it as well.\n     */\n    private void skipRemainderOfArchive() throws IOException {\n        // skip over central directory. One LFH has been read too much\n        // already.  The calculation discounts file names and extra\n        // data so it will be too short.\n        realSkip((long) entriesRead * CFH_LEN - LFH_LEN);\n        findEocdRecord();\n        realSkip((long) ZipFile.MIN_EOCD_SIZE - WORD /* signature */ - SHORT /* comment len */);\n        readFully(shortBuf);\n        // file comment\n        realSkip(ZipShort.getValue(shortBuf));\n    }\n\n    /**\n     * Reads forward until the signature of the &quot;End of central\n     * directory&quot; record is found.\n     */\n    private void findEocdRecord() throws IOException {\n        int currentByte = -1;\n        boolean skipReadCall = false;\n        while (skipReadCall || (currentByte = readOneByte()) > -1) {\n            skipReadCall = false;\n            if (!isFirstByteOfEocdSig(currentByte)) {\n                continue;\n            }\n            currentByte = readOneByte();\n            if (currentByte != ZipArchiveOutputStream.EOCD_SIG[1]) {\n                if (currentByte == -1) {\n                    break;\n                }\n                skipReadCall = isFirstByteOfEocdSig(currentByte);\n                continue;\n            }\n            currentByte = readOneByte();\n            if (currentByte != ZipArchiveOutputStream.EOCD_SIG[2]) {\n                if (currentByte == -1) {\n                    break;\n                }\n                skipReadCall = isFirstByteOfEocdSig(currentByte);\n                continue;\n            }\n            currentByte = readOneByte();\n            if (currentByte == -1\n                || currentByte == ZipArchiveOutputStream.EOCD_SIG[3]) {\n                break;\n            }\n            skipReadCall = isFirstByteOfEocdSig(currentByte);\n        }\n    }\n\n    /**\n     * Skips bytes by reading from the underlying stream rather than\n     * the (potentially inflating) archive stream - which {@link\n     * #skip} would do.\n     *\n     * Also updates bytes-read counter.\n     */\n    private void realSkip(final long value) throws IOException {\n        if (value >= 0) {\n            long skipped = 0;\n            while (skipped < value) {\n                final long rem = value - skipped;\n                final int x = in.read(skipBuf, 0, (int) (skipBuf.length > rem ? rem : skipBuf.length));\n                if (x == -1) {\n                    return;\n                }\n                count(x);\n                skipped += x;\n            }\n            return;\n        }\n        throw new IllegalArgumentException();\n    }\n\n    /**\n     * Reads bytes by reading from the underlying stream rather than\n     * the (potentially inflating) archive stream - which {@link #read} would do.\n     *\n     * Also updates bytes-read counter.\n     */\n    private int readOneByte() throws IOException {\n        final int b = in.read();\n        if (b != -1) {\n            count(1);\n        }\n        return b;\n    }\n\n    private boolean isFirstByteOfEocdSig(final int b) {\n        return b == ZipArchiveOutputStream.EOCD_SIG[0];\n    }\n\n    private static final byte[] APK_SIGNING_BLOCK_MAGIC = new byte[] {\n        'A', 'P', 'K', ' ', 'S', 'i', 'g', ' ', 'B', 'l', 'o', 'c', 'k', ' ', '4', '2',\n    };\n    private static final BigInteger LONG_MAX = BigInteger.valueOf(Long.MAX_VALUE);\n\n    /**\n     * Checks whether this might be an APK Signing Block.\n     *\n     * <p>Unfortunately the APK signing block does not start with some kind of signature, it rather ends with one. It\n     * starts with a length, so what we do is parse the suspect length, skip ahead far enough, look for the signature\n     * and if we've found it, return true.</p>\n     *\n     * @param suspectLocalFileHeader the bytes read from the underlying stream in the expectation that they would hold\n     * the local file header of the next entry.\n     *\n     * @return true if this looks like a APK signing block\n     *\n     * @see <a href=\"https://source.android.com/security/apksigning/v2\">https://source.android.com/security/apksigning/v2</a>\n     */\n    private boolean isApkSigningBlock(byte[] suspectLocalFileHeader) throws IOException {\n        // length of block excluding the size field itself\n        BigInteger len = ZipEightByteInteger.getValue(suspectLocalFileHeader);\n        // LFH has already been read and all but the first eight bytes contain (part of) the APK signing block,\n        // also subtract 16 bytes in order to position us at the magic string\n        BigInteger toSkip = len.add(BigInteger.valueOf(DWORD - suspectLocalFileHeader.length\n            - APK_SIGNING_BLOCK_MAGIC.length));\n        byte[] magic = new byte[APK_SIGNING_BLOCK_MAGIC.length];\n\n        try {\n            if (toSkip.signum() < 0) {\n                // suspectLocalFileHeader contains the start of suspect magic string\n                int off = suspectLocalFileHeader.length + toSkip.intValue();\n                // length was shorter than magic length\n                if (off < DWORD) {\n                    return false;\n                }\n                int bytesInBuffer = Math.abs(toSkip.intValue());\n                System.arraycopy(suspectLocalFileHeader, off, magic, 0, Math.min(bytesInBuffer, magic.length));\n                if (bytesInBuffer < magic.length) {\n                    readFully(magic, bytesInBuffer);\n                }\n            } else {\n                while (toSkip.compareTo(LONG_MAX) > 0) {\n                    realSkip(Long.MAX_VALUE);\n                    toSkip = toSkip.add(LONG_MAX.negate());\n                }\n                realSkip(toSkip.longValue());\n                readFully(magic);\n            }\n        } catch (EOFException ex) {\n            // length was invalid\n            return false;\n        }\n        return Arrays.equals(magic, APK_SIGNING_BLOCK_MAGIC);\n    }\n\n    /**\n     * Structure collecting information for the entry that is\n     * currently being read.\n     */\n    private static final class CurrentEntry {\n\n        /**\n         * Current ZIP entry.\n         */\n        private final ZipArchiveEntry entry = new ZipArchiveEntry();\n\n        /**\n         * Does the entry use a data descriptor?\n         */\n        private boolean hasDataDescriptor;\n\n        /**\n         * Does the entry have a ZIP64 extended information extra field.\n         */\n        private boolean usesZip64;\n\n        /**\n         * Number of bytes of entry content read by the client if the\n         * entry is STORED.\n         */\n        private long bytesRead;\n\n        /**\n         * Number of bytes of entry content read from the stream.\n         *\n         * <p>This may be more than the actual entry's length as some\n         * stuff gets buffered up and needs to be pushed back when the\n         * end of the entry has been reached.</p>\n         */\n        private long bytesReadFromStream;\n\n        /**\n         * The checksum calculated as the current entry is read.\n         */\n        private final CRC32 crc = new CRC32();\n\n        /**\n         * The input stream decompressing the data for shrunk and imploded entries.\n         */\n        private InputStream in;\n    }\n\n    /**\n     * Bounded input stream adapted from commons-io\n     */\n    private class BoundedInputStream extends InputStream {\n\n        /** the wrapped input stream */\n        private final InputStream in;\n\n        /** the max length to provide */\n        private final long max;\n\n        /** the number of bytes already returned */\n        private long pos = 0;\n\n        /**\n         * Creates a new <code>BoundedInputStream</code> that wraps the given input\n         * stream and limits it to a certain size.\n         *\n         * @param in The wrapped input stream\n         * @param size The maximum number of bytes to return\n         */\n        public BoundedInputStream(final InputStream in, final long size) {\n            this.max = size;\n            this.in = in;\n        }\n\n        @Override\n        public int read() throws IOException {\n            if (max >= 0 && pos >= max) {\n                return -1;\n            }\n            final int result = in.read();\n            pos++;\n            count(1);\n            current.bytesReadFromStream++;\n            return result;\n        }\n\n        @Override\n        public int read(final byte[] b) throws IOException {\n            return this.read(b, 0, b.length);\n        }\n\n        @Override\n        public int read(final byte[] b, final int off, final int len) throws IOException {\n            if (max >= 0 && pos >= max) {\n                return -1;\n            }\n            final long maxRead = max >= 0 ? Math.min(len, max - pos) : len;\n            final int bytesRead = in.read(b, off, (int) maxRead);\n\n            if (bytesRead == -1) {\n                return -1;\n            }\n\n            pos += bytesRead;\n            count(bytesRead);\n            current.bytesReadFromStream += bytesRead;\n            return bytesRead;\n        }\n\n        @Override\n        public long skip(final long n) throws IOException {\n            final long toSkip = max >= 0 ? Math.min(n, max - pos) : n;\n            final long skippedBytes = IOUtils.skip(in, toSkip);\n            pos += skippedBytes;\n            return skippedBytes;\n        }\n\n        @Override\n        public int available() throws IOException {\n            if (max >= 0 && pos >= max) {\n                return 0;\n            }\n            return in.available();\n        }\n    }\n}\n",
    "target": 1,
    "language": "java",
    "dataset": "vul4j",
    "idx": 200096,
    "RELATED_CWE": [
      "CWE-908",
      "CWE-362",
      "CWE-667"
    ]
  },
  {
    "CWE_ID": [
      "CWE-835"
    ],
    "code": "/*\n * Licensed to the Apache Software Foundation (ASF) under one\n * or more contributor license agreements.  See the NOTICE file\n * distributed with this work for additional information\n * regarding copyright ownership.  The ASF licenses this file\n * to you under the Apache License, Version 2.0 (the\n * \"License\"); you may not use this file except in compliance\n * with the License.  You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing,\n * software distributed under the License is distributed on an\n * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n * KIND, either express or implied.  See the License for the\n * specific language governing permissions and limitations\n * under the License.\n */\npackage org.apache.commons.compress.archivers.zip;\n\nimport java.io.ByteArrayInputStream;\nimport java.io.ByteArrayOutputStream;\nimport java.io.EOFException;\nimport java.io.IOException;\nimport java.io.InputStream;\nimport java.io.PushbackInputStream;\nimport java.math.BigInteger;\nimport java.nio.ByteBuffer;\nimport java.util.Arrays;\nimport java.util.zip.CRC32;\nimport java.util.zip.DataFormatException;\nimport java.util.zip.Inflater;\nimport java.util.zip.ZipEntry;\nimport java.util.zip.ZipException;\n\nimport org.apache.commons.compress.archivers.ArchiveEntry;\nimport org.apache.commons.compress.archivers.ArchiveInputStream;\nimport org.apache.commons.compress.compressors.bzip2.BZip2CompressorInputStream;\nimport org.apache.commons.compress.compressors.deflate64.Deflate64CompressorInputStream;\nimport org.apache.commons.compress.utils.ArchiveUtils;\nimport org.apache.commons.compress.utils.IOUtils;\nimport org.apache.commons.compress.utils.InputStreamStatistics;\n\nimport static org.apache.commons.compress.archivers.zip.ZipConstants.DWORD;\nimport static org.apache.commons.compress.archivers.zip.ZipConstants.SHORT;\nimport static org.apache.commons.compress.archivers.zip.ZipConstants.WORD;\nimport static org.apache.commons.compress.archivers.zip.ZipConstants.ZIP64_MAGIC;\n\n/**\n * Implements an input stream that can read Zip archives.\n *\n * <p>As of Apache Commons Compress it transparently supports Zip64\n * extensions and thus individual entries and archives larger than 4\n * GB or with more than 65536 entries.</p>\n *\n * <p>The {@link ZipFile} class is preferred when reading from files\n * as {@link ZipArchiveInputStream} is limited by not being able to\n * read the central directory header before returning entries.  In\n * particular {@link ZipArchiveInputStream}</p>\n *\n * <ul>\n *\n *  <li>may return entries that are not part of the central directory\n *  at all and shouldn't be considered part of the archive.</li>\n *\n *  <li>may return several entries with the same name.</li>\n *\n *  <li>will not return internal or external attributes.</li>\n *\n *  <li>may return incomplete extra field data.</li>\n *\n *  <li>may return unknown sizes and CRC values for entries until the\n *  next entry has been reached if the archive uses the data\n *  descriptor feature.</li>\n *\n * </ul>\n *\n * @see ZipFile\n * @NotThreadSafe\n */\npublic class ZipArchiveInputStream extends ArchiveInputStream implements InputStreamStatistics {\n\n    /** The zip encoding to use for filenames and the file comment. */\n    private final ZipEncoding zipEncoding;\n\n    // the provided encoding (for unit tests)\n    final String encoding;\n\n    /** Whether to look for and use Unicode extra fields. */\n    private final boolean useUnicodeExtraFields;\n\n    /** Wrapped stream, will always be a PushbackInputStream. */\n    private final InputStream in;\n\n    /** Inflater used for all deflated entries. */\n    private final Inflater inf = new Inflater(true);\n\n    /** Buffer used to read from the wrapped stream. */\n    private final ByteBuffer buf = ByteBuffer.allocate(ZipArchiveOutputStream.BUFFER_SIZE);\n\n    /** The entry that is currently being read. */\n    private CurrentEntry current = null;\n\n    /** Whether the stream has been closed. */\n    private boolean closed = false;\n\n    /** Whether the stream has reached the central directory - and thus found all entries. */\n    private boolean hitCentralDirectory = false;\n\n    /**\n     * When reading a stored entry that uses the data descriptor this\n     * stream has to read the full entry and caches it.  This is the\n     * cache.\n     */\n    private ByteArrayInputStream lastStoredEntry = null;\n\n    /** Whether the stream will try to read STORED entries that use a data descriptor. */\n    private boolean allowStoredEntriesWithDataDescriptor = false;\n\n    /** Count decompressed bytes for current entry */\n    private long uncompressedCount = 0;\n\n    private static final int LFH_LEN = 30;\n    /*\n      local file header signature     WORD\n      version needed to extract       SHORT\n      general purpose bit flag        SHORT\n      compression method              SHORT\n      last mod file time              SHORT\n      last mod file date              SHORT\n      crc-32                          WORD\n      compressed size                 WORD\n      uncompressed size               WORD\n      file name length                SHORT\n      extra field length              SHORT\n    */\n\n    private static final int CFH_LEN = 46;\n    /*\n        central file header signature   WORD\n        version made by                 SHORT\n        version needed to extract       SHORT\n        general purpose bit flag        SHORT\n        compression method              SHORT\n        last mod file time              SHORT\n        last mod file date              SHORT\n        crc-32                          WORD\n        compressed size                 WORD\n        uncompressed size               WORD\n        file name length                SHORT\n        extra field length              SHORT\n        file comment length             SHORT\n        disk number start               SHORT\n        internal file attributes        SHORT\n        external file attributes        WORD\n        relative offset of local header WORD\n    */\n\n    private static final long TWO_EXP_32 = ZIP64_MAGIC + 1;\n\n    // cached buffers - must only be used locally in the class (COMPRESS-172 - reduce garbage collection)\n    private final byte[] lfhBuf = new byte[LFH_LEN];\n    private final byte[] skipBuf = new byte[1024];\n    private final byte[] shortBuf = new byte[SHORT];\n    private final byte[] wordBuf = new byte[WORD];\n    private final byte[] twoDwordBuf = new byte[2 * DWORD];\n\n    private int entriesRead = 0;\n\n    /**\n     * Create an instance using UTF-8 encoding\n     * @param inputStream the stream to wrap\n     */\n    public ZipArchiveInputStream(final InputStream inputStream) {\n        this(inputStream, ZipEncodingHelper.UTF8);\n    }\n\n    /**\n     * Create an instance using the specified encoding\n     * @param inputStream the stream to wrap\n     * @param encoding the encoding to use for file names, use null\n     * for the platform's default encoding\n     * @since 1.5\n     */\n    public ZipArchiveInputStream(final InputStream inputStream, final String encoding) {\n        this(inputStream, encoding, true);\n    }\n\n    /**\n     * Create an instance using the specified encoding\n     * @param inputStream the stream to wrap\n     * @param encoding the encoding to use for file names, use null\n     * for the platform's default encoding\n     * @param useUnicodeExtraFields whether to use InfoZIP Unicode\n     * Extra Fields (if present) to set the file names.\n     */\n    public ZipArchiveInputStream(final InputStream inputStream, final String encoding, final boolean useUnicodeExtraFields) {\n        this(inputStream, encoding, useUnicodeExtraFields, false);\n    }\n\n    /**\n     * Create an instance using the specified encoding\n     * @param inputStream the stream to wrap\n     * @param encoding the encoding to use for file names, use null\n     * for the platform's default encoding\n     * @param useUnicodeExtraFields whether to use InfoZIP Unicode\n     * Extra Fields (if present) to set the file names.\n     * @param allowStoredEntriesWithDataDescriptor whether the stream\n     * will try to read STORED entries that use a data descriptor\n     * @since 1.1\n     */\n    public ZipArchiveInputStream(final InputStream inputStream,\n                                 final String encoding,\n                                 final boolean useUnicodeExtraFields,\n                                 final boolean allowStoredEntriesWithDataDescriptor) {\n        this.encoding = encoding;\n        zipEncoding = ZipEncodingHelper.getZipEncoding(encoding);\n        this.useUnicodeExtraFields = useUnicodeExtraFields;\n        in = new PushbackInputStream(inputStream, buf.capacity());\n        this.allowStoredEntriesWithDataDescriptor =\n            allowStoredEntriesWithDataDescriptor;\n        // haven't read anything so far\n        buf.limit(0);\n    }\n\n    public ZipArchiveEntry getNextZipEntry() throws IOException {\n        uncompressedCount = 0;\n\n        boolean firstEntry = true;\n        if (closed || hitCentralDirectory) {\n            return null;\n        }\n        if (current != null) {\n            closeEntry();\n            firstEntry = false;\n        }\n\n        long currentHeaderOffset = getBytesRead();\n        try {\n            if (firstEntry) {\n                // split archives have a special signature before the\n                // first local file header - look for it and fail with\n                // the appropriate error message if this is a split\n                // archive.\n                readFirstLocalFileHeader(lfhBuf);\n            } else {\n                readFully(lfhBuf);\n            }\n        } catch (final EOFException e) {\n            return null;\n        }\n\n        final ZipLong sig = new ZipLong(lfhBuf);\n        if (!sig.equals(ZipLong.LFH_SIG)) {\n            if (sig.equals(ZipLong.CFH_SIG) || sig.equals(ZipLong.AED_SIG) || isApkSigningBlock(lfhBuf)) {\n                hitCentralDirectory = true;\n                skipRemainderOfArchive();\n                return null;\n            }\n            throw new ZipException(String.format(\"Unexpected record signature: 0X%X\", sig.getValue()));\n        }\n\n        int off = WORD;\n        current = new CurrentEntry();\n\n        final int versionMadeBy = ZipShort.getValue(lfhBuf, off);\n        off += SHORT;\n        current.entry.setPlatform((versionMadeBy >> ZipFile.BYTE_SHIFT) & ZipFile.NIBLET_MASK);\n\n        final GeneralPurposeBit gpFlag = GeneralPurposeBit.parse(lfhBuf, off);\n        final boolean hasUTF8Flag = gpFlag.usesUTF8ForNames();\n        final ZipEncoding entryEncoding = hasUTF8Flag ? ZipEncodingHelper.UTF8_ZIP_ENCODING : zipEncoding;\n        current.hasDataDescriptor = gpFlag.usesDataDescriptor();\n        current.entry.setGeneralPurposeBit(gpFlag);\n\n        off += SHORT;\n\n        current.entry.setMethod(ZipShort.getValue(lfhBuf, off));\n        off += SHORT;\n\n        final long time = ZipUtil.dosToJavaTime(ZipLong.getValue(lfhBuf, off));\n        current.entry.setTime(time);\n        off += WORD;\n\n        ZipLong size = null, cSize = null;\n        if (!current.hasDataDescriptor) {\n            current.entry.setCrc(ZipLong.getValue(lfhBuf, off));\n            off += WORD;\n\n            cSize = new ZipLong(lfhBuf, off);\n            off += WORD;\n\n            size = new ZipLong(lfhBuf, off);\n            off += WORD;\n        } else {\n            off += 3 * WORD;\n        }\n\n        final int fileNameLen = ZipShort.getValue(lfhBuf, off);\n\n        off += SHORT;\n\n        final int extraLen = ZipShort.getValue(lfhBuf, off);\n        off += SHORT; // NOSONAR - assignment as documentation\n\n        final byte[] fileName = new byte[fileNameLen];\n        readFully(fileName);\n        current.entry.setName(entryEncoding.decode(fileName), fileName);\n        if (hasUTF8Flag) {\n            current.entry.setNameSource(ZipArchiveEntry.NameSource.NAME_WITH_EFS_FLAG);\n        }\n\n        final byte[] extraData = new byte[extraLen];\n        readFully(extraData);\n        current.entry.setExtra(extraData);\n\n        if (!hasUTF8Flag && useUnicodeExtraFields) {\n            ZipUtil.setNameAndCommentFromExtraFields(current.entry, fileName, null);\n        }\n\n        processZip64Extra(size, cSize);\n\n        current.entry.setLocalHeaderOffset(currentHeaderOffset);\n        current.entry.setDataOffset(getBytesRead());\n        current.entry.setStreamContiguous(true);\n\n        ZipMethod m = ZipMethod.getMethodByCode(current.entry.getMethod());\n        if (current.entry.getCompressedSize() != ArchiveEntry.SIZE_UNKNOWN) {\n            if (ZipUtil.canHandleEntryData(current.entry) && m != ZipMethod.STORED && m != ZipMethod.DEFLATED) {\n                InputStream bis = new BoundedInputStream(in, current.entry.getCompressedSize());\n                switch (m) {\n                case UNSHRINKING:\n                    current.in = new UnshrinkingInputStream(bis);\n                    break;\n                case IMPLODING:\n                    current.in = new ExplodingInputStream(\n                        current.entry.getGeneralPurposeBit().getSlidingDictionarySize(),\n                        current.entry.getGeneralPurposeBit().getNumberOfShannonFanoTrees(),\n                        bis);\n                    break;\n                case BZIP2:\n                    current.in = new BZip2CompressorInputStream(bis);\n                    break;\n                case ENHANCED_DEFLATED:\n                    current.in = new Deflate64CompressorInputStream(bis);\n                    break;\n                default:\n                    // we should never get here as all supported methods have been covered\n                    // will cause an error when read is invoked, don't throw an exception here so people can\n                    // skip unsupported entries\n                    break;\n                }\n            }\n        } else if (m == ZipMethod.ENHANCED_DEFLATED) {\n            current.in = new Deflate64CompressorInputStream(in);\n        }\n\n        entriesRead++;\n        return current.entry;\n    }\n\n    /**\n     * Fills the given array with the first local file header and\n     * deals with splitting/spanning markers that may prefix the first\n     * LFH.\n     */\n    private void readFirstLocalFileHeader(final byte[] lfh) throws IOException {\n        readFully(lfh);\n        final ZipLong sig = new ZipLong(lfh);\n        if (sig.equals(ZipLong.DD_SIG)) {\n            throw new UnsupportedZipFeatureException(UnsupportedZipFeatureException.Feature.SPLITTING);\n        }\n\n        if (sig.equals(ZipLong.SINGLE_SEGMENT_SPLIT_MARKER)) {\n            // The archive is not really split as only one segment was\n            // needed in the end.  Just skip over the marker.\n            final byte[] missedLfhBytes = new byte[4];\n            readFully(missedLfhBytes);\n            System.arraycopy(lfh, 4, lfh, 0, LFH_LEN - 4);\n            System.arraycopy(missedLfhBytes, 0, lfh, LFH_LEN - 4, 4);\n        }\n    }\n\n    /**\n     * Records whether a Zip64 extra is present and sets the size\n     * information from it if sizes are 0xFFFFFFFF and the entry\n     * doesn't use a data descriptor.\n     */\n    private void processZip64Extra(final ZipLong size, final ZipLong cSize) {\n        final Zip64ExtendedInformationExtraField z64 =\n            (Zip64ExtendedInformationExtraField)\n            current.entry.getExtraField(Zip64ExtendedInformationExtraField.HEADER_ID);\n        current.usesZip64 = z64 != null;\n        if (!current.hasDataDescriptor) {\n            if (z64 != null // same as current.usesZip64 but avoids NPE warning\n                    && (cSize.equals(ZipLong.ZIP64_MAGIC) || size.equals(ZipLong.ZIP64_MAGIC)) ) {\n                current.entry.setCompressedSize(z64.getCompressedSize().getLongValue());\n                current.entry.setSize(z64.getSize().getLongValue());\n            } else {\n                current.entry.setCompressedSize(cSize.getValue());\n                current.entry.setSize(size.getValue());\n            }\n        }\n    }\n\n    @Override\n    public ArchiveEntry getNextEntry() throws IOException {\n        return getNextZipEntry();\n    }\n\n    /**\n     * Whether this class is able to read the given entry.\n     *\n     * <p>May return false if it is set up to use encryption or a\n     * compression method that hasn't been implemented yet.</p>\n     * @since 1.1\n     */\n    @Override\n    public boolean canReadEntryData(final ArchiveEntry ae) {\n        if (ae instanceof ZipArchiveEntry) {\n            final ZipArchiveEntry ze = (ZipArchiveEntry) ae;\n            return ZipUtil.canHandleEntryData(ze)\n                && supportsDataDescriptorFor(ze)\n                && supportsCompressedSizeFor(ze);\n        }\n        return false;\n    }\n\n    @Override\n    public int read(final byte[] buffer, final int offset, final int length) throws IOException {\n        if (closed) {\n            throw new IOException(\"The stream is closed\");\n        }\n\n        if (current == null) {\n            return -1;\n        }\n\n        // avoid int overflow, check null buffer\n        if (offset > buffer.length || length < 0 || offset < 0 || buffer.length - offset < length) {\n            throw new ArrayIndexOutOfBoundsException();\n        }\n\n        ZipUtil.checkRequestedFeatures(current.entry);\n        if (!supportsDataDescriptorFor(current.entry)) {\n            throw new UnsupportedZipFeatureException(UnsupportedZipFeatureException.Feature.DATA_DESCRIPTOR,\n                    current.entry);\n        }\n        if (!supportsCompressedSizeFor(current.entry)) {\n            throw new UnsupportedZipFeatureException(UnsupportedZipFeatureException.Feature.UNKNOWN_COMPRESSED_SIZE,\n                    current.entry);\n        }\n\n        int read;\n        if (current.entry.getMethod() == ZipArchiveOutputStream.STORED) {\n            read = readStored(buffer, offset, length);\n        } else if (current.entry.getMethod() == ZipArchiveOutputStream.DEFLATED) {\n            read = readDeflated(buffer, offset, length);\n        } else if (current.entry.getMethod() == ZipMethod.UNSHRINKING.getCode()\n                || current.entry.getMethod() == ZipMethod.IMPLODING.getCode()\n                || current.entry.getMethod() == ZipMethod.ENHANCED_DEFLATED.getCode()\n                || current.entry.getMethod() == ZipMethod.BZIP2.getCode()) {\n            read = current.in.read(buffer, offset, length);\n        } else {\n            throw new UnsupportedZipFeatureException(ZipMethod.getMethodByCode(current.entry.getMethod()),\n                    current.entry);\n        }\n\n        if (read >= 0) {\n            current.crc.update(buffer, offset, read);\n            uncompressedCount += read;\n        }\n\n        return read;\n    }\n\n    /**\n     * @since 1.17\n     */\n    @Override\n    public long getCompressedCount() {\n        if (current.entry.getMethod() == ZipArchiveOutputStream.STORED) {\n            return current.bytesRead;\n        } else if (current.entry.getMethod() == ZipArchiveOutputStream.DEFLATED) {\n            return getBytesInflated();\n        } else if (current.entry.getMethod() == ZipMethod.UNSHRINKING.getCode()) {\n            return ((UnshrinkingInputStream) current.in).getCompressedCount();\n        } else if (current.entry.getMethod() == ZipMethod.IMPLODING.getCode()) {\n            return ((ExplodingInputStream) current.in).getCompressedCount();\n        } else if (current.entry.getMethod() == ZipMethod.ENHANCED_DEFLATED.getCode()) {\n            return ((Deflate64CompressorInputStream) current.in).getCompressedCount();\n        } else if (current.entry.getMethod() == ZipMethod.BZIP2.getCode()) {\n            return ((BZip2CompressorInputStream) current.in).getCompressedCount();\n        } else {\n            return -1;\n        }\n    }\n\n    /**\n     * @since 1.17\n     */\n    @Override\n    public long getUncompressedCount() {\n        return uncompressedCount;\n    }\n\n    /**\n     * Implementation of read for STORED entries.\n     */\n    private int readStored(final byte[] buffer, final int offset, final int length) throws IOException {\n\n        if (current.hasDataDescriptor) {\n            if (lastStoredEntry == null) {\n                readStoredEntry();\n            }\n            return lastStoredEntry.read(buffer, offset, length);\n        }\n\n        final long csize = current.entry.getSize();\n        if (current.bytesRead >= csize) {\n            return -1;\n        }\n\n        if (buf.position() >= buf.limit()) {\n            buf.position(0);\n            final int l = in.read(buf.array());\n            if (l == -1) {\n                buf.limit(0);\n                throw new IOException(\"Truncated ZIP file\");\n            }\n            buf.limit(l);\n\n            count(l);\n            current.bytesReadFromStream += l;\n        }\n\n        int toRead = Math.min(buf.remaining(), length);\n        if ((csize - current.bytesRead) < toRead) {\n            // if it is smaller than toRead then it fits into an int\n            toRead = (int) (csize - current.bytesRead);\n        }\n        buf.get(buffer, offset, toRead);\n        current.bytesRead += toRead;\n        return toRead;\n    }\n\n    /**\n     * Implementation of read for DEFLATED entries.\n     */\n    private int readDeflated(final byte[] buffer, final int offset, final int length) throws IOException {\n        final int read = readFromInflater(buffer, offset, length);\n        if (read <= 0) {\n            if (inf.finished()) {\n                return -1;\n            } else if (inf.needsDictionary()) {\n                throw new ZipException(\"This archive needs a preset dictionary\"\n                                       + \" which is not supported by Commons\"\n                                       + \" Compress.\");\n            } else if (read == -1) {\n                throw new IOException(\"Truncated ZIP file\");\n            }\n        }\n        return read;\n    }\n\n    /**\n     * Potentially reads more bytes to fill the inflater's buffer and\n     * reads from it.\n     */\n    private int readFromInflater(final byte[] buffer, final int offset, final int length) throws IOException {\n        int read = 0;\n        do {\n            if (inf.needsInput()) {\n                final int l = fill();\n                if (l > 0) {\n                    current.bytesReadFromStream += buf.limit();\n                } else if (l == -1) {\n                    return -1;\n                } else {\n                    break;\n                }\n            }\n            try {\n                read = inf.inflate(buffer, offset, length);\n            } catch (final DataFormatException e) {\n                throw (IOException) new ZipException(e.getMessage()).initCause(e);\n            }\n        } while (read == 0 && inf.needsInput());\n        return read;\n    }\n\n    @Override\n    public void close() throws IOException {\n        if (!closed) {\n            closed = true;\n            try {\n                in.close();\n            } finally {\n                inf.end();\n            }\n        }\n    }\n\n    /**\n     * Skips over and discards value bytes of data from this input\n     * stream.\n     *\n     * <p>This implementation may end up skipping over some smaller\n     * number of bytes, possibly 0, if and only if it reaches the end\n     * of the underlying stream.</p>\n     *\n     * <p>The actual number of bytes skipped is returned.</p>\n     *\n     * @param value the number of bytes to be skipped.\n     * @return the actual number of bytes skipped.\n     * @throws IOException - if an I/O error occurs.\n     * @throws IllegalArgumentException - if value is negative.\n     */\n    @Override\n    public long skip(final long value) throws IOException {\n        if (value >= 0) {\n            long skipped = 0;\n            while (skipped < value) {\n                final long rem = value - skipped;\n                final int x = read(skipBuf, 0, (int) (skipBuf.length > rem ? rem : skipBuf.length));\n                if (x == -1) {\n                    return skipped;\n                }\n                skipped += x;\n            }\n            return skipped;\n        }\n        throw new IllegalArgumentException();\n    }\n\n    /**\n     * Checks if the signature matches what is expected for a zip file.\n     * Does not currently handle self-extracting zips which may have arbitrary\n     * leading content.\n     *\n     * @param signature the bytes to check\n     * @param length    the number of bytes to check\n     * @return true, if this stream is a zip archive stream, false otherwise\n     */\n    public static boolean matches(final byte[] signature, final int length) {\n        if (length < ZipArchiveOutputStream.LFH_SIG.length) {\n            return false;\n        }\n\n        return checksig(signature, ZipArchiveOutputStream.LFH_SIG) // normal file\n            || checksig(signature, ZipArchiveOutputStream.EOCD_SIG) // empty zip\n            || checksig(signature, ZipArchiveOutputStream.DD_SIG) // split zip\n            || checksig(signature, ZipLong.SINGLE_SEGMENT_SPLIT_MARKER.getBytes());\n    }\n\n    private static boolean checksig(final byte[] signature, final byte[] expected) {\n        for (int i = 0; i < expected.length; i++) {\n            if (signature[i] != expected[i]) {\n                return false;\n            }\n        }\n        return true;\n    }\n\n    /**\n     * Closes the current ZIP archive entry and positions the underlying\n     * stream to the beginning of the next entry. All per-entry variables\n     * and data structures are cleared.\n     * <p>\n     * If the compressed size of this entry is included in the entry header,\n     * then any outstanding bytes are simply skipped from the underlying\n     * stream without uncompressing them. This allows an entry to be safely\n     * closed even if the compression method is unsupported.\n     * <p>\n     * In case we don't know the compressed size of this entry or have\n     * already buffered too much data from the underlying stream to support\n     * uncompression, then the uncompression process is completed and the\n     * end position of the stream is adjusted based on the result of that\n     * process.\n     *\n     * @throws IOException if an error occurs\n     */\n    private void closeEntry() throws IOException {\n        if (closed) {\n            throw new IOException(\"The stream is closed\");\n        }\n        if (current == null) {\n            return;\n        }\n\n        // Ensure all entry bytes are read\n        if (currentEntryHasOutstandingBytes()) {\n            drainCurrentEntryData();\n        } else {\n            // this is guaranteed to exhaust the stream\n            skip(Long.MAX_VALUE); //NOSONAR\n\n            final long inB = current.entry.getMethod() == ZipArchiveOutputStream.DEFLATED\n                       ? getBytesInflated() : current.bytesRead;\n\n            // this is at most a single read() operation and can't\n            // exceed the range of int\n            final int diff = (int) (current.bytesReadFromStream - inB);\n\n            // Pushback any required bytes\n            if (diff > 0) {\n                pushback(buf.array(), buf.limit() - diff, diff);\n                current.bytesReadFromStream -= diff;\n            }\n\n            // Drain remainder of entry if not all data bytes were required\n            if (currentEntryHasOutstandingBytes()) {\n                drainCurrentEntryData();\n            }\n        }\n\n        if (lastStoredEntry == null && current.hasDataDescriptor) {\n            readDataDescriptor();\n        }\n\n        inf.reset();\n        buf.clear().flip();\n        current = null;\n        lastStoredEntry = null;\n    }\n\n    /**\n     * If the compressed size of the current entry is included in the entry header\n     * and there are any outstanding bytes in the underlying stream, then\n     * this returns true.\n     *\n     * @return true, if current entry is determined to have outstanding bytes, false otherwise\n     */\n    private boolean currentEntryHasOutstandingBytes() {\n        return current.bytesReadFromStream <= current.entry.getCompressedSize()\n                && !current.hasDataDescriptor;\n    }\n\n    /**\n     * Read all data of the current entry from the underlying stream\n     * that hasn't been read, yet.\n     */\n    private void drainCurrentEntryData() throws IOException {\n        long remaining = current.entry.getCompressedSize() - current.bytesReadFromStream;\n        while (remaining > 0) {\n            final long n = in.read(buf.array(), 0, (int) Math.min(buf.capacity(), remaining));\n            if (n < 0) {\n                throw new EOFException(\"Truncated ZIP entry: \"\n                                       + ArchiveUtils.sanitize(current.entry.getName()));\n            }\n            count(n);\n            remaining -= n;\n        }\n    }\n\n    /**\n     * Get the number of bytes Inflater has actually processed.\n     *\n     * <p>for Java &lt; Java7 the getBytes* methods in\n     * Inflater/Deflater seem to return unsigned ints rather than\n     * longs that start over with 0 at 2^32.</p>\n     *\n     * <p>The stream knows how many bytes it has read, but not how\n     * many the Inflater actually consumed - it should be between the\n     * total number of bytes read for the entry and the total number\n     * minus the last read operation.  Here we just try to make the\n     * value close enough to the bytes we've read by assuming the\n     * number of bytes consumed must be smaller than (or equal to) the\n     * number of bytes read but not smaller by more than 2^32.</p>\n     */\n    private long getBytesInflated() {\n        long inB = inf.getBytesRead();\n        if (current.bytesReadFromStream >= TWO_EXP_32) {\n            while (inB + TWO_EXP_32 <= current.bytesReadFromStream) {\n                inB += TWO_EXP_32;\n            }\n        }\n        return inB;\n    }\n\n    private int fill() throws IOException {\n        if (closed) {\n            throw new IOException(\"The stream is closed\");\n        }\n        final int length = in.read(buf.array());\n        if (length > 0) {\n            buf.limit(length);\n            count(buf.limit());\n            inf.setInput(buf.array(), 0, buf.limit());\n        }\n        return length;\n    }\n\n    private void readFully(final byte[] b) throws IOException {\n        readFully(b, 0);\n    }\n\n    private void readFully(final byte[] b, final int off) throws IOException {\n        final int len = b.length - off;\n        final int count = IOUtils.readFully(in, b, off, len);\n        count(count);\n        if (count < len) {\n            throw new EOFException();\n        }\n    }\n\n    private void readDataDescriptor() throws IOException {\n        readFully(wordBuf);\n        ZipLong val = new ZipLong(wordBuf);\n        if (ZipLong.DD_SIG.equals(val)) {\n            // data descriptor with signature, skip sig\n            readFully(wordBuf);\n            val = new ZipLong(wordBuf);\n        }\n        current.entry.setCrc(val.getValue());\n\n        // if there is a ZIP64 extra field, sizes are eight bytes\n        // each, otherwise four bytes each.  Unfortunately some\n        // implementations - namely Java7 - use eight bytes without\n        // using a ZIP64 extra field -\n        // https://bugs.sun.com/bugdatabase/view_bug.do?bug_id=7073588\n\n        // just read 16 bytes and check whether bytes nine to twelve\n        // look like one of the signatures of what could follow a data\n        // descriptor (ignoring archive decryption headers for now).\n        // If so, push back eight bytes and assume sizes are four\n        // bytes, otherwise sizes are eight bytes each.\n        readFully(twoDwordBuf);\n        final ZipLong potentialSig = new ZipLong(twoDwordBuf, DWORD);\n        if (potentialSig.equals(ZipLong.CFH_SIG) || potentialSig.equals(ZipLong.LFH_SIG)) {\n            pushback(twoDwordBuf, DWORD, DWORD);\n            current.entry.setCompressedSize(ZipLong.getValue(twoDwordBuf));\n            current.entry.setSize(ZipLong.getValue(twoDwordBuf, WORD));\n        } else {\n            current.entry.setCompressedSize(ZipEightByteInteger.getLongValue(twoDwordBuf));\n            current.entry.setSize(ZipEightByteInteger.getLongValue(twoDwordBuf, DWORD));\n        }\n    }\n\n    /**\n     * Whether this entry requires a data descriptor this library can work with.\n     *\n     * @return true if allowStoredEntriesWithDataDescriptor is true,\n     * the entry doesn't require any data descriptor or the method is\n     * DEFLATED or ENHANCED_DEFLATED.\n     */\n    private boolean supportsDataDescriptorFor(final ZipArchiveEntry entry) {\n        return !entry.getGeneralPurposeBit().usesDataDescriptor()\n\n                || (allowStoredEntriesWithDataDescriptor && entry.getMethod() == ZipEntry.STORED)\n                || entry.getMethod() == ZipEntry.DEFLATED\n                || entry.getMethod() == ZipMethod.ENHANCED_DEFLATED.getCode();\n    }\n\n    /**\n     * Whether the compressed size for the entry is either known or\n     * not required by the compression method being used.\n     */\n    private boolean supportsCompressedSizeFor(final ZipArchiveEntry entry) {\n        return entry.getCompressedSize() != ArchiveEntry.SIZE_UNKNOWN\n            || entry.getMethod() == ZipEntry.DEFLATED\n            || entry.getMethod() == ZipMethod.ENHANCED_DEFLATED.getCode()\n            || (entry.getGeneralPurposeBit().usesDataDescriptor()\n                && allowStoredEntriesWithDataDescriptor\n                && entry.getMethod() == ZipEntry.STORED);\n    }\n\n    /**\n     * Caches a stored entry that uses the data descriptor.\n     *\n     * <ul>\n     *   <li>Reads a stored entry until the signature of a local file\n     *     header, central directory header or data descriptor has been\n     *     found.</li>\n     *   <li>Stores all entry data in lastStoredEntry.</p>\n     *   <li>Rewinds the stream to position at the data\n     *     descriptor.</li>\n     *   <li>reads the data descriptor</li>\n     * </ul>\n     *\n     * <p>After calling this method the entry should know its size,\n     * the entry's data is cached and the stream is positioned at the\n     * next local file or central directory header.</p>\n     */\n    private void readStoredEntry() throws IOException {\n        final ByteArrayOutputStream bos = new ByteArrayOutputStream();\n        int off = 0;\n        boolean done = false;\n\n        // length of DD without signature\n        final int ddLen = current.usesZip64 ? WORD + 2 * DWORD : 3 * WORD;\n\n        while (!done) {\n            final int r = in.read(buf.array(), off, ZipArchiveOutputStream.BUFFER_SIZE - off);\n            if (r <= 0) {\n                // read the whole archive without ever finding a\n                // central directory\n                throw new IOException(\"Truncated ZIP file\");\n            }\n            if (r + off < 4) {\n                // buffer too small to check for a signature, loop\n                off += r;\n                continue;\n            }\n\n            done = bufferContainsSignature(bos, off, r, ddLen);\n            if (!done) {\n                off = cacheBytesRead(bos, off, r, ddLen);\n            }\n        }\n\n        final byte[] b = bos.toByteArray();\n        lastStoredEntry = new ByteArrayInputStream(b);\n    }\n\n    private static final byte[] LFH = ZipLong.LFH_SIG.getBytes();\n    private static final byte[] CFH = ZipLong.CFH_SIG.getBytes();\n    private static final byte[] DD = ZipLong.DD_SIG.getBytes();\n\n    /**\n     * Checks whether the current buffer contains the signature of a\n     * &quot;data descriptor&quot;, &quot;local file header&quot; or\n     * &quot;central directory entry&quot;.\n     *\n     * <p>If it contains such a signature, reads the data descriptor\n     * and positions the stream right after the data descriptor.</p>\n     */\n    private boolean bufferContainsSignature(final ByteArrayOutputStream bos, final int offset, final int lastRead, final int expectedDDLen)\n            throws IOException {\n\n        boolean done = false;\n        int readTooMuch = 0;\n        for (int i = 0; !done && i < offset + lastRead - 4; i++) {\n            if (buf.array()[i] == LFH[0] && buf.array()[i + 1] == LFH[1]) {\n                if ((buf.array()[i + 2] == LFH[2] && buf.array()[i + 3] == LFH[3])\n                    || (buf.array()[i] == CFH[2] && buf.array()[i + 3] == CFH[3])) {\n                    // found a LFH or CFH:\n                    readTooMuch = offset + lastRead - i - expectedDDLen;\n                    done = true;\n                }\n                else if (buf.array()[i + 2] == DD[2] && buf.array()[i + 3] == DD[3]) {\n                    // found DD:\n                    readTooMuch = offset + lastRead - i;\n                    done = true;\n                }\n                if (done) {\n                    // * push back bytes read in excess as well as the data\n                    //   descriptor\n                    // * copy the remaining bytes to cache\n                    // * read data descriptor\n                    pushback(buf.array(), offset + lastRead - readTooMuch, readTooMuch);\n                    bos.write(buf.array(), 0, i);\n                    readDataDescriptor();\n                }\n            }\n        }\n        return done;\n    }\n\n    /**\n     * If the last read bytes could hold a data descriptor and an\n     * incomplete signature then save the last bytes to the front of\n     * the buffer and cache everything in front of the potential data\n     * descriptor into the given ByteArrayOutputStream.\n     *\n     * <p>Data descriptor plus incomplete signature (3 bytes in the\n     * worst case) can be 20 bytes max.</p>\n     */\n    private int cacheBytesRead(final ByteArrayOutputStream bos, int offset, final int lastRead, final int expecteDDLen) {\n        final int cacheable = offset + lastRead - expecteDDLen - 3;\n        if (cacheable > 0) {\n            bos.write(buf.array(), 0, cacheable);\n            System.arraycopy(buf.array(), cacheable, buf.array(), 0, expecteDDLen + 3);\n            offset = expecteDDLen + 3;\n        } else {\n            offset += lastRead;\n        }\n        return offset;\n    }\n\n    private void pushback(final byte[] buf, final int offset, final int length) throws IOException {\n        ((PushbackInputStream) in).unread(buf, offset, length);\n        pushedBackBytes(length);\n    }\n\n    // End of Central Directory Record\n    //   end of central dir signature    WORD\n    //   number of this disk             SHORT\n    //   number of the disk with the\n    //   start of the central directory  SHORT\n    //   total number of entries in the\n    //   central directory on this disk  SHORT\n    //   total number of entries in\n    //   the central directory           SHORT\n    //   size of the central directory   WORD\n    //   offset of start of central\n    //   directory with respect to\n    //   the starting disk number        WORD\n    //   .ZIP file comment length        SHORT\n    //   .ZIP file comment               up to 64KB\n    //\n\n    /**\n     * Reads the stream until it find the \"End of central directory\n     * record\" and consumes it as well.\n     */\n    private void skipRemainderOfArchive() throws IOException {\n        // skip over central directory. One LFH has been read too much\n        // already.  The calculation discounts file names and extra\n        // data so it will be too short.\n        realSkip((long) entriesRead * CFH_LEN - LFH_LEN);\n        findEocdRecord();\n        realSkip((long) ZipFile.MIN_EOCD_SIZE - WORD /* signature */ - SHORT /* comment len */);\n        readFully(shortBuf);\n        // file comment\n        realSkip(ZipShort.getValue(shortBuf));\n    }\n\n    /**\n     * Reads forward until the signature of the &quot;End of central\n     * directory&quot; record is found.\n     */\n    private void findEocdRecord() throws IOException {\n        int currentByte = -1;\n        boolean skipReadCall = false;\n        while (skipReadCall || (currentByte = readOneByte()) > -1) {\n            skipReadCall = false;\n            if (!isFirstByteOfEocdSig(currentByte)) {\n                continue;\n            }\n            currentByte = readOneByte();\n            if (currentByte != ZipArchiveOutputStream.EOCD_SIG[1]) {\n                if (currentByte == -1) {\n                    break;\n                }\n                skipReadCall = isFirstByteOfEocdSig(currentByte);\n                continue;\n            }\n            currentByte = readOneByte();\n            if (currentByte != ZipArchiveOutputStream.EOCD_SIG[2]) {\n                if (currentByte == -1) {\n                    break;\n                }\n                skipReadCall = isFirstByteOfEocdSig(currentByte);\n                continue;\n            }\n            currentByte = readOneByte();\n            if (currentByte == -1\n                || currentByte == ZipArchiveOutputStream.EOCD_SIG[3]) {\n                break;\n            }\n            skipReadCall = isFirstByteOfEocdSig(currentByte);\n        }\n    }\n\n    /**\n     * Skips bytes by reading from the underlying stream rather than\n     * the (potentially inflating) archive stream - which {@link\n     * #skip} would do.\n     *\n     * Also updates bytes-read counter.\n     */\n    private void realSkip(final long value) throws IOException {\n        if (value >= 0) {\n            long skipped = 0;\n            while (skipped < value) {\n                final long rem = value - skipped;\n                final int x = in.read(skipBuf, 0, (int) (skipBuf.length > rem ? rem : skipBuf.length));\n                if (x == -1) {\n                    return;\n                }\n                count(x);\n                skipped += x;\n            }\n            return;\n        }\n        throw new IllegalArgumentException();\n    }\n\n    /**\n     * Reads bytes by reading from the underlying stream rather than\n     * the (potentially inflating) archive stream - which {@link #read} would do.\n     *\n     * Also updates bytes-read counter.\n     */\n    private int readOneByte() throws IOException {\n        final int b = in.read();\n        if (b != -1) {\n            count(1);\n        }\n        return b;\n    }\n\n    private boolean isFirstByteOfEocdSig(final int b) {\n        return b == ZipArchiveOutputStream.EOCD_SIG[0];\n    }\n\n    private static final byte[] APK_SIGNING_BLOCK_MAGIC = new byte[] {\n        'A', 'P', 'K', ' ', 'S', 'i', 'g', ' ', 'B', 'l', 'o', 'c', 'k', ' ', '4', '2',\n    };\n    private static final BigInteger LONG_MAX = BigInteger.valueOf(Long.MAX_VALUE);\n\n    /**\n     * Checks whether this might be an APK Signing Block.\n     *\n     * <p>Unfortunately the APK signing block does not start with some kind of signature, it rather ends with one. It\n     * starts with a length, so what we do is parse the suspect length, skip ahead far enough, look for the signature\n     * and if we've found it, return true.</p>\n     *\n     * @param suspectLocalFileHeader the bytes read from the underlying stream in the expectation that they would hold\n     * the local file header of the next entry.\n     *\n     * @return true if this looks like a APK signing block\n     *\n     * @see <a href=\"https://source.android.com/security/apksigning/v2\">https://source.android.com/security/apksigning/v2</a>\n     */\n    private boolean isApkSigningBlock(byte[] suspectLocalFileHeader) throws IOException {\n        // length of block excluding the size field itself\n        BigInteger len = ZipEightByteInteger.getValue(suspectLocalFileHeader);\n        // LFH has already been read and all but the first eight bytes contain (part of) the APK signing block,\n        // also subtract 16 bytes in order to position us at the magic string\n        BigInteger toSkip = len.add(BigInteger.valueOf(DWORD - suspectLocalFileHeader.length\n            - APK_SIGNING_BLOCK_MAGIC.length));\n        byte[] magic = new byte[APK_SIGNING_BLOCK_MAGIC.length];\n\n        try {\n            if (toSkip.signum() < 0) {\n                // suspectLocalFileHeader contains the start of suspect magic string\n                int off = suspectLocalFileHeader.length + toSkip.intValue();\n                // length was shorter than magic length\n                if (off < DWORD) {\n                    return false;\n                }\n                int bytesInBuffer = Math.abs(toSkip.intValue());\n                System.arraycopy(suspectLocalFileHeader, off, magic, 0, Math.min(bytesInBuffer, magic.length));\n                if (bytesInBuffer < magic.length) {\n                    readFully(magic, bytesInBuffer);\n                }\n            } else {\n                while (toSkip.compareTo(LONG_MAX) > 0) {\n                    realSkip(Long.MAX_VALUE);\n                    toSkip = toSkip.add(LONG_MAX.negate());\n                }\n                realSkip(toSkip.longValue());\n                readFully(magic);\n            }\n        } catch (EOFException ex) {\n            // length was invalid\n            return false;\n        }\n        return Arrays.equals(magic, APK_SIGNING_BLOCK_MAGIC);\n    }\n\n    /**\n     * Structure collecting information for the entry that is\n     * currently being read.\n     */\n    private static final class CurrentEntry {\n\n        /**\n         * Current ZIP entry.\n         */\n        private final ZipArchiveEntry entry = new ZipArchiveEntry();\n\n        /**\n         * Does the entry use a data descriptor?\n         */\n        private boolean hasDataDescriptor;\n\n        /**\n         * Does the entry have a ZIP64 extended information extra field.\n         */\n        private boolean usesZip64;\n\n        /**\n         * Number of bytes of entry content read by the client if the\n         * entry is STORED.\n         */\n        private long bytesRead;\n\n        /**\n         * Number of bytes of entry content read from the stream.\n         *\n         * <p>This may be more than the actual entry's length as some\n         * stuff gets buffered up and needs to be pushed back when the\n         * end of the entry has been reached.</p>\n         */\n        private long bytesReadFromStream;\n\n        /**\n         * The checksum calculated as the current entry is read.\n         */\n        private final CRC32 crc = new CRC32();\n\n        /**\n         * The input stream decompressing the data for shrunk and imploded entries.\n         */\n        private InputStream in;\n    }\n\n    /**\n     * Bounded input stream adapted from commons-io\n     */\n    private class BoundedInputStream extends InputStream {\n\n        /** the wrapped input stream */\n        private final InputStream in;\n\n        /** the max length to provide */\n        private final long max;\n\n        /** the number of bytes already returned */\n        private long pos = 0;\n\n        /**\n         * Creates a new <code>BoundedInputStream</code> that wraps the given input\n         * stream and limits it to a certain size.\n         *\n         * @param in The wrapped input stream\n         * @param size The maximum number of bytes to return\n         */\n        public BoundedInputStream(final InputStream in, final long size) {\n            this.max = size;\n            this.in = in;\n        }\n\n        @Override\n        public int read() throws IOException {\n            if (max >= 0 && pos >= max) {\n                return -1;\n            }\n            final int result = in.read();\n            pos++;\n            count(1);\n            current.bytesReadFromStream++;\n            return result;\n        }\n\n        @Override\n        public int read(final byte[] b) throws IOException {\n            return this.read(b, 0, b.length);\n        }\n\n        @Override\n        public int read(final byte[] b, final int off, final int len) throws IOException {\n            if (max >= 0 && pos >= max) {\n                return -1;\n            }\n            final long maxRead = max >= 0 ? Math.min(len, max - pos) : len;\n            final int bytesRead = in.read(b, off, (int) maxRead);\n\n            if (bytesRead == -1) {\n                return -1;\n            }\n\n            pos += bytesRead;\n            count(bytesRead);\n            current.bytesReadFromStream += bytesRead;\n            return bytesRead;\n        }\n\n        @Override\n        public long skip(final long n) throws IOException {\n            final long toSkip = max >= 0 ? Math.min(n, max - pos) : n;\n            final long skippedBytes = IOUtils.skip(in, toSkip);\n            pos += skippedBytes;\n            return skippedBytes;\n        }\n\n        @Override\n        public int available() throws IOException {\n            if (max >= 0 && pos >= max) {\n                return 0;\n            }\n            return in.available();\n        }\n    }\n}\n",
    "target": 0,
    "language": "java",
    "dataset": "vul4j",
    "idx": 200097,
    "RELATED_CWE": [
      "CWE-908",
      "CWE-362",
      "CWE-667"
    ]
  },
  {
    "CWE_ID": [
      "CWE-835"
    ],
    "code": "/*\n * Licensed to the Apache Software Foundation (ASF) under one\n * or more contributor license agreements.  See the NOTICE file\n * distributed with this work for additional information\n * regarding copyright ownership.  The ASF licenses this file\n * to you under the Apache License, Version 2.0 (the\n * \"License\"); you may not use this file except in compliance\n * with the License.  You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing,\n * software distributed under the License is distributed on an\n * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n * KIND, either express or implied.  See the License for the\n * specific language governing permissions and limitations\n * under the License.\n */\n\npackage org.apache.commons.compress.archivers.zip;\n\nimport java.io.IOException;\nimport java.nio.ByteBuffer;\nimport java.nio.CharBuffer;\nimport java.nio.charset.Charset;\nimport java.nio.charset.CharsetDecoder;\nimport java.nio.charset.CharsetEncoder;\nimport java.nio.charset.CoderResult;\nimport java.nio.charset.CodingErrorAction;\n\n/**\n * A ZipEncoding, which uses a java.nio {@link\n * java.nio.charset.Charset Charset} to encode names.\n * <p>The methods of this class are reentrant.</p>\n * @Immutable\n */\nclass NioZipEncoding implements ZipEncoding, CharsetAccessor {\n\n    private final Charset charset;\n    private final boolean useReplacement;\n    private static final char REPLACEMENT = '?';\n    private static final byte[] REPLACEMENT_BYTES = { (byte) REPLACEMENT };\n    private static final String REPLACEMENT_STRING = String.valueOf(REPLACEMENT);\n    private static final char[] HEX_CHARS = new char[] {\n        '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'A', 'B', 'C', 'D', 'E', 'F'\n    };\n\n\n    /**\n     * Construct an NioZipEncoding using the given charset.\n     * @param charset  The character set to use.\n     * @param useReplacement should invalid characters be replaced, or reported.\n     */\n    NioZipEncoding(final Charset charset, boolean useReplacement) {\n        this.charset = charset;\n        this.useReplacement = useReplacement;\n    }\n\n    @Override\n    public Charset getCharset() {\n        return charset;\n    }\n\n    /**\n     * @see  ZipEncoding#canEncode(java.lang.String)\n     */\n    @Override\n    public boolean canEncode(final String name) {\n        final CharsetEncoder enc = newEncoder();\n\n        return enc.canEncode(name);\n    }\n\n    /**\n     * @see ZipEncoding#encode(java.lang.String)\n     */\n    @Override\n    public ByteBuffer encode(final String name) {\n        final CharsetEncoder enc = newEncoder();\n\n        final CharBuffer cb = CharBuffer.wrap(name);\n        CharBuffer tmp = null;\n        ByteBuffer out = ByteBuffer.allocate(estimateInitialBufferSize(enc, cb.remaining()));\n\n        while (cb.remaining() > 0) {\n            final CoderResult res = enc.encode(cb, out, false);\n\n            if (res.isUnmappable() || res.isMalformed()) {\n\n                // write the unmappable characters in utf-16\n                // pseudo-URL encoding style to ByteBuffer.\n\n                int spaceForSurrogate = estimateIncrementalEncodingSize(enc, 6 * res.length());\n                if (spaceForSurrogate > out.remaining()) {\n                    // if the destination buffer isn't over sized, assume that the presence of one\n                    // unmappable character makes it likely that there will be more. Find all the\n                    // un-encoded characters and allocate space based on those estimates.\n                    int charCount = 0;\n                    for (int i = cb.position() ; i < cb.limit(); i++) {\n                        charCount += !enc.canEncode(cb.get(i)) ? 6 : 1;\n                    }\n                    int totalExtraSpace = estimateIncrementalEncodingSize(enc, charCount);\n                    out = ZipEncodingHelper.growBufferBy(out, totalExtraSpace - out.remaining());\n                }\n                if (tmp == null) {\n                    tmp = CharBuffer.allocate(6);\n                }\n                for (int i = 0; i < res.length(); ++i) {\n                    out = encodeFully(enc, encodeSurrogate(tmp, cb.get()), out);\n                }\n\n            } else if (res.isOverflow()) {\n                int increment = estimateIncrementalEncodingSize(enc, cb.remaining());\n                out = ZipEncodingHelper.growBufferBy(out, increment);\n            }\n        }\n        // tell the encoder we are done\n        enc.encode(cb, out, true);\n        // may have caused underflow, but that's been ignored traditionally\n\n        out.limit(out.position());\n        out.rewind();\n        return out;\n    }\n\n    /**\n     * @see\n     * ZipEncoding#decode(byte[])\n     */\n    @Override\n    public String decode(final byte[] data) throws IOException {\n        return newDecoder()\n            .decode(ByteBuffer.wrap(data)).toString();\n    }\n\n    private static ByteBuffer encodeFully(CharsetEncoder enc, CharBuffer cb, ByteBuffer out) {\n        ByteBuffer o = out;\n        while (cb.hasRemaining()) {\n            CoderResult result = enc.encode(cb, o, false);\n            if (result.isOverflow()) {\n                int increment = estimateIncrementalEncodingSize(enc, cb.remaining());\n                o = ZipEncodingHelper.growBufferBy(o, increment);\n            }\n        }\n        return o;\n    }\n\n    private static CharBuffer encodeSurrogate(CharBuffer cb, char c) {\n        cb.position(0).limit(6);\n        cb.put('%');\n        cb.put('U');\n\n        cb.put(HEX_CHARS[(c >> 12) & 0x0f]);\n        cb.put(HEX_CHARS[(c >> 8) & 0x0f]);\n        cb.put(HEX_CHARS[(c >> 4) & 0x0f]);\n        cb.put(HEX_CHARS[c & 0x0f]);\n        cb.flip();\n        return cb;\n    }\n\n    private CharsetEncoder newEncoder() {\n        if (useReplacement) {\n            return charset.newEncoder()\n                .onMalformedInput(CodingErrorAction.REPLACE)\n                .onUnmappableCharacter(CodingErrorAction.REPLACE)\n                .replaceWith(REPLACEMENT_BYTES);\n        } else {\n            return charset.newEncoder()\n                .onMalformedInput(CodingErrorAction.REPORT)\n                .onUnmappableCharacter(CodingErrorAction.REPORT);\n        }\n    }\n\n    private CharsetDecoder newDecoder() {\n        if (!useReplacement) {\n            return this.charset.newDecoder()\n                .onMalformedInput(CodingErrorAction.REPORT)\n                .onUnmappableCharacter(CodingErrorAction.REPORT);\n        } else {\n            return  charset.newDecoder()\n                .onMalformedInput(CodingErrorAction.REPLACE)\n                .onUnmappableCharacter(CodingErrorAction.REPLACE)\n                .replaceWith(REPLACEMENT_STRING);\n        }\n    }\n\n    /**\n     * Estimate the initial encoded size (in bytes) for a character buffer.\n     * <p>\n     * The estimate assumes that one character consumes uses the maximum length encoding,\n     * whilst the rest use an average size encoding. This accounts for any BOM for UTF-16, at\n     * the expense of a couple of extra bytes for UTF-8 encoded ASCII.\n     * </p>\n     *\n     * @param enc        encoder to use for estimates\n     * @param charChount number of characters in string\n     * @return estimated size in bytes.\n     */\n    private static int estimateInitialBufferSize(CharsetEncoder enc, int charChount) {\n        float first = enc.maxBytesPerChar();\n        float rest = (charChount - 1) * enc.averageBytesPerChar();\n        return (int) Math.ceil(first + rest);\n    }\n\n    /**\n     * Estimate the size needed for remaining characters\n     *\n     * @param enc       encoder to use for estimates\n     * @param charCount number of characters remaining\n     * @return estimated size in bytes.\n     */\n    private static int estimateIncrementalEncodingSize(CharsetEncoder enc, int charCount) {\n        return (int) Math.ceil(charCount * enc.averageBytesPerChar());\n    }\n\n}\n",
    "target": 1,
    "language": "java",
    "dataset": "vul4j",
    "idx": 200098,
    "RELATED_CWE": [
      "CWE-908",
      "CWE-362",
      "CWE-667"
    ]
  },
  {
    "CWE_ID": [
      "CWE-835"
    ],
    "code": "/*\n * Licensed to the Apache Software Foundation (ASF) under one\n * or more contributor license agreements.  See the NOTICE file\n * distributed with this work for additional information\n * regarding copyright ownership.  The ASF licenses this file\n * to you under the Apache License, Version 2.0 (the\n * \"License\"); you may not use this file except in compliance\n * with the License.  You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing,\n * software distributed under the License is distributed on an\n * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n * KIND, either express or implied.  See the License for the\n * specific language governing permissions and limitations\n * under the License.\n */\n\npackage org.apache.commons.compress.archivers.zip;\n\nimport java.io.IOException;\nimport java.nio.ByteBuffer;\nimport java.nio.CharBuffer;\nimport java.nio.charset.Charset;\nimport java.nio.charset.CharsetDecoder;\nimport java.nio.charset.CharsetEncoder;\nimport java.nio.charset.CoderResult;\nimport java.nio.charset.CodingErrorAction;\n\n/**\n * A ZipEncoding, which uses a java.nio {@link\n * java.nio.charset.Charset Charset} to encode names.\n * <p>The methods of this class are reentrant.</p>\n * @Immutable\n */\nclass NioZipEncoding implements ZipEncoding, CharsetAccessor {\n\n    private final Charset charset;\n    private final boolean useReplacement;\n    private static final char REPLACEMENT = '?';\n    private static final byte[] REPLACEMENT_BYTES = { (byte) REPLACEMENT };\n    private static final String REPLACEMENT_STRING = String.valueOf(REPLACEMENT);\n    private static final char[] HEX_CHARS = new char[] {\n        '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'A', 'B', 'C', 'D', 'E', 'F'\n    };\n\n\n    /**\n     * Construct an NioZipEncoding using the given charset.\n     * @param charset  The character set to use.\n     * @param useReplacement should invalid characters be replaced, or reported.\n     */\n    NioZipEncoding(final Charset charset, boolean useReplacement) {\n        this.charset = charset;\n        this.useReplacement = useReplacement;\n    }\n\n    @Override\n    public Charset getCharset() {\n        return charset;\n    }\n\n    /**\n     * @see  ZipEncoding#canEncode(java.lang.String)\n     */\n    @Override\n    public boolean canEncode(final String name) {\n        final CharsetEncoder enc = newEncoder();\n\n        return enc.canEncode(name);\n    }\n\n    /**\n     * @see ZipEncoding#encode(java.lang.String)\n     */\n    @Override\n    public ByteBuffer encode(final String name) {\n        final CharsetEncoder enc = newEncoder();\n\n        final CharBuffer cb = CharBuffer.wrap(name);\n        CharBuffer tmp = null;\n        ByteBuffer out = ByteBuffer.allocate(estimateInitialBufferSize(enc, cb.remaining()));\n\n        while (cb.remaining() > 0) {\n            final CoderResult res = enc.encode(cb, out, false);\n\n            if (res.isUnmappable() || res.isMalformed()) {\n\n                // write the unmappable characters in utf-16\n                // pseudo-URL encoding style to ByteBuffer.\n\n                int spaceForSurrogate = estimateIncrementalEncodingSize(enc, 6 * res.length());\n                if (spaceForSurrogate > out.remaining()) {\n                    // if the destination buffer isn't over sized, assume that the presence of one\n                    // unmappable character makes it likely that there will be more. Find all the\n                    // un-encoded characters and allocate space based on those estimates.\n                    int charCount = 0;\n                    for (int i = cb.position() ; i < cb.limit(); i++) {\n                        charCount += !enc.canEncode(cb.get(i)) ? 6 : 1;\n                    }\n                    int totalExtraSpace = estimateIncrementalEncodingSize(enc, charCount);\n                    out = ZipEncodingHelper.growBufferBy(out, totalExtraSpace - out.remaining());\n                }\n                if (tmp == null) {\n                    tmp = CharBuffer.allocate(6);\n                }\n                for (int i = 0; i < res.length(); ++i) {\n                    out = encodeFully(enc, encodeSurrogate(tmp, cb.get()), out);\n                }\n\n            } else if (res.isOverflow()) {\n                int increment = estimateIncrementalEncodingSize(enc, cb.remaining());\n                out = ZipEncodingHelper.growBufferBy(out, increment);\n\n            } else if (res.isUnderflow() || res.isError()) {\n                break;\n            }\n        }\n        // tell the encoder we are done\n        enc.encode(cb, out, true);\n        // may have caused underflow, but that's been ignored traditionally\n\n        out.limit(out.position());\n        out.rewind();\n        return out;\n    }\n\n    /**\n     * @see\n     * ZipEncoding#decode(byte[])\n     */\n    @Override\n    public String decode(final byte[] data) throws IOException {\n        return newDecoder()\n            .decode(ByteBuffer.wrap(data)).toString();\n    }\n\n    private static ByteBuffer encodeFully(CharsetEncoder enc, CharBuffer cb, ByteBuffer out) {\n        ByteBuffer o = out;\n        while (cb.hasRemaining()) {\n            CoderResult result = enc.encode(cb, o, false);\n            if (result.isOverflow()) {\n                int increment = estimateIncrementalEncodingSize(enc, cb.remaining());\n                o = ZipEncodingHelper.growBufferBy(o, increment);\n            }\n        }\n        return o;\n    }\n\n    private static CharBuffer encodeSurrogate(CharBuffer cb, char c) {\n        cb.position(0).limit(6);\n        cb.put('%');\n        cb.put('U');\n\n        cb.put(HEX_CHARS[(c >> 12) & 0x0f]);\n        cb.put(HEX_CHARS[(c >> 8) & 0x0f]);\n        cb.put(HEX_CHARS[(c >> 4) & 0x0f]);\n        cb.put(HEX_CHARS[c & 0x0f]);\n        cb.flip();\n        return cb;\n    }\n\n    private CharsetEncoder newEncoder() {\n        if (useReplacement) {\n            return charset.newEncoder()\n                .onMalformedInput(CodingErrorAction.REPLACE)\n                .onUnmappableCharacter(CodingErrorAction.REPLACE)\n                .replaceWith(REPLACEMENT_BYTES);\n        } else {\n            return charset.newEncoder()\n                .onMalformedInput(CodingErrorAction.REPORT)\n                .onUnmappableCharacter(CodingErrorAction.REPORT);\n        }\n    }\n\n    private CharsetDecoder newDecoder() {\n        if (!useReplacement) {\n            return this.charset.newDecoder()\n                .onMalformedInput(CodingErrorAction.REPORT)\n                .onUnmappableCharacter(CodingErrorAction.REPORT);\n        } else {\n            return  charset.newDecoder()\n                .onMalformedInput(CodingErrorAction.REPLACE)\n                .onUnmappableCharacter(CodingErrorAction.REPLACE)\n                .replaceWith(REPLACEMENT_STRING);\n        }\n    }\n\n    /**\n     * Estimate the initial encoded size (in bytes) for a character buffer.\n     * <p>\n     * The estimate assumes that one character consumes uses the maximum length encoding,\n     * whilst the rest use an average size encoding. This accounts for any BOM for UTF-16, at\n     * the expense of a couple of extra bytes for UTF-8 encoded ASCII.\n     * </p>\n     *\n     * @param enc        encoder to use for estimates\n     * @param charChount number of characters in string\n     * @return estimated size in bytes.\n     */\n    private static int estimateInitialBufferSize(CharsetEncoder enc, int charChount) {\n        float first = enc.maxBytesPerChar();\n        float rest = (charChount - 1) * enc.averageBytesPerChar();\n        return (int) Math.ceil(first + rest);\n    }\n\n    /**\n     * Estimate the size needed for remaining characters\n     *\n     * @param enc       encoder to use for estimates\n     * @param charCount number of characters remaining\n     * @return estimated size in bytes.\n     */\n    private static int estimateIncrementalEncodingSize(CharsetEncoder enc, int charCount) {\n        return (int) Math.ceil(charCount * enc.averageBytesPerChar());\n    }\n\n}\n",
    "target": 0,
    "language": "java",
    "dataset": "vul4j",
    "idx": 200099,
    "RELATED_CWE": [
      "CWE-908",
      "CWE-362",
      "CWE-667"
    ]
  },
  {
    "CWE_ID": [
      "CWE-835"
    ],
    "code": "/*\n *  Licensed under the Apache License, Version 2.0 (the \"License\");\n *  you may not use this file except in compliance with the License.\n *  You may obtain a copy of the License at\n *\n *       http://www.apache.org/licenses/LICENSE-2.0\n *\n *  Unless required by applicable law or agreed to in writing, software\n *  distributed under the License is distributed on an \"AS IS\" BASIS,\n *  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n *  See the License for the specific language governing permissions and\n *  limitations under the License.\n *  under the License.\n */\n\npackage org.apache.commons.imaging.formats.jpeg.decoder;\n\nimport static org.apache.commons.imaging.common.BinaryFunctions.read2Bytes;\nimport static org.apache.commons.imaging.common.BinaryFunctions.readBytes;\n\nimport java.awt.image.BufferedImage;\nimport java.awt.image.ColorModel;\nimport java.awt.image.DataBuffer;\nimport java.awt.image.DirectColorModel;\nimport java.awt.image.Raster;\nimport java.awt.image.WritableRaster;\nimport java.io.ByteArrayInputStream;\nimport java.io.IOException;\nimport java.util.Arrays;\nimport java.util.Properties;\n\nimport org.apache.commons.imaging.ImageReadException;\nimport org.apache.commons.imaging.common.BinaryFileParser;\nimport org.apache.commons.imaging.common.bytesource.ByteSource;\nimport org.apache.commons.imaging.formats.jpeg.JpegConstants;\nimport org.apache.commons.imaging.formats.jpeg.JpegUtils;\nimport org.apache.commons.imaging.formats.jpeg.segments.DhtSegment;\nimport org.apache.commons.imaging.formats.jpeg.segments.DqtSegment;\nimport org.apache.commons.imaging.formats.jpeg.segments.SofnSegment;\nimport org.apache.commons.imaging.formats.jpeg.segments.SosSegment;\n\npublic class JpegDecoder extends BinaryFileParser implements JpegUtils.Visitor {\n    /*\n     * JPEG is an advanced image format that takes significant computation to\n     * decode. Keep decoding fast: - Don't allocate memory inside loops,\n     * allocate it once and reuse. - Minimize calculations per pixel and per\n     * block (using lookup tables for YCbCr->RGB conversion doubled\n     * performance). - Math.round() is slow, use (int)(x+0.5f) instead for\n     * positive numbers.\n     */\n\n    private final DqtSegment.QuantizationTable[] quantizationTables = new DqtSegment.QuantizationTable[4];\n    private final DhtSegment.HuffmanTable[] huffmanDCTables = new DhtSegment.HuffmanTable[4];\n    private final DhtSegment.HuffmanTable[] huffmanACTables = new DhtSegment.HuffmanTable[4];\n    private SofnSegment sofnSegment;\n    private SosSegment sosSegment;\n    private final float[][] scaledQuantizationTables = new float[4][];\n    private BufferedImage image;\n    private ImageReadException imageReadException;\n    private IOException ioException;\n    private final int[] zz = new int[64];\n    private final int[] blockInt = new int[64];\n    private final float[] block = new float[64];\n\n    @Override\n    public boolean beginSOS() {\n        return true;\n    }\n\n    @Override\n    public void visitSOS(final int marker, final byte[] markerBytes, final byte[] imageData) {\n        final ByteArrayInputStream is = new ByteArrayInputStream(imageData);\n        try {\n            final int segmentLength = read2Bytes(\"segmentLength\", is, \"Not a Valid JPEG File\", getByteOrder());\n            final byte[] sosSegmentBytes = readBytes(\"SosSegment\",\n                    is, segmentLength - 2, \"Not a Valid JPEG File\");\n            sosSegment = new SosSegment(marker, sosSegmentBytes);\n\n            int hMax = 0;\n            int vMax = 0;\n            for (int i = 0; i < sofnSegment.numberOfComponents; i++) {\n                hMax = Math.max(hMax,\n                        sofnSegment.getComponents(i).horizontalSamplingFactor);\n                vMax = Math.max(vMax,\n                        sofnSegment.getComponents(i).verticalSamplingFactor);\n            }\n            final int hSize = 8 * hMax;\n            final int vSize = 8 * vMax;\n\n            final JpegInputStream bitInputStream = new JpegInputStream(is);\n            final int xMCUs = (sofnSegment.width + hSize - 1) / hSize;\n            final int yMCUs = (sofnSegment.height + vSize - 1) / vSize;\n            final Block[] mcu = allocateMCUMemory();\n            final Block[] scaledMCU = new Block[mcu.length];\n            for (int i = 0; i < scaledMCU.length; i++) {\n                scaledMCU[i] = new Block(hSize, vSize);\n            }\n            final int[] preds = new int[sofnSegment.numberOfComponents];\n            ColorModel colorModel;\n            WritableRaster raster;\n            if (sofnSegment.numberOfComponents == 3) {\n                colorModel = new DirectColorModel(24, 0x00ff0000, 0x0000ff00,\n                        0x000000ff);\n                raster = Raster.createPackedRaster(DataBuffer.TYPE_INT,\n                        sofnSegment.width, sofnSegment.height, new int[] {\n                                0x00ff0000, 0x0000ff00, 0x000000ff }, null);\n            } else if (sofnSegment.numberOfComponents == 1) {\n                colorModel = new DirectColorModel(24, 0x00ff0000, 0x0000ff00,\n                        0x000000ff);\n                raster = Raster.createPackedRaster(DataBuffer.TYPE_INT,\n                        sofnSegment.width, sofnSegment.height, new int[] {\n                                0x00ff0000, 0x0000ff00, 0x000000ff }, null);\n                // FIXME: why do images come out too bright with CS_GRAY?\n                // colorModel = new ComponentColorModel(\n                // ColorSpace.getInstance(ColorSpace.CS_GRAY), false, true,\n                // Transparency.OPAQUE, DataBuffer.TYPE_BYTE);\n                // raster = colorModel.createCompatibleWritableRaster(\n                // sofnSegment.width, sofnSegment.height);\n            } else {\n                throw new ImageReadException(sofnSegment.numberOfComponents\n                        + \" components are invalid or unsupported\");\n            }\n            final DataBuffer dataBuffer = raster.getDataBuffer();\n\n            for (int y1 = 0; y1 < vSize * yMCUs; y1 += vSize) {\n                for (int x1 = 0; x1 < hSize * xMCUs; x1 += hSize) {\n                    readMCU(bitInputStream, preds, mcu);\n                    rescaleMCU(mcu, hSize, vSize, scaledMCU);\n                    int srcRowOffset = 0;\n                    int dstRowOffset = y1 * sofnSegment.width + x1;\n                    for (int y2 = 0; y2 < vSize && y1 + y2 < sofnSegment.height; y2++) {\n                        for (int x2 = 0; x2 < hSize\n                                && x1 + x2 < sofnSegment.width; x2++) {\n                            if (scaledMCU.length == 3) {\n                                final int Y = scaledMCU[0].samples[srcRowOffset + x2];\n                                final int Cb = scaledMCU[1].samples[srcRowOffset + x2];\n                                final int Cr = scaledMCU[2].samples[srcRowOffset + x2];\n                                final int rgb = YCbCrConverter.convertYCbCrToRGB(Y,\n                                        Cb, Cr);\n                                dataBuffer.setElem(dstRowOffset + x2, rgb);\n                            } else if (mcu.length == 1) {\n                                final int Y = scaledMCU[0].samples[srcRowOffset + x2];\n                                dataBuffer.setElem(dstRowOffset + x2, (Y << 16)\n                                        | (Y << 8) | Y);\n                            } else {\n                                throw new ImageReadException(\n                                        \"Unsupported JPEG with \" + mcu.length\n                                                + \" components\");\n                            }\n                        }\n                        srcRowOffset += hSize;\n                        dstRowOffset += sofnSegment.width;\n                    }\n                }\n            }\n            image = new BufferedImage(colorModel, raster,\n                    colorModel.isAlphaPremultiplied(), new Properties());\n            // byte[] remainder = super.getStreamBytes(is);\n            // for (int i = 0; i < remainder.length; i++)\n            // {\n            // System.out.println(\"\" + i + \" = \" +\n            // Integer.toHexString(remainder[i]));\n            // }\n        } catch (final ImageReadException imageReadEx) {\n            imageReadException = imageReadEx;\n        } catch (final IOException ioEx) {\n            ioException = ioEx;\n        } catch (final RuntimeException ex) {\n            // Corrupt images can throw NPE and IOOBE\n            imageReadException = new ImageReadException(\"Error parsing JPEG\",\n                    ex);\n        }\n    }\n\n    @Override\n    public boolean visitSegment(final int marker, final byte[] markerBytes,\n            final int segmentLength, final byte[] segmentLengthBytes, final byte[] segmentData)\n            throws ImageReadException, IOException {\n        final int[] sofnSegments = {\n                JpegConstants.SOF0_MARKER,\n                JpegConstants.SOF1_MARKER,\n                JpegConstants.SOF2_MARKER,\n                JpegConstants.SOF3_MARKER,\n                JpegConstants.SOF5_MARKER,\n                JpegConstants.SOF6_MARKER,\n                JpegConstants.SOF7_MARKER,\n                JpegConstants.SOF9_MARKER,\n                JpegConstants.SOF10_MARKER,\n                JpegConstants.SOF11_MARKER,\n                JpegConstants.SOF13_MARKER,\n                JpegConstants.SOF14_MARKER,\n                JpegConstants.SOF15_MARKER,\n        };\n\n        if (Arrays.binarySearch(sofnSegments, marker) >= 0) {\n            if (marker != JpegConstants.SOF0_MARKER) {\n                throw new ImageReadException(\"Only sequential, baseline JPEGs \"\n                        + \"are supported at the moment\");\n            }\n            sofnSegment = new SofnSegment(marker, segmentData);\n        } else if (marker == JpegConstants.DQT_MARKER) {\n            final DqtSegment dqtSegment = new DqtSegment(marker, segmentData);\n            for (int i = 0; i < dqtSegment.quantizationTables.size(); i++) {\n                final DqtSegment.QuantizationTable table = dqtSegment.quantizationTables.get(i);\n                if (0 > table.destinationIdentifier\n                        || table.destinationIdentifier >= quantizationTables.length) {\n                    throw new ImageReadException(\n                            \"Invalid quantization table identifier \"\n                                    + table.destinationIdentifier);\n                }\n                quantizationTables[table.destinationIdentifier] = table;\n                final int[] quantizationMatrixInt = new int[64];\n                ZigZag.zigZagToBlock(table.getElements(), quantizationMatrixInt);\n                final float[] quantizationMatrixFloat = new float[64];\n                for (int j = 0; j < 64; j++) {\n                    quantizationMatrixFloat[j] = quantizationMatrixInt[j];\n                }\n                Dct.scaleDequantizationMatrix(quantizationMatrixFloat);\n                scaledQuantizationTables[table.destinationIdentifier] = quantizationMatrixFloat;\n            }\n        } else if (marker == JpegConstants.DHT_MARKER) {\n            final DhtSegment dhtSegment = new DhtSegment(marker, segmentData);\n            for (int i = 0; i < dhtSegment.huffmanTables.size(); i++) {\n                final DhtSegment.HuffmanTable table = dhtSegment.huffmanTables.get(i);\n                DhtSegment.HuffmanTable[] tables;\n                if (table.tableClass == 0) {\n                    tables = huffmanDCTables;\n                } else if (table.tableClass == 1) {\n                    tables = huffmanACTables;\n                } else {\n                    throw new ImageReadException(\"Invalid huffman table class \"\n                            + table.tableClass);\n                }\n                if (0 > table.destinationIdentifier\n                        || table.destinationIdentifier >= tables.length) {\n                    throw new ImageReadException(\n                            \"Invalid huffman table identifier \"\n                                    + table.destinationIdentifier);\n                }\n                tables[table.destinationIdentifier] = table;\n            }\n        }\n        return true;\n    }\n\n    private void rescaleMCU(final Block[] dataUnits, final int hSize, final int vSize, final Block[] ret) {\n        for (int i = 0; i < dataUnits.length; i++) {\n            final Block dataUnit = dataUnits[i];\n            if (dataUnit.width == hSize && dataUnit.height == vSize) {\n                System.arraycopy(dataUnit.samples, 0, ret[i].samples, 0, hSize\n                        * vSize);\n            } else {\n                final int hScale = hSize / dataUnit.width;\n                final int vScale = vSize / dataUnit.height;\n                if (hScale == 2 && vScale == 2) {\n                    int srcRowOffset = 0;\n                    int dstRowOffset = 0;\n                    for (int y = 0; y < dataUnit.height; y++) {\n                        for (int x = 0; x < hSize; x++) {\n                            final int sample = dataUnit.samples[srcRowOffset + (x >> 1)];\n                            ret[i].samples[dstRowOffset + x] = sample;\n                            ret[i].samples[dstRowOffset + hSize + x] = sample;\n                        }\n                        srcRowOffset += dataUnit.width;\n                        dstRowOffset += 2 * hSize;\n                    }\n                } else {\n                    // FIXME: optimize\n                    int dstRowOffset = 0;\n                    for (int y = 0; y < vSize; y++) {\n                        for (int x = 0; x < hSize; x++) {\n                            ret[i].samples[dstRowOffset + x] = dataUnit.samples[(y / vScale)\n                                    * dataUnit.width + (x / hScale)];\n                        }\n                        dstRowOffset += hSize;\n                    }\n                }\n            }\n        }\n    }\n\n    private Block[] allocateMCUMemory() throws ImageReadException {\n        final Block[] mcu = new Block[sosSegment.numberOfComponents];\n        for (int i = 0; i < sosSegment.numberOfComponents; i++) {\n            final SosSegment.Component scanComponent = sosSegment.getComponents(i);\n            SofnSegment.Component frameComponent = null;\n            for (int j = 0; j < sofnSegment.numberOfComponents; j++) {\n                if (sofnSegment.getComponents(j).componentIdentifier == scanComponent.scanComponentSelector) {\n                    frameComponent = sofnSegment.getComponents(j);\n                    break;\n                }\n            }\n            if (frameComponent == null) {\n                throw new ImageReadException(\"Invalid component\");\n            }\n            final Block fullBlock = new Block(\n                    8 * frameComponent.horizontalSamplingFactor,\n                    8 * frameComponent.verticalSamplingFactor);\n            mcu[i] = fullBlock;\n        }\n        return mcu;\n    }\n\n    private void readMCU(final JpegInputStream is, final int[] preds, final Block[] mcu)\n            throws IOException, ImageReadException {\n        for (int i = 0; i < sosSegment.numberOfComponents; i++) {\n            final SosSegment.Component scanComponent = sosSegment.getComponents(i);\n            SofnSegment.Component frameComponent = null;\n            for (int j = 0; j < sofnSegment.numberOfComponents; j++) {\n                if (sofnSegment.getComponents(j).componentIdentifier == scanComponent.scanComponentSelector) {\n                    frameComponent = sofnSegment.getComponents(j);\n                    break;\n                }\n            }\n            if (frameComponent == null) {\n                throw new ImageReadException(\"Invalid component\");\n            }\n            final Block fullBlock = mcu[i];\n            for (int y = 0; y < frameComponent.verticalSamplingFactor; y++) {\n                for (int x = 0; x < frameComponent.horizontalSamplingFactor; x++) {\n                    Arrays.fill(zz, 0);\n                    // page 104 of T.81\n                    final int t = decode(\n                            is,\n                            huffmanDCTables[scanComponent.dcCodingTableSelector]);\n                    int diff = receive(t, is);\n                    diff = extend(diff, t);\n                    zz[0] = preds[i] + diff;\n                    preds[i] = zz[0];\n\n                    // \"Decode_AC_coefficients\", figure F.13, page 106 of T.81\n                    int k = 1;\n                    while (true) {\n                        final int rs = decode(\n                                is,\n                                huffmanACTables[scanComponent.acCodingTableSelector]);\n                        final int ssss = rs & 0xf;\n                        final int rrrr = rs >> 4;\n                        final int r = rrrr;\n\n                        if (ssss == 0) {\n                            if (r == 15) {\n                                k += 16;\n                            } else {\n                                break;\n                            }\n                        } else {\n                            k += r;\n\n                            // \"Decode_ZZ(k)\", figure F.14, page 107 of T.81\n                            zz[k] = receive(ssss, is);\n                            zz[k] = extend(zz[k], ssss);\n\n                            if (k == 63) {\n                                break;\n                            } else {\n                                k++;\n                            }\n                        }\n                    }\n\n                    final int shift = (1 << (sofnSegment.precision - 1));\n                    final int max = (1 << sofnSegment.precision) - 1;\n\n                    final float[] scaledQuantizationTable = scaledQuantizationTables[frameComponent.quantTabDestSelector];\n                    ZigZag.zigZagToBlock(zz, blockInt);\n                    for (int j = 0; j < 64; j++) {\n                        block[j] = blockInt[j] * scaledQuantizationTable[j];\n                    }\n                    Dct.inverseDCT8x8(block);\n\n                    int dstRowOffset = 8 * y * 8\n                            * frameComponent.horizontalSamplingFactor + 8 * x;\n                    int srcNext = 0;\n                    for (int yy = 0; yy < 8; yy++) {\n                        for (int xx = 0; xx < 8; xx++) {\n                            float sample = block[srcNext++];\n                            sample += shift;\n                            int result;\n                            if (sample < 0) {\n                                result = 0;\n                            } else if (sample > max) {\n                                result = max;\n                            } else {\n                                result = fastRound(sample);\n                            }\n                            fullBlock.samples[dstRowOffset + xx] = result;\n                        }\n                        dstRowOffset += 8 * frameComponent.horizontalSamplingFactor;\n                    }\n                }\n            }\n        }\n    }\n\n    private static int fastRound(final float x) {\n        return (int) (x + 0.5f);\n    }\n\n    private int extend(int v, final int t) {\n        // \"EXTEND\", section F.2.2.1, figure F.12, page 105 of T.81\n        int vt = (1 << (t - 1));\n        while (v < vt) {\n            vt = (-1 << t) + 1;\n            v += vt;\n        }\n        return v;\n    }\n\n    private int receive(final int ssss, final JpegInputStream is) throws IOException,\n            ImageReadException {\n        // \"RECEIVE\", section F.2.2.4, figure F.17, page 110 of T.81\n        int i = 0;\n        int v = 0;\n        while (i != ssss) {\n            i++;\n            v = (v << 1) + is.nextBit();\n        }\n        return v;\n    }\n\n    private int decode(final JpegInputStream is, final DhtSegment.HuffmanTable huffmanTable)\n            throws IOException, ImageReadException {\n        // \"DECODE\", section F.2.2.3, figure F.16, page 109 of T.81\n        int i = 1;\n        int code = is.nextBit();\n        while (code > huffmanTable.getMaxCode(i)) {\n            i++;\n            code = (code << 1) | is.nextBit();\n        }\n        int j = huffmanTable.getValPtr(i);\n        j += code - huffmanTable.getMinCode(i);\n        return huffmanTable.getHuffVal(j);\n    }\n\n    public BufferedImage decode(final ByteSource byteSource) throws IOException,\n            ImageReadException {\n        final JpegUtils jpegUtils = new JpegUtils();\n        jpegUtils.traverseJFIF(byteSource, this);\n        if (imageReadException != null) {\n            throw imageReadException;\n        }\n        if (ioException != null) {\n            throw ioException;\n        }\n        return image;\n    }\n}\n",
    "target": 1,
    "language": "java",
    "dataset": "vul4j",
    "idx": 200102,
    "RELATED_CWE": [
      "CWE-908",
      "CWE-362",
      "CWE-667"
    ]
  },
  {
    "CWE_ID": [
      "CWE-835"
    ],
    "code": "/*\n *  Licensed under the Apache License, Version 2.0 (the \"License\");\n *  you may not use this file except in compliance with the License.\n *  You may obtain a copy of the License at\n *\n *       http://www.apache.org/licenses/LICENSE-2.0\n *\n *  Unless required by applicable law or agreed to in writing, software\n *  distributed under the License is distributed on an \"AS IS\" BASIS,\n *  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n *  See the License for the specific language governing permissions and\n *  limitations under the License.\n *  under the License.\n */\n\npackage org.apache.commons.imaging.formats.jpeg.decoder;\n\nimport static org.apache.commons.imaging.common.BinaryFunctions.read2Bytes;\nimport static org.apache.commons.imaging.common.BinaryFunctions.readBytes;\n\nimport java.awt.image.BufferedImage;\nimport java.awt.image.ColorModel;\nimport java.awt.image.DataBuffer;\nimport java.awt.image.DirectColorModel;\nimport java.awt.image.Raster;\nimport java.awt.image.WritableRaster;\nimport java.io.ByteArrayInputStream;\nimport java.io.IOException;\nimport java.util.Arrays;\nimport java.util.Properties;\n\nimport org.apache.commons.imaging.ImageReadException;\nimport org.apache.commons.imaging.common.BinaryFileParser;\nimport org.apache.commons.imaging.common.bytesource.ByteSource;\nimport org.apache.commons.imaging.formats.jpeg.JpegConstants;\nimport org.apache.commons.imaging.formats.jpeg.JpegUtils;\nimport org.apache.commons.imaging.formats.jpeg.segments.DhtSegment;\nimport org.apache.commons.imaging.formats.jpeg.segments.DqtSegment;\nimport org.apache.commons.imaging.formats.jpeg.segments.SofnSegment;\nimport org.apache.commons.imaging.formats.jpeg.segments.SosSegment;\n\npublic class JpegDecoder extends BinaryFileParser implements JpegUtils.Visitor {\n    /*\n     * JPEG is an advanced image format that takes significant computation to\n     * decode. Keep decoding fast: - Don't allocate memory inside loops,\n     * allocate it once and reuse. - Minimize calculations per pixel and per\n     * block (using lookup tables for YCbCr->RGB conversion doubled\n     * performance). - Math.round() is slow, use (int)(x+0.5f) instead for\n     * positive numbers.\n     */\n\n    private final DqtSegment.QuantizationTable[] quantizationTables = new DqtSegment.QuantizationTable[4];\n    private final DhtSegment.HuffmanTable[] huffmanDCTables = new DhtSegment.HuffmanTable[4];\n    private final DhtSegment.HuffmanTable[] huffmanACTables = new DhtSegment.HuffmanTable[4];\n    private SofnSegment sofnSegment;\n    private SosSegment sosSegment;\n    private final float[][] scaledQuantizationTables = new float[4][];\n    private BufferedImage image;\n    private ImageReadException imageReadException;\n    private IOException ioException;\n    private final int[] zz = new int[64];\n    private final int[] blockInt = new int[64];\n    private final float[] block = new float[64];\n\n    @Override\n    public boolean beginSOS() {\n        return true;\n    }\n\n    @Override\n    public void visitSOS(final int marker, final byte[] markerBytes, final byte[] imageData) {\n        final ByteArrayInputStream is = new ByteArrayInputStream(imageData);\n        try {\n            final int segmentLength = read2Bytes(\"segmentLength\", is, \"Not a Valid JPEG File\", getByteOrder());\n            final byte[] sosSegmentBytes = readBytes(\"SosSegment\",\n                    is, segmentLength - 2, \"Not a Valid JPEG File\");\n            sosSegment = new SosSegment(marker, sosSegmentBytes);\n\n            int hMax = 0;\n            int vMax = 0;\n            for (int i = 0; i < sofnSegment.numberOfComponents; i++) {\n                hMax = Math.max(hMax,\n                        sofnSegment.getComponents(i).horizontalSamplingFactor);\n                vMax = Math.max(vMax,\n                        sofnSegment.getComponents(i).verticalSamplingFactor);\n            }\n            final int hSize = 8 * hMax;\n            final int vSize = 8 * vMax;\n\n            final JpegInputStream bitInputStream = new JpegInputStream(is);\n            final int xMCUs = (sofnSegment.width + hSize - 1) / hSize;\n            final int yMCUs = (sofnSegment.height + vSize - 1) / vSize;\n            final Block[] mcu = allocateMCUMemory();\n            final Block[] scaledMCU = new Block[mcu.length];\n            for (int i = 0; i < scaledMCU.length; i++) {\n                scaledMCU[i] = new Block(hSize, vSize);\n            }\n            final int[] preds = new int[sofnSegment.numberOfComponents];\n            ColorModel colorModel;\n            WritableRaster raster;\n            if (sofnSegment.numberOfComponents == 3) {\n                colorModel = new DirectColorModel(24, 0x00ff0000, 0x0000ff00,\n                        0x000000ff);\n                raster = Raster.createPackedRaster(DataBuffer.TYPE_INT,\n                        sofnSegment.width, sofnSegment.height, new int[] {\n                                0x00ff0000, 0x0000ff00, 0x000000ff }, null);\n            } else if (sofnSegment.numberOfComponents == 1) {\n                colorModel = new DirectColorModel(24, 0x00ff0000, 0x0000ff00,\n                        0x000000ff);\n                raster = Raster.createPackedRaster(DataBuffer.TYPE_INT,\n                        sofnSegment.width, sofnSegment.height, new int[] {\n                                0x00ff0000, 0x0000ff00, 0x000000ff }, null);\n                // FIXME: why do images come out too bright with CS_GRAY?\n                // colorModel = new ComponentColorModel(\n                // ColorSpace.getInstance(ColorSpace.CS_GRAY), false, true,\n                // Transparency.OPAQUE, DataBuffer.TYPE_BYTE);\n                // raster = colorModel.createCompatibleWritableRaster(\n                // sofnSegment.width, sofnSegment.height);\n            } else {\n                throw new ImageReadException(sofnSegment.numberOfComponents\n                        + \" components are invalid or unsupported\");\n            }\n            final DataBuffer dataBuffer = raster.getDataBuffer();\n\n            for (int y1 = 0; y1 < vSize * yMCUs; y1 += vSize) {\n                for (int x1 = 0; x1 < hSize * xMCUs; x1 += hSize) {\n                    readMCU(bitInputStream, preds, mcu);\n                    rescaleMCU(mcu, hSize, vSize, scaledMCU);\n                    int srcRowOffset = 0;\n                    int dstRowOffset = y1 * sofnSegment.width + x1;\n                    for (int y2 = 0; y2 < vSize && y1 + y2 < sofnSegment.height; y2++) {\n                        for (int x2 = 0; x2 < hSize\n                                && x1 + x2 < sofnSegment.width; x2++) {\n                            if (scaledMCU.length == 3) {\n                                final int Y = scaledMCU[0].samples[srcRowOffset + x2];\n                                final int Cb = scaledMCU[1].samples[srcRowOffset + x2];\n                                final int Cr = scaledMCU[2].samples[srcRowOffset + x2];\n                                final int rgb = YCbCrConverter.convertYCbCrToRGB(Y,\n                                        Cb, Cr);\n                                dataBuffer.setElem(dstRowOffset + x2, rgb);\n                            } else if (mcu.length == 1) {\n                                final int Y = scaledMCU[0].samples[srcRowOffset + x2];\n                                dataBuffer.setElem(dstRowOffset + x2, (Y << 16)\n                                        | (Y << 8) | Y);\n                            } else {\n                                throw new ImageReadException(\n                                        \"Unsupported JPEG with \" + mcu.length\n                                                + \" components\");\n                            }\n                        }\n                        srcRowOffset += hSize;\n                        dstRowOffset += sofnSegment.width;\n                    }\n                }\n            }\n            image = new BufferedImage(colorModel, raster,\n                    colorModel.isAlphaPremultiplied(), new Properties());\n            // byte[] remainder = super.getStreamBytes(is);\n            // for (int i = 0; i < remainder.length; i++)\n            // {\n            // System.out.println(\"\" + i + \" = \" +\n            // Integer.toHexString(remainder[i]));\n            // }\n        } catch (final ImageReadException imageReadEx) {\n            imageReadException = imageReadEx;\n        } catch (final IOException ioEx) {\n            ioException = ioEx;\n        } catch (final RuntimeException ex) {\n            // Corrupt images can throw NPE and IOOBE\n            imageReadException = new ImageReadException(\"Error parsing JPEG\",\n                    ex);\n        }\n    }\n\n    @Override\n    public boolean visitSegment(final int marker, final byte[] markerBytes,\n            final int segmentLength, final byte[] segmentLengthBytes, final byte[] segmentData)\n            throws ImageReadException, IOException {\n        final int[] sofnSegments = {\n                JpegConstants.SOF0_MARKER,\n                JpegConstants.SOF1_MARKER,\n                JpegConstants.SOF2_MARKER,\n                JpegConstants.SOF3_MARKER,\n                JpegConstants.SOF5_MARKER,\n                JpegConstants.SOF6_MARKER,\n                JpegConstants.SOF7_MARKER,\n                JpegConstants.SOF9_MARKER,\n                JpegConstants.SOF10_MARKER,\n                JpegConstants.SOF11_MARKER,\n                JpegConstants.SOF13_MARKER,\n                JpegConstants.SOF14_MARKER,\n                JpegConstants.SOF15_MARKER,\n        };\n\n        if (Arrays.binarySearch(sofnSegments, marker) >= 0) {\n            if (marker != JpegConstants.SOF0_MARKER) {\n                throw new ImageReadException(\"Only sequential, baseline JPEGs \"\n                        + \"are supported at the moment\");\n            }\n            sofnSegment = new SofnSegment(marker, segmentData);\n        } else if (marker == JpegConstants.DQT_MARKER) {\n            final DqtSegment dqtSegment = new DqtSegment(marker, segmentData);\n            for (int i = 0; i < dqtSegment.quantizationTables.size(); i++) {\n                final DqtSegment.QuantizationTable table = dqtSegment.quantizationTables.get(i);\n                if (0 > table.destinationIdentifier\n                        || table.destinationIdentifier >= quantizationTables.length) {\n                    throw new ImageReadException(\n                            \"Invalid quantization table identifier \"\n                                    + table.destinationIdentifier);\n                }\n                quantizationTables[table.destinationIdentifier] = table;\n                final int[] quantizationMatrixInt = new int[64];\n                ZigZag.zigZagToBlock(table.getElements(), quantizationMatrixInt);\n                final float[] quantizationMatrixFloat = new float[64];\n                for (int j = 0; j < 64; j++) {\n                    quantizationMatrixFloat[j] = quantizationMatrixInt[j];\n                }\n                Dct.scaleDequantizationMatrix(quantizationMatrixFloat);\n                scaledQuantizationTables[table.destinationIdentifier] = quantizationMatrixFloat;\n            }\n        } else if (marker == JpegConstants.DHT_MARKER) {\n            final DhtSegment dhtSegment = new DhtSegment(marker, segmentData);\n            for (int i = 0; i < dhtSegment.huffmanTables.size(); i++) {\n                final DhtSegment.HuffmanTable table = dhtSegment.huffmanTables.get(i);\n                DhtSegment.HuffmanTable[] tables;\n                if (table.tableClass == 0) {\n                    tables = huffmanDCTables;\n                } else if (table.tableClass == 1) {\n                    tables = huffmanACTables;\n                } else {\n                    throw new ImageReadException(\"Invalid huffman table class \"\n                            + table.tableClass);\n                }\n                if (0 > table.destinationIdentifier\n                        || table.destinationIdentifier >= tables.length) {\n                    throw new ImageReadException(\n                            \"Invalid huffman table identifier \"\n                                    + table.destinationIdentifier);\n                }\n                tables[table.destinationIdentifier] = table;\n            }\n        }\n        return true;\n    }\n\n    private void rescaleMCU(final Block[] dataUnits, final int hSize, final int vSize, final Block[] ret) {\n        for (int i = 0; i < dataUnits.length; i++) {\n            final Block dataUnit = dataUnits[i];\n            if (dataUnit.width == hSize && dataUnit.height == vSize) {\n                System.arraycopy(dataUnit.samples, 0, ret[i].samples, 0, hSize\n                        * vSize);\n            } else {\n                final int hScale = hSize / dataUnit.width;\n                final int vScale = vSize / dataUnit.height;\n                if (hScale == 2 && vScale == 2) {\n                    int srcRowOffset = 0;\n                    int dstRowOffset = 0;\n                    for (int y = 0; y < dataUnit.height; y++) {\n                        for (int x = 0; x < hSize; x++) {\n                            final int sample = dataUnit.samples[srcRowOffset + (x >> 1)];\n                            ret[i].samples[dstRowOffset + x] = sample;\n                            ret[i].samples[dstRowOffset + hSize + x] = sample;\n                        }\n                        srcRowOffset += dataUnit.width;\n                        dstRowOffset += 2 * hSize;\n                    }\n                } else {\n                    // FIXME: optimize\n                    int dstRowOffset = 0;\n                    for (int y = 0; y < vSize; y++) {\n                        for (int x = 0; x < hSize; x++) {\n                            ret[i].samples[dstRowOffset + x] = dataUnit.samples[(y / vScale)\n                                    * dataUnit.width + (x / hScale)];\n                        }\n                        dstRowOffset += hSize;\n                    }\n                }\n            }\n        }\n    }\n\n    private Block[] allocateMCUMemory() throws ImageReadException {\n        final Block[] mcu = new Block[sosSegment.numberOfComponents];\n        for (int i = 0; i < sosSegment.numberOfComponents; i++) {\n            final SosSegment.Component scanComponent = sosSegment.getComponents(i);\n            SofnSegment.Component frameComponent = null;\n            for (int j = 0; j < sofnSegment.numberOfComponents; j++) {\n                if (sofnSegment.getComponents(j).componentIdentifier == scanComponent.scanComponentSelector) {\n                    frameComponent = sofnSegment.getComponents(j);\n                    break;\n                }\n            }\n            if (frameComponent == null) {\n                throw new ImageReadException(\"Invalid component\");\n            }\n            final Block fullBlock = new Block(\n                    8 * frameComponent.horizontalSamplingFactor,\n                    8 * frameComponent.verticalSamplingFactor);\n            mcu[i] = fullBlock;\n        }\n        return mcu;\n    }\n\n    private void readMCU(final JpegInputStream is, final int[] preds, final Block[] mcu)\n            throws IOException, ImageReadException {\n        for (int i = 0; i < sosSegment.numberOfComponents; i++) {\n            final SosSegment.Component scanComponent = sosSegment.getComponents(i);\n            SofnSegment.Component frameComponent = null;\n            for (int j = 0; j < sofnSegment.numberOfComponents; j++) {\n                if (sofnSegment.getComponents(j).componentIdentifier == scanComponent.scanComponentSelector) {\n                    frameComponent = sofnSegment.getComponents(j);\n                    break;\n                }\n            }\n            if (frameComponent == null) {\n                throw new ImageReadException(\"Invalid component\");\n            }\n            final Block fullBlock = mcu[i];\n            for (int y = 0; y < frameComponent.verticalSamplingFactor; y++) {\n                for (int x = 0; x < frameComponent.horizontalSamplingFactor; x++) {\n                    Arrays.fill(zz, 0);\n                    // page 104 of T.81\n                    final int t = decode(\n                            is,\n                            huffmanDCTables[scanComponent.dcCodingTableSelector]);\n                    int diff = receive(t, is);\n                    diff = extend(diff, t);\n                    zz[0] = preds[i] + diff;\n                    preds[i] = zz[0];\n\n                    // \"Decode_AC_coefficients\", figure F.13, page 106 of T.81\n                    int k = 1;\n                    while (true) {\n                        final int rs = decode(\n                                is,\n                                huffmanACTables[scanComponent.acCodingTableSelector]);\n                        final int ssss = rs & 0xf;\n                        final int rrrr = rs >> 4;\n                        final int r = rrrr;\n\n                        if (ssss == 0) {\n                            if (r == 15) {\n                                k += 16;\n                            } else {\n                                break;\n                            }\n                        } else {\n                            k += r;\n\n                            // \"Decode_ZZ(k)\", figure F.14, page 107 of T.81\n                            zz[k] = receive(ssss, is);\n                            zz[k] = extend(zz[k], ssss);\n\n                            if (k == 63) {\n                                break;\n                            } else {\n                                k++;\n                            }\n                        }\n                    }\n\n                    final int shift = (1 << (sofnSegment.precision - 1));\n                    final int max = (1 << sofnSegment.precision) - 1;\n\n                    final float[] scaledQuantizationTable = scaledQuantizationTables[frameComponent.quantTabDestSelector];\n                    ZigZag.zigZagToBlock(zz, blockInt);\n                    for (int j = 0; j < 64; j++) {\n                        block[j] = blockInt[j] * scaledQuantizationTable[j];\n                    }\n                    Dct.inverseDCT8x8(block);\n\n                    int dstRowOffset = 8 * y * 8\n                            * frameComponent.horizontalSamplingFactor + 8 * x;\n                    int srcNext = 0;\n                    for (int yy = 0; yy < 8; yy++) {\n                        for (int xx = 0; xx < 8; xx++) {\n                            float sample = block[srcNext++];\n                            sample += shift;\n                            int result;\n                            if (sample < 0) {\n                                result = 0;\n                            } else if (sample > max) {\n                                result = max;\n                            } else {\n                                result = fastRound(sample);\n                            }\n                            fullBlock.samples[dstRowOffset + xx] = result;\n                        }\n                        dstRowOffset += 8 * frameComponent.horizontalSamplingFactor;\n                    }\n                }\n            }\n        }\n    }\n\n    private static int fastRound(final float x) {\n        return (int) (x + 0.5f);\n    }\n\n    private int extend(int v, final int t) {\n        // \"EXTEND\", section F.2.2.1, figure F.12, page 105 of T.81\n        int vt = (1 << (t - 1));\n        if (v < vt) {\n            vt = (-1 << t) + 1;\n            v += vt;\n        }\n        return v;\n    }\n\n    private int receive(final int ssss, final JpegInputStream is) throws IOException,\n            ImageReadException {\n        // \"RECEIVE\", section F.2.2.4, figure F.17, page 110 of T.81\n        int i = 0;\n        int v = 0;\n        while (i != ssss) {\n            i++;\n            v = (v << 1) + is.nextBit();\n        }\n        return v;\n    }\n\n    private int decode(final JpegInputStream is, final DhtSegment.HuffmanTable huffmanTable)\n            throws IOException, ImageReadException {\n        // \"DECODE\", section F.2.2.3, figure F.16, page 109 of T.81\n        int i = 1;\n        int code = is.nextBit();\n        while (code > huffmanTable.getMaxCode(i)) {\n            i++;\n            code = (code << 1) | is.nextBit();\n        }\n        int j = huffmanTable.getValPtr(i);\n        j += code - huffmanTable.getMinCode(i);\n        return huffmanTable.getHuffVal(j);\n    }\n\n    public BufferedImage decode(final ByteSource byteSource) throws IOException,\n            ImageReadException {\n        final JpegUtils jpegUtils = new JpegUtils();\n        jpegUtils.traverseJFIF(byteSource, this);\n        if (imageReadException != null) {\n            throw imageReadException;\n        }\n        if (ioException != null) {\n            throw ioException;\n        }\n        return image;\n    }\n}\n",
    "target": 0,
    "language": "java",
    "dataset": "vul4j",
    "idx": 200103,
    "RELATED_CWE": [
      "CWE-908",
      "CWE-362",
      "CWE-667"
    ]
  },
  {
    "CWE_ID": [
      "CWE-835"
    ],
    "code": "/*\n * Licensed to the Apache Software Foundation (ASF) under one or more\n * contributor license agreements.  See the NOTICE file distributed with\n * this work for additional information regarding copyright ownership.\n * The ASF licenses this file to You under the Apache License, Version 2.0\n * (the \"License\"); you may not use this file except in compliance with\n * the License.  You may obtain a copy of the License at\n *\n *      http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\npackage org.apache.commons.imaging.formats.rgbe;\n\nimport java.io.Closeable;\nimport java.io.IOException;\nimport java.io.InputStream;\nimport java.nio.ByteOrder;\nimport java.util.regex.Matcher;\nimport java.util.regex.Pattern;\n\nimport org.apache.commons.imaging.ImageReadException;\nimport org.apache.commons.imaging.common.BinaryFunctions;\nimport org.apache.commons.imaging.common.ByteConversions;\nimport org.apache.commons.imaging.common.ImageMetadata;\nimport org.apache.commons.imaging.common.GenericImageMetadata;\nimport org.apache.commons.imaging.common.bytesource.ByteSource;\n\nclass RgbeInfo implements Closeable {\n    // #?RADIANCE\n    private static final byte[] HEADER = new byte[] {\n        0x23, 0x3F, 0x52, 0x41, 0x44, 0x49, 0x41, 0x4E, 0x43, 0x45\n    };\n    private static final Pattern RESOLUTION_STRING = Pattern.compile(\"-Y (\\\\d+) \\\\+X (\\\\d+)\");\n\n    private final InputStream in;\n    private GenericImageMetadata metadata;\n    private int width = -1;\n    private int height = -1;\n    private static final byte[] TWO_TWO = new byte[] { 0x2, 0x2 };\n\n    RgbeInfo(final ByteSource byteSource) throws IOException {\n        this.in = byteSource.getInputStream();\n    }\n\n    ImageMetadata getMetadata() throws IOException, ImageReadException {\n        if (null == metadata) {\n            readMetadata();\n        }\n\n        return metadata;\n    }\n\n    int getWidth() throws IOException, ImageReadException {\n        if (-1 == width) {\n            readDimensions();\n        }\n\n        return width;\n    }\n\n    int getHeight() throws IOException, ImageReadException {\n        if (-1 == height) {\n            readDimensions();\n        }\n\n        return height;\n    }\n\n    @Override\n    public void close() throws IOException {\n        in.close();\n    }\n\n    private void readDimensions() throws IOException, ImageReadException {\n        getMetadata(); // Ensure we've read past this\n\n        final InfoHeaderReader reader = new InfoHeaderReader(in);\n        final String resolution = reader.readNextLine();\n        final Matcher matcher = RESOLUTION_STRING.matcher(resolution);\n\n        if (!matcher.matches()) {\n            throw new ImageReadException(\n                    \"Invalid HDR resolution string. Only \\\"-Y N +X M\\\" is supported. Found \\\"\"\n                            + resolution + \"\\\"\");\n        }\n\n        height = Integer.parseInt(matcher.group(1));\n        width = Integer.parseInt(matcher.group(2));\n    }\n\n    private void readMetadata() throws IOException, ImageReadException {\n        BinaryFunctions.readAndVerifyBytes(in, HEADER, \"Not a valid HDR: Incorrect Header\");\n\n        final InfoHeaderReader reader = new InfoHeaderReader(in);\n\n        if (reader.readNextLine().length() != 0) {\n            throw new ImageReadException(\"Not a valid HDR: Incorrect Header\");\n        }\n\n        metadata = new GenericImageMetadata();\n\n        String info = reader.readNextLine();\n\n        while (info.length() != 0) {\n            final int equals = info.indexOf('=');\n\n            if (equals > 0) {\n                final String variable = info.substring(0, equals);\n                final String value = info.substring(equals + 1);\n\n                if (\"FORMAT\".equals(value) && !\"32-bit_rle_rgbe\".equals(value)) {\n                    throw new ImageReadException(\"Only 32-bit_rle_rgbe images are supported, trying to read \" + value);\n                }\n\n                metadata.add(variable, value);\n            } else {\n                metadata.add(\"<command>\", info);\n            }\n\n            info = reader.readNextLine();\n        }\n    }\n\n    public float[][] getPixelData() throws IOException, ImageReadException {\n        // Read into local variables to ensure that we have seeked into the file\n        // far enough\n        final int ht = getHeight();\n        final int wd = getWidth();\n\n        if (wd >= 32768) {\n            throw new ImageReadException(\"Scan lines must be less than 32768 bytes long\");\n        }\n\n        final byte[] scanLineBytes = ByteConversions.toBytes((short) wd,\n                ByteOrder.BIG_ENDIAN);\n        final byte[] rgbe = new byte[wd * 4];\n        final float[][] out = new float[3][wd * ht];\n\n        for (int i = 0; i < ht; i++) {\n            BinaryFunctions.readAndVerifyBytes(in, TWO_TWO, \"Scan line \" + i + \" expected to start with 0x2 0x2\");\n            BinaryFunctions.readAndVerifyBytes(in, scanLineBytes, \"Scan line \" + i + \" length expected\");\n\n            decompress(in, rgbe);\n\n            for (int channel = 0; channel < 3; channel++) {\n                final int channelOffset = channel * wd;\n                final int eOffset = 3 * wd;\n\n                for (int p = 0; p < wd; p++) {\n                    final int mantissa = rgbe[p + eOffset] & 0xff;\n                    final int pos = p + i * wd;\n\n                    if (0 == mantissa) {\n                        out[channel][pos] = 0;\n                    } else {\n                        final float mult = (float) Math.pow(2, mantissa - (128 + 8));\n                        out[channel][pos] = ((rgbe[p + channelOffset] & 0xff) + 0.5f) * mult;\n                    }\n                }\n            }\n        }\n\n        return out;\n    }\n\n    private static void decompress(final InputStream in, final byte[] out)\n            throws IOException {\n        int position = 0;\n        final int total = out.length;\n\n        while (position < total) {\n            final int n = in.read();\n\n            if (n > 128) {\n                final int value = in.read();\n\n                for (int i = 0; i < (n & 0x7f); i++) {\n                    out[position++] = (byte) value;\n                }\n            } else {\n                for (int i = 0; i < n; i++) {\n                    out[position++] = (byte) in.read();\n                }\n            }\n        }\n    }\n}\n",
    "target": 1,
    "language": "java",
    "dataset": "vul4j",
    "idx": 200104,
    "RELATED_CWE": [
      "CWE-908",
      "CWE-362",
      "CWE-667"
    ]
  },
  {
    "CWE_ID": [
      "CWE-835"
    ],
    "code": "/*\n * Licensed to the Apache Software Foundation (ASF) under one or more\n * contributor license agreements.  See the NOTICE file distributed with\n * this work for additional information regarding copyright ownership.\n * The ASF licenses this file to You under the Apache License, Version 2.0\n * (the \"License\"); you may not use this file except in compliance with\n * the License.  You may obtain a copy of the License at\n *\n *      http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\npackage org.apache.commons.imaging.formats.rgbe;\n\nimport java.io.Closeable;\nimport java.io.IOException;\nimport java.io.InputStream;\nimport java.nio.ByteOrder;\nimport java.util.regex.Matcher;\nimport java.util.regex.Pattern;\n\nimport org.apache.commons.imaging.ImageReadException;\nimport org.apache.commons.imaging.common.BinaryFunctions;\nimport org.apache.commons.imaging.common.ByteConversions;\nimport org.apache.commons.imaging.common.ImageMetadata;\nimport org.apache.commons.imaging.common.GenericImageMetadata;\nimport org.apache.commons.imaging.common.bytesource.ByteSource;\n\nclass RgbeInfo implements Closeable {\n    // #?RADIANCE\n    private static final byte[] HEADER = new byte[] {\n        0x23, 0x3F, 0x52, 0x41, 0x44, 0x49, 0x41, 0x4E, 0x43, 0x45\n    };\n    private static final Pattern RESOLUTION_STRING = Pattern.compile(\"-Y (\\\\d+) \\\\+X (\\\\d+)\");\n\n    private final InputStream in;\n    private GenericImageMetadata metadata;\n    private int width = -1;\n    private int height = -1;\n    private static final byte[] TWO_TWO = new byte[] { 0x2, 0x2 };\n\n    RgbeInfo(final ByteSource byteSource) throws IOException {\n        this.in = byteSource.getInputStream();\n    }\n\n    ImageMetadata getMetadata() throws IOException, ImageReadException {\n        if (null == metadata) {\n            readMetadata();\n        }\n\n        return metadata;\n    }\n\n    int getWidth() throws IOException, ImageReadException {\n        if (-1 == width) {\n            readDimensions();\n        }\n\n        return width;\n    }\n\n    int getHeight() throws IOException, ImageReadException {\n        if (-1 == height) {\n            readDimensions();\n        }\n\n        return height;\n    }\n\n    @Override\n    public void close() throws IOException {\n        in.close();\n    }\n\n    private void readDimensions() throws IOException, ImageReadException {\n        getMetadata(); // Ensure we've read past this\n\n        final InfoHeaderReader reader = new InfoHeaderReader(in);\n        final String resolution = reader.readNextLine();\n        final Matcher matcher = RESOLUTION_STRING.matcher(resolution);\n\n        if (!matcher.matches()) {\n            throw new ImageReadException(\n                    \"Invalid HDR resolution string. Only \\\"-Y N +X M\\\" is supported. Found \\\"\"\n                            + resolution + \"\\\"\");\n        }\n\n        height = Integer.parseInt(matcher.group(1));\n        width = Integer.parseInt(matcher.group(2));\n    }\n\n    private void readMetadata() throws IOException, ImageReadException {\n        BinaryFunctions.readAndVerifyBytes(in, HEADER, \"Not a valid HDR: Incorrect Header\");\n\n        final InfoHeaderReader reader = new InfoHeaderReader(in);\n\n        if (reader.readNextLine().length() != 0) {\n            throw new ImageReadException(\"Not a valid HDR: Incorrect Header\");\n        }\n\n        metadata = new GenericImageMetadata();\n\n        String info = reader.readNextLine();\n\n        while (info.length() != 0) {\n            final int equals = info.indexOf('=');\n\n            if (equals > 0) {\n                final String variable = info.substring(0, equals);\n                final String value = info.substring(equals + 1);\n\n                if (\"FORMAT\".equals(value) && !\"32-bit_rle_rgbe\".equals(value)) {\n                    throw new ImageReadException(\"Only 32-bit_rle_rgbe images are supported, trying to read \" + value);\n                }\n\n                metadata.add(variable, value);\n            } else {\n                metadata.add(\"<command>\", info);\n            }\n\n            info = reader.readNextLine();\n        }\n    }\n\n    public float[][] getPixelData() throws IOException, ImageReadException {\n        // Read into local variables to ensure that we have seeked into the file\n        // far enough\n        final int ht = getHeight();\n        final int wd = getWidth();\n\n        if (wd >= 32768) {\n            throw new ImageReadException(\"Scan lines must be less than 32768 bytes long\");\n        }\n\n        final byte[] scanLineBytes = ByteConversions.toBytes((short) wd,\n                ByteOrder.BIG_ENDIAN);\n        final byte[] rgbe = new byte[wd * 4];\n        final float[][] out = new float[3][wd * ht];\n\n        for (int i = 0; i < ht; i++) {\n            BinaryFunctions.readAndVerifyBytes(in, TWO_TWO, \"Scan line \" + i + \" expected to start with 0x2 0x2\");\n            BinaryFunctions.readAndVerifyBytes(in, scanLineBytes, \"Scan line \" + i + \" length expected\");\n\n            decompress(in, rgbe);\n\n            for (int channel = 0; channel < 3; channel++) {\n                final int channelOffset = channel * wd;\n                final int eOffset = 3 * wd;\n\n                for (int p = 0; p < wd; p++) {\n                    final int mantissa = rgbe[p + eOffset] & 0xff;\n                    final int pos = p + i * wd;\n\n                    if (0 == mantissa) {\n                        out[channel][pos] = 0;\n                    } else {\n                        final float mult = (float) Math.pow(2, mantissa - (128 + 8));\n                        out[channel][pos] = ((rgbe[p + channelOffset] & 0xff) + 0.5f) * mult;\n                    }\n                }\n            }\n        }\n\n        return out;\n    }\n\n    private static void decompress(final InputStream in, final byte[] out)\n            throws IOException,ImageReadException {\n        int position = 0;\n        final int total = out.length;\n\n        while (position < total) {\n            final int n = in.read();\n\n            if (n < 0) {\n                throw new ImageReadException(\"Error decompressing RGBE file\");\n            }\n\n            if (n > 128) {\n                final int value = in.read();\n\n                for (int i = 0; i < (n & 0x7f); i++) {\n                    out[position++] = (byte) value;\n                }\n            } else {\n                for (int i = 0; i < n; i++) {\n                    out[position++] = (byte) in.read();\n                }\n            }\n        }\n    }\n}\n",
    "target": 0,
    "language": "java",
    "dataset": "vul4j",
    "idx": 200105,
    "RELATED_CWE": [
      "CWE-908",
      "CWE-362",
      "CWE-667"
    ]
  },
  {
    "CWE_ID": [
      "CWE-835"
    ],
    "code": "/*\n * Licensed to the Apache Software Foundation (ASF) under one or more\n * contributor license agreements.  See the NOTICE file distributed with\n * this work for additional information regarding copyright ownership.\n * The ASF licenses this file to You under the Apache License, Version 2.0\n * (the \"License\"); you may not use this file except in compliance with\n * the License.  You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\npackage org.apache.tika.parser.iptc;\n\nimport java.io.IOException;\nimport java.io.InputStream;\nimport java.text.ParseException;\nimport java.text.SimpleDateFormat;\nimport java.util.Collections;\nimport java.util.Date;\nimport java.util.HashMap;\nimport java.util.Locale;\nimport java.util.Set;\nimport java.util.TimeZone;\n\nimport org.apache.tika.exception.TikaException;\nimport org.apache.tika.metadata.Metadata;\nimport org.apache.tika.metadata.TikaCoreProperties;\nimport org.apache.tika.mime.MediaType;\nimport org.apache.tika.parser.ParseContext;\nimport org.apache.tika.parser.Parser;\nimport org.apache.tika.sax.XHTMLContentHandler;\nimport org.xml.sax.ContentHandler;\nimport org.xml.sax.SAXException;\n\nimport static java.nio.charset.StandardCharsets.UTF_8;\n\n/**\n * Parser for IPTC ANPA New Wire Feeds\n */\npublic class IptcAnpaParser implements Parser {\n    /** Serial version UID */\n    private static final long serialVersionUID = -6062820170212879115L;\n\n    private static final MediaType TYPE =\n        MediaType.text(\"vnd.iptc.anpa\");\n\n    private static final Set<MediaType> SUPPORTED_TYPES =\n        Collections.singleton(TYPE);\n\n    public Set<MediaType> getSupportedTypes(ParseContext context) {\n        return SUPPORTED_TYPES;\n    }\n\n    public void parse(\n           InputStream stream, ContentHandler handler,\n           Metadata metadata, ParseContext context)\n           throws IOException, SAXException, TikaException {\n\n        HashMap<String,String> properties = this.loadProperties(stream);\n        this.setMetadata(metadata, properties);\n\n        XHTMLContentHandler xhtml = new XHTMLContentHandler(handler, metadata);\n        xhtml.startDocument();\n        // TODO: put body content here\n        xhtml.startElement(\"p\");\n        String body = clean(properties.get(\"body\"));\n        if (body != null)\n           xhtml.characters(body);\n        xhtml.endElement(\"p\");\n        xhtml.endDocument();\n    }\n\n    /**\n     * @deprecated This method will be removed in Apache Tika 1.0.\n     */\n    public void parse(\n            InputStream stream, ContentHandler handler, Metadata metadata)\n            throws IOException, SAXException, TikaException {\n        parse(stream, handler, metadata, new ParseContext());\n    }\n\n\n   private int FMT_ANPA_1312    = 0x00;   // \"NAA 89-3 (ANPA 1312)\"\n   private int FMT_ANPA_UPI     = 0x01;   // \"United Press International ANPA 1312 variant\"\n   private int FMT_ANPA_UPI_DL  = 0x02;   // \"United Press International Down-Load Message\"\n   private int FMT_IPTC_7901    = 0x03;   // \"IPTC7901 Recommended Message Format\"\n   private int FMT_IPTC_PHOTO   = 0x04;   // \"IPTC-NAA Digital Newsphoto Parameter Record\"\n   private int FMT_IPTC_CHAR    = 0x05;   // \"IPTC Unstructured Character Oriented File Format (UCOFF)\"\n   private int FMT_NITF         = 0x06;   // \"News Industry Text Format (NITF)\"\n   private int FMT_NITF_TT      = 0x07;   // \"Tidningarnas Telegrambyra NITF version (TTNITF DTD)\"\n   private int FMT_NITF_RB      = 0x08;   // \"Ritzaus Bureau NITF version (RBNITF DTD)\"\n   private int FMT_IPTC_AP      = 0x09;   // \"Associated Press news wire format\"\n   private int FMT_IPTC_BLM     = 0x0A;   // \"Bloomberg News news wire format\"\n   private int FMT_IPTC_NYT     = 0x0B;   // \"New York Times news wire format\"\n   private int FMT_IPTC_RTR     = 0x0C;   // \"Reuters news wire format\"\n\n   private int FORMAT = FMT_ANPA_1312;    // assume the default format to be ANPA-1312\n\n   private final static char SOH = 0x01;    // start of header (ctrl-a)\n   private final static char STX = 0x02;    // start of text (ctrl-b)\n   private final static char ETX = 0x03;    // end of text (ctrl-c)\n   private final static char EOT = 0x04;    // the tab character (ctrl-d)\n   private final static char SYN = 0x16;    // synchronous idle (ctrl-v)\n\n   private final static char BS = 0x08;    // the backspace character (used for diacriticals)\n   private final static char TB = 0x09;    // the tab character\n   private final static char LF = 0x0A;    // line feed\n   private final static char FF = 0x0C;    // form feed\n   private final static char CR = 0x0D;    // carriage return\n   private final static char XQ = 0x11;    // device control (ctrl-q)\n   private final static char XS = 0x13;    // device control (ctrl-s)\n   private final static char FS = 0x1F;    // a field delimiter\n\n   private final static char HY = 0x2D;    // hyphen\n   private final static char SP = 0x20;    // the blank space\n   private final static char LT = 0x3C;    // less than\n   private final static char EQ = 0x3D;    // less than\n   private final static char CT = 0x5E;    // carat\n\n   private final static char SL = 0x91;    // single-quote left\n   private final static char SR = 0x92;    // single-quote right\n   private final static char DL = 0x93;    // double-quote left\n   private final static char DR = 0x94;    // double-quote right\n\n\n   /**\n    * scan the news messsage and store the metadata and data into a map\n    */\n   private HashMap<String,String> loadProperties(InputStream is) {\n      \n      HashMap<String,String> properties = new HashMap<String,String>();\n\n      FORMAT = this.scanFormat(is);\n\n      byte[] residual = this.getSection(is,\"residual\");\n\n      byte[] header = this.getSection(is,\"header\");\n      parseHeader(header, properties);\n\n      byte[] body = this.getSection(is,\"body\");\n      parseBody(body, properties);\n\n      byte[] footer = this.getSection(is,\"footer\");\n      parseFooter(footer, properties);\n       \n      return (properties);\n   }\n\n\n   private int scanFormat(InputStream is) {\n      int format    = this.FORMAT;\n      int  maxsize  = 524288;     //  512K\n\n      byte[] buf = new byte[maxsize];\n      try {\n         if (is.markSupported()) {\n            is.mark(maxsize);\n         }\n         int msgsize = is.read(buf);                // read in at least the full data\n\n         String message = (new String(buf, UTF_8)).toLowerCase(Locale.ROOT);\n         // these are not if-then-else, because we want to go from most common\n         // and fall through to least.  this is imperfect, as these tags could\n         // show up in other agency stories, but i can't find a spec or any\n         // explicit codes to identify the wire source in the message itself\n\n         if (message.contains(\"ap-wf\")) {\n            format = this.FMT_IPTC_AP;\n         }\n         if (message.contains(\"reuters\")) {\n            format = this.FMT_IPTC_RTR;\n         }\n         if (message.contains(\"new york times\")) {\n            format = this.FMT_IPTC_NYT;\n         }\n         if (message.contains(\"bloomberg news\")) {\n            format = this.FMT_IPTC_BLM;\n         }\n      }\n      catch (IOException eio) {\n         // we are in an unstable state\n      }\n\n      try {\n         if (is.markSupported()) {\n            is.reset();\n         }\n      }\n      catch (IOException eio) {\n         // we are in an unstable state\n      }\n      return (format);\n   }\n\n\n   private void setFormat(int format) {\n      this.FORMAT = format;\n   }\n\n\n   private String getFormatName() {\n      \n      String name = \"\";\n      \n      if (FORMAT == this.FMT_IPTC_AP) {\n         name = \"Associated Press\";\n      }\n      \n      else if(FORMAT == this.FMT_IPTC_BLM) {\n         name = \"Bloomberg\";\n      }\n\n      else if(FORMAT == this.FMT_IPTC_NYT) {\n         name = \"New York Times\";\n      }\n\n      else if(FORMAT == this.FMT_IPTC_RTR) {\n         name = \"Reuters\";\n      }\n\n      return (name);\n   }\n\n\n   private byte[] getSection(InputStream is, String name) {\n\n      byte[] value = new byte[0];\n\n      if (name.equals(\"residual\")) {\n         // the header shouldn't be more than 1k, but just being generous here\n         int  maxsize  = 8192;     //  8K\n         byte bstart   = SYN;     // check for SYN [0x16 : ctrl-v] (may have leftover residue from preceding message)\n         byte bfinish  = SOH;     // check for SOH [0x01 : ctrl-a] (typically follows a pair of SYN [0x16 : ctrl-v])\n         value = getSection(is, maxsize, bstart, bfinish, true);\n      }\n\n      else if(name.equals(\"header\")) {\n         // the header shouldn't be more than 1k, but just being generous here\n         int  maxsize  = 8192;     //  8K\n         byte bstart   = SOH;     // check for SOH [0x01 : ctrl-a] (typically follows a pair of SYN [0x16 : ctrl-v])\n         byte bfinish  = STX;     // check for STX [0x02 : ctrl-b] (marks end of header, beginning of message)\n         value = getSection(is, maxsize, bstart, bfinish, true);\n      }\n\n      else if (name.equals(\"body\")) {\n         // the message shouldn't be more than 16k (?), leaving plenty of space\n         int  maxsize  = 524288;     //  512K\n         byte bstart   = STX;     // check for STX [0x02 : ctrl-b] (marks end of header, beginning of message)\n         byte bfinish  = ETX;     // check for ETX [0x03 : ctrl-c] (marks end of message, beginning of footer)\n         value = getSection(is, maxsize, bstart, bfinish, true);\n      }\n\n      else if (name.equals(\"footer\")) {\n         // the footer shouldn't be more than 1k , leaving plenty of space\n         int maxsize   = 8192;     //  8K\n         byte bstart   = ETX;     // check for ETX [0x03 : ctrl-c] (marks end of message, beginning of footer)\n         byte bfinish  = EOT;     // check for EOT [0x04 : ctrl-d] (marks end of transmission)\n         value = getSection(is, maxsize, bstart, bfinish, true);\n      }\n\n      return (value);\n   }\n\n\n   private byte[] getSection(InputStream is, int maxsize, byte bstart, byte bfinish, boolean ifincomplete) {\n      byte[] value  = new byte[0];\n\n      try {\n         boolean started = false;                   // check if we have found the start flag\n         boolean finished = false;                  // check if we have found the finish flag\n         int read = 0;                              // the number of bytes we read\n         int start = 0;                             // the position after the start flag\n\n         // TODO: this only pulls back 8K of data on a read, regardless of buffer size\n         //       more nefariously, it caps at a total 8K, through all sections\n         int streammax = is.available();\n         maxsize = Math.min(maxsize, streammax);\n\n         is.mark(maxsize);\n         byte[] buf = new byte[maxsize];\n         int totsize = 0;\n         int remainder = maxsize - totsize;\n         while (remainder > 0) {\n            int msgsize = is.read(buf, maxsize-remainder, maxsize);    // read in at least the full data\n            if (msgsize == -1) {\n               remainder = msgsize = 0;\n            }\n            remainder -= msgsize;\n            totsize   += msgsize;\n         }\n\n         // scan through the provided input stream\n         for (read=0; read < totsize; read++) {\n            byte b = buf[read];\n\n            if (!started) {\n               started = (b == bstart);\n               start = read + 1;\n               continue;\n            }\n\n            if (finished = (b == bfinish)) {\n/*\n               is.reset();\n               long skipped = is.skip((long)read);\n               if (skipped != read) {\n                  // we are in an unstable state\n               }\n               is.mark(1);\n */\n               break;\n            }\n\n            // load from the stream until we run out of characters, or hit the termination byte\n            continue;\n         }\n\n         // move the input stream back to where it was initially\n         is.reset();\n\n         if (finished) {\n            // now, we want to reset the stream to be sitting right on top of the finish marker\n            is.skip(read);\n            value = new byte[read-start];\n            System.arraycopy(buf, start, value, 0, read-start);\n         }\n         else {\n            if (ifincomplete && started) {\n               // the caller wants anything that was read, and we finished the stream or buffer\n               value = new byte[read-start];\n               System.arraycopy(buf, start, value, 0, read-start);\n            }\n         }\n      }\n      catch (IOException eio) {\n         // something invalid occurred, return an empty string\n      }\n\n      return (value);\n   }\n\n\n   private boolean parseHeader(byte[] value, HashMap<String,String> properties) {\n      boolean added = false;\n\n      String env_serviceid = \"\";\n      String env_category = \"\";\n      String env_urgency = \"\";\n      String hdr_edcode = \"\";\n      String hdr_subject = \"\";\n      String hdr_date = \"\";\n      String hdr_time = \"\";\n\n      int read = 0;\n\n      while (read < value.length) {\n\n         // pull apart the envelope, getting the service id  (....\\x1f)\n         while (read < value.length) {\n            byte val_next = value[read++];\n            if (val_next != FS) {\n               env_serviceid += (char)(val_next & 0xff);  // convert the byte to an unsigned int\n            }\n            else {\n               break;\n            }\n         }\n\n         // pull apart the envelope, getting the category  (....\\x13\\x11)\n         while (read < value.length) {\n            byte val_next = value[read++];\n            if (val_next != XS) {   // the end of the envelope is marked (\\x13)\n               env_category += (char)(val_next & 0xff);  // convert the byte to an unsigned int\n            }\n            else {\n               val_next = value[read];  // get the remaining byte (\\x11)\n               if (val_next == XQ) {\n                  read++;\n               }\n               break;\n            }\n         }\n\n         // pull apart the envelope, getting the subject heading\n         while (read < value.length) {\n            boolean subject = true;\n            byte val_next = value[read++];\n            while ((subject) && (val_next != SP) && (val_next != 0x00)) {  // ignore the envelope subject\n               hdr_subject += (char)(val_next & 0xff);  // convert the byte to an unsigned int\n               val_next =  (read < value.length) ? value[read++] : 0x00;\n               while (val_next == SP) {  // consume all the spaces\n                  subject = false;\n                  val_next =  (read < value.length) ? value[read++] : 0x00;\n                  if (val_next != SP) {\n                     --read;  // otherwise we eat into the next section\n                  }\n               }\n            }\n            if (!subject) {\n               break;\n            }\n         }\n\n         // pull apart the envelope, getting the date and time\n         while (read < value.length) {\n            byte val_next = value[read++];\n            if (hdr_date.length() == 0) {\n               while (((val_next >= (byte)0x30) && (val_next <= (byte)0x39))  // consume all numerics and hyphens\n                  ||   (val_next == HY)) {\n                  hdr_date += (char)(val_next & 0xff);  // convert the byte to an unsigned int\n                  val_next =  (read < value.length) ? value[read++] : 0x00;\n               }\n            }\n            else if (val_next == SP) {\n               while (val_next == SP) {  // consume all the spaces\n                  val_next =  (read < value.length) ? value[read++] : 0x00;\n               }\n               continue;\n            }\n            else {\n               while (((val_next >= (byte)0x30) && (val_next <= (byte)0x39))  // consume all numerics and hyphens\n                  ||   (val_next == HY)) {\n                  hdr_time += (char)(val_next & 0xff);  // convert the byte to an unsigned int\n                  val_next =  (read < value.length) ? value[read++] : 0x00;\n               }\n            }\n         }\n         break; // don't let this run back through and start thrashing metadata\n      }\n\n      // if we were saving any of these values, we would set the properties map here\n\n      added = (env_serviceid.length() + env_category.length() + hdr_subject.length() + \n               hdr_date.length() + hdr_time.length()) > 0; \n      return added;\n   }\n\n   private boolean parseBody(byte[] value, HashMap<String,String> properties) {\n      boolean added = false;\n\n      String bdy_heading = \"\";\n      String bdy_title = \"\";\n      String bdy_source = \"\";\n      String bdy_author = \"\";\n      String bdy_body = \"\";\n\n      int read = 0;\n      boolean done = false;\n\n      while (!done && (read < value.length)) {\n\n         // pull apart the body, getting the heading (^....\\x0d\\x0a)\n         while (read < value.length) {\n            byte val_next = value[read++];\n            if (val_next == CT) {      //  start of a new section , first is the heading\n               val_next =  (read < value.length) ? value[read++] : 0x00;\n               // AP, NYT, and Bloomberg end with < , Reuters with EOL\n               while ((val_next != LT) && (val_next != CR) && (val_next != LF)) {   // less than delimiter (\\x3c) and not EOL\n                  bdy_heading += (char)(val_next & 0xff);  // convert the byte to an unsigned int\n                  val_next =  (read < value.length) ? value[read++] : 0x00;\n                  if (read > value.length) { break; }  // shouldn't ever hit this, but save a NPE\n               }\n               if (val_next == LT) {\n                  // hit the delimiter, carry on\n                  val_next =  (read < value.length) ? value[read++] : 0x00;\n               }\n               while (bdy_heading.length() > 0 && ((val_next == CR) || (val_next == LF))) {\n                  val_next =  (read < value.length) ? value[read++] : 0x00;  // skip the new lines\n                  if ((val_next != CR) && (val_next != LF)) {\n                     --read;\n                  }\n               }\n            }\n            else {\n               // this will only be hit on poorly-formed files\n\n               // for reuters, the heading does not start with the ^, so we push one back into the stream\n               if (FORMAT == this.FMT_IPTC_RTR) {\n                  if (val_next != CT) {\n                     // for any non-whitespace, we need to go back an additional step to non destroy the data\n                     if ((val_next != SP) && (val_next != TB) && (val_next != CR) && (val_next != LF)) {\n                        // if the very first byte is data, we have to shift the whole array, and stuff in a carat\n                        if (read == 1) {\n                           byte[] resize = new byte[value.length + 1];\n                           System.arraycopy(value, 0, resize, 1, value.length);\n                           value = resize;\n                        }\n                     }\n                     value[--read] = CT;\n                     continue;\n                  }\n               }\n            }\n            break;\n         }\n\n         // pull apart the body, getting the title (^....\\x0d\\x0a)\n         while (read < value.length) {\n            byte val_next = value[read++];\n            if (val_next == CT) {      //  start of a new section , first is the heading\n               val_next =  (read < value.length) ? value[read++] : 0x00;\n               // AP, NYT, and Bloomberg end with < , Reuters with EOL\n               while ((val_next != LT) && (val_next != CT) && (val_next != CR) && (val_next != LF)) {   // less than delimiter (\\x3c), or carat (\\x5e) and not EOL\n                  bdy_title += (char)(val_next & 0xff);  // convert the byte to an unsigned int\n                  val_next =  (read < value.length) ? value[read++] : 0x00;\n                  if (read > value.length) { break; }  // shouldn't ever hit this, but save a NPE\n               }\n\n               if (val_next == CT) {      //  start of a new section , when first didn't finish cleanly\n                   --read;\n               }\n\n               if (val_next == LT) {\n                  // hit the delimiter, carry on\n                  val_next =  (read < value.length) ? value[read++] : 0x00;\n               }\n\n               while (bdy_title.length() > 0 && ((val_next == CR) || (val_next == LF))) {\n                  val_next =  (read < value.length) ? value[read++] : 0x00;  // skip the new lines\n                  if ((val_next != CR) && (val_next != LF)) {\n                     --read;\n                  }\n               }\n            }\n            else {\n               // this will only be hit on poorly-formed files\n\n               // for bloomberg, the title does not start with the ^, so we push one back into the stream\n               if (FORMAT == this.FMT_IPTC_BLM) {\n                  if (val_next == TB) {\n                     value[--read] = CT;\n                     continue;\n                  }\n               }\n\n               // for reuters, the title does not start with the ^, so we push one back into the stream\n               if (FORMAT == this.FMT_IPTC_RTR) {\n                  if (val_next != CT) {\n                     // for any non-whitespace, we need to go back an additional step to non destroy the data\n                     if ((val_next != SP) && (val_next != TB) && (val_next != CR) && (val_next != LF)) {\n                        --read;\n                     }\n                     value[--read] = CT;\n                     continue;\n                  }\n               }\n            }\n            break;\n         }\n\n\n         // at this point, we have a variable number of metadata lines, with various orders\n         // we scan the start of each line for the special character, and run to the end character\n         // pull apart the body, getting the title (^....\\x0d\\x0a)\n         boolean metastarted = false;\n         String longline = \"\";\n         String longkey = \"\";\n         while (read < value.length) {\n            byte val_next = value[read++];\n\n            // eat up whitespace before committing to the next section\n            if ((val_next == SP) || (val_next == TB) || (val_next == CR) || (val_next == LF)) {\n               continue;\n            }\n\n            if (val_next == CT) {      //  start of a new section , could be authors, sources, etc\n               val_next =  (read < value.length) ? value[read++] : 0x00;\n               String tmp_line = \"\";\n               while ((val_next != LT) && (val_next != CT) && (val_next != CR) && (val_next != LF) && (val_next != 0))  {\n                  // less than delimiter (\\x3c), maybe also badly formed with just new line\n                  tmp_line += (char)(val_next & 0xff);  // convert the byte to an unsigned int\n                  val_next =  (read < value.length) ? value[read++] : 0x00;\n                  if (read > value.length) { break; }  // shouldn't ever hit this, but save a NPE\n               }\n\n               if (val_next == CT) {      //  start of a new section , when first didn't finish cleanly\n                   --read;\n               }\n\n               if (val_next == LT) {\n                  // hit the delimiter, carry on\n                  val_next =  (read < value.length) ? value[read++] : 0x00;\n               }\n\n               while ((val_next == CR) || (val_next == LF)) {\n                  val_next =  (read < value.length) ? value[read++] : 0x00;  // skip the new lines\n                  if ((val_next != CR) && (val_next != LF)) {\n                     --read;\n                  }\n               }\n               if (tmp_line.toLowerCase(Locale.ROOT).startsWith(\"by\") || longline.equals(\"bdy_author\")) {\n                  longkey = \"bdy_author\";\n\n                  // prepend a space to subsequent line, so it gets parsed consistent with the lead line\n                  tmp_line = (longline.equals(longkey) ? \" \" : \"\") + tmp_line;\n\n                  // we have an author candidate\n                  int term = tmp_line.length();\n                  term = Math.min(term, (tmp_line.contains(\"<\") ? tmp_line.indexOf(\"<\")  : term));\n                  term = Math.min(term, (tmp_line.contains(\"=\") ? tmp_line.indexOf(\"=\")  : term));\n                  term = Math.min(term, (tmp_line.contains(\"\\n\") ? tmp_line.indexOf(\"\\n\") : term));\n                  term = (term > 0 ) ? term : tmp_line.length();\n                  bdy_author += tmp_line.substring(tmp_line.indexOf(\" \"), term);\n                  metastarted = true;\n                  longline = ((tmp_line.contains(\"=\")) && (!longline.equals(longkey)) ? longkey : \"\");\n               }\n               else if (FORMAT == this.FMT_IPTC_BLM) {\n                  String byline = \"   by \";\n                  if (tmp_line.toLowerCase(Locale.ROOT).contains(byline)) {\n                     longkey = \"bdy_author\";\n\n                     int term = tmp_line.length();\n                     term = Math.min(term, (tmp_line.contains(\"<\") ? tmp_line.indexOf(\"<\")  : term));\n                     term = Math.min(term, (tmp_line.contains(\"=\") ? tmp_line.indexOf(\"=\")  : term));\n                     term = Math.min(term, (tmp_line.contains(\"\\n\") ? tmp_line.indexOf(\"\\n\") : term));\n                     term = (term > 0 ) ? term : tmp_line.length();\n                     // for bloomberg, the author line sits below their copyright statement\n                     bdy_author += tmp_line.substring(tmp_line.toLowerCase(Locale.ROOT).indexOf(byline) + byline.length(), term) + \" \";\n                     metastarted = true;\n                     longline = ((tmp_line.contains(\"=\")) && (!longline.equals(longkey)) ? longkey : \"\");\n                  }\n                  else if(tmp_line.toLowerCase(Locale.ROOT).startsWith(\"c.\")) {\n                     // the author line for bloomberg is a multiline starting with c.2011 Bloomberg News\n                     // then containing the author info on the next line\n                     if (val_next == TB) {\n                        value[--read] = CT;\n                        continue;\n                     }\n                  }\n                  else if(tmp_line.toLowerCase(Locale.ROOT).trim().startsWith(\"(\") && tmp_line.toLowerCase(Locale.ROOT).trim().endsWith(\")\")) {\n                     // the author line may have one or more comment lines between the copyright\n                     // statement, and the By AUTHORNAME line\n                     if (val_next == TB) {\n                        value[--read] = CT;\n                        continue;\n                     }\n                  }\n               }\n\n               else if (tmp_line.toLowerCase(Locale.ROOT).startsWith(\"eds\") || longline.equals(\"bdy_source\")) {\n                  longkey = \"bdy_source\";\n                  // prepend a space to subsequent line, so it gets parsed consistent with the lead line\n                  tmp_line = (longline.equals(longkey) ? \" \" : \"\") + tmp_line;\n\n                  // we have a source candidate\n                  int term = tmp_line.length();\n                  term = Math.min(term, (tmp_line.contains(\"<\") ? tmp_line.indexOf(\"<\")  : term));\n                  term = Math.min(term, (tmp_line.contains(\"=\") ? tmp_line.indexOf(\"=\")  : term));\n//                  term = Math.min(term, (tmp_line.indexOf(\"\\n\") > -1 ? tmp_line.indexOf(\"\\n\") : term));\n                  term = (term > 0 ) ? term : tmp_line.length();\n                  bdy_source += tmp_line.substring(tmp_line.indexOf(\" \") + 1, term) + \" \";\n                  metastarted = true;\n                  longline = (!longline.equals(longkey) ? longkey  : \"\");\n               }\n               else {\n                  // this has fallen all the way through.  trap it as part of the subject,\n                  // rather than just losing it\n                  if (!metastarted) {\n                     bdy_title += \" , \" + tmp_line;     //  not sure where else to put this but in the title\n                  }\n                  else {\n                     // what to do with stuff that is metadata, which falls after metadata lines started?\n                     bdy_body += \" \" + tmp_line + \" , \";     //  not sure where else to put this but in the title\n                  }\n               }\n            }\n            else {  // we're on to the main body\n               while ((read < value.length) && (val_next != 0))  {\n                  // read until the train runs out of tracks\n                  bdy_body += (char)(val_next & 0xff);  // convert the byte to an unsigned int\n                  val_next =  (read < value.length) ? value[read++] : 0x00;\n                  if (read > value.length) { break; }  // shouldn't ever hit this, but save a NPE\n               }\n\n            }\n            // we would normally break here, but just let this read out to the end\n         }\n         done = true; // don't let this run back through and start thrashing metadata\n      }\n      properties.put(\"body\", bdy_body);\n      properties.put(\"title\", bdy_title);\n      properties.put(\"subject\", bdy_heading);\n      properties.put(\"author\", bdy_author);\n      properties.put(\"source\", bdy_source);\n\n      added = (bdy_body.length() + bdy_title.length() + bdy_heading.length() + bdy_author.length() +\n               bdy_source.length()) > 0;\n      return added;\n   }\n\n\n   private boolean parseFooter(byte[] value, HashMap<String,String> properties) {\n      boolean added = false;\n\n      String ftr_source = \"\";\n      String ftr_datetime = \"\";\n\n      int read = 0;\n      boolean done = false;\n\n      while (!done && (read < value.length)) {\n\n         // pull apart the footer, getting the news feed source (^....\\x0d\\x0a)\n         byte val_next = value[read++];\n         byte val_peek =  (read < value.length) ? value[read+1] : 0x00;  // skip the new lines\n\n         while (((val_next < (byte)0x30) || (val_next > (byte)0x39)) && (val_next != 0)) {  // consume all non-numerics first\n            ftr_source += (char)(val_next & 0xff);  // convert the byte to an unsigned int\n            val_next =  (read < value.length) ? value[read] : 0x00;  // attempt to read until end of stream\n            read++;\n            if (read > value.length) { break; }  // shouldn't ever hit this, but save a NPE\n         }\n\n         while ((val_next != LT) && (val_next != CR) && (val_next != LF) && (val_next != 0))  {  // get as much timedate as possible\n            // this is an american format, so arrives as mm-dd-yy HHiizzz\n            ftr_datetime += (char)(val_next & 0xff);  // convert the byte to an unsigned int\n            val_next =  (read < value.length) ? value[read++] : 0x00;  // skip the new lines\n            if (read > value.length) { break; }  // shouldn't ever hit this, but save a NPE\n         }\n         if (val_next == LT) {\n            // hit the delimiter, carry on\n            val_next =  (read < value.length) ? value[read++] : 0x00;\n         }\n\n         if (ftr_datetime.length() > 0) {\n            // we want to pass this back in a more friendly format\n            String format_out = \"yyyy-MM-dd'T'HH:mm:ss'Z'\";\n            Date dateunix = new Date();\n            try {\n               // standard ap format\n               String format_in = \"MM-dd-yy HHmmzzz\";\n\n               if (FORMAT == this.FMT_IPTC_RTR) {\n                  // standard reuters format\n                  format_in = \"HH:mm MM-dd-yy\";\n               }\n               SimpleDateFormat dfi = new SimpleDateFormat(format_in, Locale.ROOT);\n               dfi.setTimeZone(TimeZone.getTimeZone(\"UTC\"));\n               dateunix = dfi.parse(ftr_datetime);\n            }\n            catch (ParseException ep) {\n               // failed, but this will just fall through to setting the date to now\n            }\n            SimpleDateFormat dfo = new SimpleDateFormat(format_out, Locale.ROOT);\n            dfo.setTimeZone(TimeZone.getTimeZone(\"UTC\"));\n            ftr_datetime = dfo.format(dateunix);\n         }\n         while ((val_next == CR) || (val_next == LF)) {\n            val_next =  (read < value.length) ? value[read++] : 0x00;  // skip the new lines\n            if ((val_next != CR) && (val_next != LF)) {\n               --read;\n            }\n         }\n         done = true; // don't let this run back through and start thrashing metadata\n      }\n\n      properties.put(\"publisher\", ftr_source);\n      properties.put(\"created\", ftr_datetime);\n      properties.put(\"modified\", ftr_datetime);\n\n      added = (ftr_source.length() + ftr_datetime.length()) > 0; \n      return added;\n   }\n\n\n   private void setMetadata(Metadata metadata, HashMap<String,String> properties) {\n\n      // every property that gets set must be non-null, or it will cause NPE\n      // in other consuming applications, like Lucene\n      metadata.set(Metadata.CONTENT_TYPE,  clean(\"text/anpa-1312\"));\n      metadata.set(TikaCoreProperties.TITLE,         clean(properties.get(\"title\")));\n      metadata.set(TikaCoreProperties.SUBJECT,       clean(properties.get(\"subject\")));\n      metadata.set(TikaCoreProperties.CREATOR,        clean(properties.get(\"author\")));\n      metadata.set(TikaCoreProperties.CREATED, clean(properties.get(\"created\")));\n      metadata.set(TikaCoreProperties.MODIFIED,      clean(properties.get(\"modified\")));\n      metadata.set(TikaCoreProperties.SOURCE,      clean(properties.get(\"source\")));\n//      metadata.set(TikaCoreProperties.PUBLISHER,     clean(properties.get(\"publisher\")));\n      metadata.set(TikaCoreProperties.PUBLISHER,     clean(this.getFormatName()));\n\n/*\n        metadata.set(TikaCoreProperties.DATE, font.getHeader().getCreated().getTime());\n        metadata.set(\n                Property.internalDate(TikaCoreProperties.MODIFIED),\n                font.getHeader().getModified().getTime());\n*/\n   }\n\n   private String clean(String value) {\n      if (value == null) {\n         value = \"\";\n      }\n\n      value = value.replaceAll(\"``\", \"`\");\n      value = value.replaceAll(\"''\", \"'\");\n      value = value.replaceAll(new String(new char[] {SL}), \"'\");\n      value = value.replaceAll(new String(new char[] {SR}), \"'\");\n      value = value.replaceAll(new String(new char[] {DL}), \"\\\"\");\n      value = value.replaceAll(new String(new char[] {DR}), \"\\\"\");\n      value = value.trim();\n\n      return (value);\n   }\n}\n",
    "target": 1,
    "language": "java",
    "dataset": "vul4j",
    "idx": 200134,
    "RELATED_CWE": [
      "CWE-908",
      "CWE-362",
      "CWE-667"
    ]
  },
  {
    "CWE_ID": [
      "CWE-835"
    ],
    "code": "/*\n * Licensed to the Apache Software Foundation (ASF) under one or more\n * contributor license agreements.  See the NOTICE file distributed with\n * this work for additional information regarding copyright ownership.\n * The ASF licenses this file to You under the Apache License, Version 2.0\n * (the \"License\"); you may not use this file except in compliance with\n * the License.  You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\npackage org.apache.tika.parser.iptc;\n\nimport java.io.IOException;\nimport java.io.InputStream;\nimport java.text.ParseException;\nimport java.text.SimpleDateFormat;\nimport java.util.Collections;\nimport java.util.Date;\nimport java.util.HashMap;\nimport java.util.Locale;\nimport java.util.Set;\nimport java.util.TimeZone;\n\nimport org.apache.tika.exception.TikaException;\nimport org.apache.tika.metadata.Metadata;\nimport org.apache.tika.metadata.TikaCoreProperties;\nimport org.apache.tika.mime.MediaType;\nimport org.apache.tika.parser.ParseContext;\nimport org.apache.tika.parser.Parser;\nimport org.apache.tika.sax.XHTMLContentHandler;\nimport org.xml.sax.ContentHandler;\nimport org.xml.sax.SAXException;\n\nimport static java.nio.charset.StandardCharsets.UTF_8;\n\n/**\n * Parser for IPTC ANPA New Wire Feeds\n */\npublic class IptcAnpaParser implements Parser {\n    /** Serial version UID */\n    private static final long serialVersionUID = -6062820170212879115L;\n\n    private static final MediaType TYPE =\n        MediaType.text(\"vnd.iptc.anpa\");\n\n    private static final Set<MediaType> SUPPORTED_TYPES =\n        Collections.singleton(TYPE);\n\n    public Set<MediaType> getSupportedTypes(ParseContext context) {\n        return SUPPORTED_TYPES;\n    }\n\n    public void parse(\n           InputStream stream, ContentHandler handler,\n           Metadata metadata, ParseContext context)\n           throws IOException, SAXException, TikaException {\n\n        HashMap<String,String> properties = this.loadProperties(stream);\n        this.setMetadata(metadata, properties);\n\n        XHTMLContentHandler xhtml = new XHTMLContentHandler(handler, metadata);\n        xhtml.startDocument();\n        // TODO: put body content here\n        xhtml.startElement(\"p\");\n        String body = clean(properties.get(\"body\"));\n        if (body != null)\n           xhtml.characters(body);\n        xhtml.endElement(\"p\");\n        xhtml.endDocument();\n    }\n\n    /**\n     * @deprecated This method will be removed in Apache Tika 1.0.\n     */\n    public void parse(\n            InputStream stream, ContentHandler handler, Metadata metadata)\n            throws IOException, SAXException, TikaException {\n        parse(stream, handler, metadata, new ParseContext());\n    }\n\n\n   private int FMT_ANPA_1312    = 0x00;   // \"NAA 89-3 (ANPA 1312)\"\n   private int FMT_ANPA_UPI     = 0x01;   // \"United Press International ANPA 1312 variant\"\n   private int FMT_ANPA_UPI_DL  = 0x02;   // \"United Press International Down-Load Message\"\n   private int FMT_IPTC_7901    = 0x03;   // \"IPTC7901 Recommended Message Format\"\n   private int FMT_IPTC_PHOTO   = 0x04;   // \"IPTC-NAA Digital Newsphoto Parameter Record\"\n   private int FMT_IPTC_CHAR    = 0x05;   // \"IPTC Unstructured Character Oriented File Format (UCOFF)\"\n   private int FMT_NITF         = 0x06;   // \"News Industry Text Format (NITF)\"\n   private int FMT_NITF_TT      = 0x07;   // \"Tidningarnas Telegrambyra NITF version (TTNITF DTD)\"\n   private int FMT_NITF_RB      = 0x08;   // \"Ritzaus Bureau NITF version (RBNITF DTD)\"\n   private int FMT_IPTC_AP      = 0x09;   // \"Associated Press news wire format\"\n   private int FMT_IPTC_BLM     = 0x0A;   // \"Bloomberg News news wire format\"\n   private int FMT_IPTC_NYT     = 0x0B;   // \"New York Times news wire format\"\n   private int FMT_IPTC_RTR     = 0x0C;   // \"Reuters news wire format\"\n\n   private int FORMAT = FMT_ANPA_1312;    // assume the default format to be ANPA-1312\n\n   private final static char SOH = 0x01;    // start of header (ctrl-a)\n   private final static char STX = 0x02;    // start of text (ctrl-b)\n   private final static char ETX = 0x03;    // end of text (ctrl-c)\n   private final static char EOT = 0x04;    // the tab character (ctrl-d)\n   private final static char SYN = 0x16;    // synchronous idle (ctrl-v)\n\n   private final static char BS = 0x08;    // the backspace character (used for diacriticals)\n   private final static char TB = 0x09;    // the tab character\n   private final static char LF = 0x0A;    // line feed\n   private final static char FF = 0x0C;    // form feed\n   private final static char CR = 0x0D;    // carriage return\n   private final static char XQ = 0x11;    // device control (ctrl-q)\n   private final static char XS = 0x13;    // device control (ctrl-s)\n   private final static char FS = 0x1F;    // a field delimiter\n\n   private final static char HY = 0x2D;    // hyphen\n   private final static char SP = 0x20;    // the blank space\n   private final static char LT = 0x3C;    // less than\n   private final static char EQ = 0x3D;    // less than\n   private final static char CT = 0x5E;    // carat\n\n   private final static char SL = 0x91;    // single-quote left\n   private final static char SR = 0x92;    // single-quote right\n   private final static char DL = 0x93;    // double-quote left\n   private final static char DR = 0x94;    // double-quote right\n\n\n   /**\n    * scan the news messsage and store the metadata and data into a map\n    */\n   private HashMap<String,String> loadProperties(InputStream is) {\n      \n      HashMap<String,String> properties = new HashMap<String,String>();\n\n      FORMAT = this.scanFormat(is);\n\n      byte[] residual = this.getSection(is,\"residual\");\n\n      byte[] header = this.getSection(is,\"header\");\n      parseHeader(header, properties);\n\n      byte[] body = this.getSection(is,\"body\");\n      parseBody(body, properties);\n\n      byte[] footer = this.getSection(is,\"footer\");\n      parseFooter(footer, properties);\n       \n      return (properties);\n   }\n\n\n   private int scanFormat(InputStream is) {\n      int format    = this.FORMAT;\n      int  maxsize  = 524288;     //  512K\n\n      byte[] buf = new byte[maxsize];\n      try {\n         if (is.markSupported()) {\n            is.mark(maxsize);\n         }\n         int msgsize = is.read(buf);                // read in at least the full data\n\n         String message = (new String(buf, UTF_8)).toLowerCase(Locale.ROOT);\n         // these are not if-then-else, because we want to go from most common\n         // and fall through to least.  this is imperfect, as these tags could\n         // show up in other agency stories, but i can't find a spec or any\n         // explicit codes to identify the wire source in the message itself\n\n         if (message.contains(\"ap-wf\")) {\n            format = this.FMT_IPTC_AP;\n         }\n         if (message.contains(\"reuters\")) {\n            format = this.FMT_IPTC_RTR;\n         }\n         if (message.contains(\"new york times\")) {\n            format = this.FMT_IPTC_NYT;\n         }\n         if (message.contains(\"bloomberg news\")) {\n            format = this.FMT_IPTC_BLM;\n         }\n      }\n      catch (IOException eio) {\n         // we are in an unstable state\n      }\n\n      try {\n         if (is.markSupported()) {\n            is.reset();\n         }\n      }\n      catch (IOException eio) {\n         // we are in an unstable state\n      }\n      return (format);\n   }\n\n\n   private void setFormat(int format) {\n      this.FORMAT = format;\n   }\n\n\n   private String getFormatName() {\n      \n      String name = \"\";\n      \n      if (FORMAT == this.FMT_IPTC_AP) {\n         name = \"Associated Press\";\n      }\n      \n      else if(FORMAT == this.FMT_IPTC_BLM) {\n         name = \"Bloomberg\";\n      }\n\n      else if(FORMAT == this.FMT_IPTC_NYT) {\n         name = \"New York Times\";\n      }\n\n      else if(FORMAT == this.FMT_IPTC_RTR) {\n         name = \"Reuters\";\n      }\n\n      return (name);\n   }\n\n\n   private byte[] getSection(InputStream is, String name) {\n\n      byte[] value = new byte[0];\n\n      if (name.equals(\"residual\")) {\n         // the header shouldn't be more than 1k, but just being generous here\n         int  maxsize  = 8192;     //  8K\n         byte bstart   = SYN;     // check for SYN [0x16 : ctrl-v] (may have leftover residue from preceding message)\n         byte bfinish  = SOH;     // check for SOH [0x01 : ctrl-a] (typically follows a pair of SYN [0x16 : ctrl-v])\n         value = getSection(is, maxsize, bstart, bfinish, true);\n      }\n\n      else if(name.equals(\"header\")) {\n         // the header shouldn't be more than 1k, but just being generous here\n         int  maxsize  = 8192;     //  8K\n         byte bstart   = SOH;     // check for SOH [0x01 : ctrl-a] (typically follows a pair of SYN [0x16 : ctrl-v])\n         byte bfinish  = STX;     // check for STX [0x02 : ctrl-b] (marks end of header, beginning of message)\n         value = getSection(is, maxsize, bstart, bfinish, true);\n      }\n\n      else if (name.equals(\"body\")) {\n         // the message shouldn't be more than 16k (?), leaving plenty of space\n         int  maxsize  = 524288;     //  512K\n         byte bstart   = STX;     // check for STX [0x02 : ctrl-b] (marks end of header, beginning of message)\n         byte bfinish  = ETX;     // check for ETX [0x03 : ctrl-c] (marks end of message, beginning of footer)\n         value = getSection(is, maxsize, bstart, bfinish, true);\n      }\n\n      else if (name.equals(\"footer\")) {\n         // the footer shouldn't be more than 1k , leaving plenty of space\n         int maxsize   = 8192;     //  8K\n         byte bstart   = ETX;     // check for ETX [0x03 : ctrl-c] (marks end of message, beginning of footer)\n         byte bfinish  = EOT;     // check for EOT [0x04 : ctrl-d] (marks end of transmission)\n         value = getSection(is, maxsize, bstart, bfinish, true);\n      }\n\n      return (value);\n   }\n\n\n   private byte[] getSection(InputStream is, int maxsize, byte bstart, byte bfinish, boolean ifincomplete) {\n      byte[] value  = new byte[0];\n\n      try {\n         boolean started = false;                   // check if we have found the start flag\n         boolean finished = false;                  // check if we have found the finish flag\n         int read = 0;                              // the number of bytes we read\n         int start = 0;                             // the position after the start flag\n\n         // TODO: this only pulls back 8K of data on a read, regardless of buffer size\n         //       more nefariously, it caps at a total 8K, through all sections\n         int streammax = is.available();\n         maxsize = Math.min(maxsize, streammax);\n\n         is.mark(maxsize);\n         byte[] buf = new byte[maxsize];\n         int totsize = 0;\n         int remainder = maxsize - totsize;\n         while (remainder > 0) {\n            int msgsize = is.read(buf, maxsize-remainder, maxsize);    // read in at least the full data\n            if (msgsize == -1) {\n               remainder = msgsize = 0;\n            }\n            remainder -= msgsize;\n            totsize   += msgsize;\n         }\n\n         // scan through the provided input stream\n         for (read=0; read < totsize; read++) {\n            byte b = buf[read];\n\n            if (!started) {\n               started = (b == bstart);\n               start = read + 1;\n               continue;\n            }\n\n            if (finished = (b == bfinish)) {\n/*\n               is.reset();\n               long skipped = is.skip((long)read);\n               if (skipped != read) {\n                  // we are in an unstable state\n               }\n               is.mark(1);\n */\n               break;\n            }\n\n            // load from the stream until we run out of characters, or hit the termination byte\n            continue;\n         }\n\n         // move the input stream back to where it was initially\n         is.reset();\n\n         if (finished) {\n            // now, we want to reset the stream to be sitting right on top of the finish marker\n            is.skip(read);\n            value = new byte[read-start];\n            System.arraycopy(buf, start, value, 0, read-start);\n         }\n         else {\n            if (ifincomplete && started) {\n               // the caller wants anything that was read, and we finished the stream or buffer\n               value = new byte[read-start];\n               System.arraycopy(buf, start, value, 0, read-start);\n            }\n         }\n      }\n      catch (IOException eio) {\n         // something invalid occurred, return an empty string\n      }\n\n      return (value);\n   }\n\n\n   private boolean parseHeader(byte[] value, HashMap<String,String> properties) {\n      boolean added = false;\n\n      String env_serviceid = \"\";\n      String env_category = \"\";\n      String env_urgency = \"\";\n      String hdr_edcode = \"\";\n      String hdr_subject = \"\";\n      String hdr_date = \"\";\n      String hdr_time = \"\";\n\n      int read = 0;\n\n      while (read < value.length) {\n\n         // pull apart the envelope, getting the service id  (....\\x1f)\n         while (read < value.length) {\n            byte val_next = value[read++];\n            if (val_next != FS) {\n               env_serviceid += (char)(val_next & 0xff);  // convert the byte to an unsigned int\n            }\n            else {\n               break;\n            }\n         }\n\n         // pull apart the envelope, getting the category  (....\\x13\\x11)\n         while (read < value.length) {\n            byte val_next = value[read++];\n            if (val_next != XS) {   // the end of the envelope is marked (\\x13)\n               env_category += (char)(val_next & 0xff);  // convert the byte to an unsigned int\n            }\n            else {\n               val_next = value[read];  // get the remaining byte (\\x11)\n               if (val_next == XQ) {\n                  read++;\n               }\n               break;\n            }\n         }\n\n         // pull apart the envelope, getting the subject heading\n         while (read < value.length) {\n            boolean subject = true;\n            byte val_next = value[read++];\n            while ((subject) && (val_next != SP) && (val_next != 0x00)) {  // ignore the envelope subject\n               hdr_subject += (char)(val_next & 0xff);  // convert the byte to an unsigned int\n               val_next =  (read < value.length) ? value[read++] : 0x00;\n               while (val_next == SP) {  // consume all the spaces\n                  subject = false;\n                  val_next =  (read < value.length) ? value[read++] : 0x00;\n                  if (val_next != SP) {\n                     --read;  // otherwise we eat into the next section\n                  }\n               }\n            }\n            if (!subject) {\n               break;\n            }\n         }\n\n         // pull apart the envelope, getting the date and time\n         while (read < value.length) {\n            byte val_next = value[read++];\n            if (hdr_date.length() == 0) {\n               while (((val_next >= (byte)0x30) && (val_next <= (byte)0x39))  // consume all numerics and hyphens\n                  ||   (val_next == HY)) {\n                  hdr_date += (char)(val_next & 0xff);  // convert the byte to an unsigned int\n                  val_next =  (read < value.length) ? value[read++] : 0x00;\n               }\n            }\n            else if (val_next == SP) {\n               while (val_next == SP) {  // consume all the spaces\n                  val_next =  (read < value.length) ? value[read++] : 0x00;\n               }\n               continue;\n            }\n            else {\n               while (((val_next >= (byte)0x30) && (val_next <= (byte)0x39))  // consume all numerics and hyphens\n                  ||   (val_next == HY)) {\n                  hdr_time += (char)(val_next & 0xff);  // convert the byte to an unsigned int\n                  val_next =  (read < value.length) ? value[read++] : 0x00;\n               }\n            }\n         }\n         break; // don't let this run back through and start thrashing metadata\n      }\n\n      // if we were saving any of these values, we would set the properties map here\n\n      added = (env_serviceid.length() + env_category.length() + hdr_subject.length() + \n               hdr_date.length() + hdr_time.length()) > 0; \n      return added;\n   }\n\n   private boolean parseBody(byte[] value, HashMap<String,String> properties) {\n      boolean added = false;\n\n      String bdy_heading = \"\";\n      String bdy_title = \"\";\n      String bdy_source = \"\";\n      String bdy_author = \"\";\n      String bdy_body = \"\";\n\n      int read = 0;\n      boolean done = false;\n\n      while (!done && (read < value.length)) {\n\n         // pull apart the body, getting the heading (^....\\x0d\\x0a)\n         while (read < value.length) {\n            byte val_next = value[read++];\n            if (val_next == CT) {      //  start of a new section , first is the heading\n               val_next =  (read < value.length) ? value[read++] : 0x00;\n               // AP, NYT, and Bloomberg end with < , Reuters with EOL\n               while ((val_next != LT) && (val_next != CR) && (val_next != LF)) {   // less than delimiter (\\x3c) and not EOL\n                  bdy_heading += (char)(val_next & 0xff);  // convert the byte to an unsigned int\n                  val_next =  (read < value.length) ? value[read++] : 0x00;\n                  if (read >= value.length) { break; }  // shouldn't ever hit this, but save a NPE\n               }\n               if (val_next == LT) {\n                  // hit the delimiter, carry on\n                  val_next =  (read < value.length) ? value[read++] : 0x00;\n               }\n               while (bdy_heading.length() > 0 && ((val_next == CR) || (val_next == LF))) {\n                  val_next =  (read < value.length) ? value[read++] : 0x00;  // skip the new lines\n                  if ((val_next != CR) && (val_next != LF)) {\n                     --read;\n                  }\n               }\n            }\n            else {\n               // this will only be hit on poorly-formed files\n\n               // for reuters, the heading does not start with the ^, so we push one back into the stream\n               if (FORMAT == this.FMT_IPTC_RTR) {\n                  if (val_next != CT) {\n                     // for any non-whitespace, we need to go back an additional step to non destroy the data\n                     if ((val_next != SP) && (val_next != TB) && (val_next != CR) && (val_next != LF)) {\n                        // if the very first byte is data, we have to shift the whole array, and stuff in a carat\n                        if (read == 1) {\n                           byte[] resize = new byte[value.length + 1];\n                           System.arraycopy(value, 0, resize, 1, value.length);\n                           value = resize;\n                        }\n                     }\n                     value[--read] = CT;\n                     continue;\n                  }\n               }\n            }\n            break;\n         }\n\n         // pull apart the body, getting the title (^....\\x0d\\x0a)\n         while (read < value.length) {\n            byte val_next = value[read++];\n            if (val_next == CT) {      //  start of a new section , first is the heading\n               val_next =  (read < value.length) ? value[read++] : 0x00;\n               // AP, NYT, and Bloomberg end with < , Reuters with EOL\n               while ((val_next != LT) && (val_next != CT) && (val_next != CR) && (val_next != LF)) {   // less than delimiter (\\x3c), or carat (\\x5e) and not EOL\n                  bdy_title += (char)(val_next & 0xff);  // convert the byte to an unsigned int\n                  val_next =  (read < value.length) ? value[read++] : 0x00;\n                  if (read >= value.length) { break; }  // shouldn't ever hit this, but save a NPE\n               }\n\n               if (val_next == CT) {      //  start of a new section , when first didn't finish cleanly\n                   --read;\n               }\n\n               if (val_next == LT) {\n                  // hit the delimiter, carry on\n                  val_next =  (read < value.length) ? value[read++] : 0x00;\n               }\n\n               while (bdy_title.length() > 0 && ((val_next == CR) || (val_next == LF))) {\n                  val_next =  (read < value.length) ? value[read++] : 0x00;  // skip the new lines\n                  if ((val_next != CR) && (val_next != LF)) {\n                     --read;\n                  }\n               }\n            }\n            else {\n               // this will only be hit on poorly-formed files\n\n               // for bloomberg, the title does not start with the ^, so we push one back into the stream\n               if (FORMAT == this.FMT_IPTC_BLM) {\n                  if (val_next == TB) {\n                     value[--read] = CT;\n                     continue;\n                  }\n               }\n\n               // for reuters, the title does not start with the ^, so we push one back into the stream\n               if (FORMAT == this.FMT_IPTC_RTR) {\n                  if (val_next != CT) {\n                     // for any non-whitespace, we need to go back an additional step to non destroy the data\n                     if ((val_next != SP) && (val_next != TB) && (val_next != CR) && (val_next != LF)) {\n                        --read;\n                     }\n                     value[--read] = CT;\n                     continue;\n                  }\n               }\n            }\n            break;\n         }\n\n\n         // at this point, we have a variable number of metadata lines, with various orders\n         // we scan the start of each line for the special character, and run to the end character\n         // pull apart the body, getting the title (^....\\x0d\\x0a)\n         boolean metastarted = false;\n         String longline = \"\";\n         String longkey = \"\";\n         while (read < value.length) {\n            byte val_next = value[read++];\n\n            // eat up whitespace before committing to the next section\n            if ((val_next == SP) || (val_next == TB) || (val_next == CR) || (val_next == LF)) {\n               continue;\n            }\n\n            if (val_next == CT) {      //  start of a new section , could be authors, sources, etc\n               val_next =  (read < value.length) ? value[read++] : 0x00;\n               String tmp_line = \"\";\n               while ((val_next != LT) && (val_next != CT) && (val_next != CR) && (val_next != LF) && (val_next != 0))  {\n                  // less than delimiter (\\x3c), maybe also badly formed with just new line\n                  tmp_line += (char)(val_next & 0xff);  // convert the byte to an unsigned int\n                  val_next =  (read < value.length) ? value[read++] : 0x00;\n                  if (read >= value.length) { break; }  // shouldn't ever hit this, but save a NPE\n               }\n\n               if (val_next == CT) {      //  start of a new section , when first didn't finish cleanly\n                   --read;\n               }\n\n               if (val_next == LT) {\n                  // hit the delimiter, carry on\n                  val_next =  (read < value.length) ? value[read++] : 0x00;\n               }\n\n               while ((val_next == CR) || (val_next == LF)) {\n                  val_next =  (read < value.length) ? value[read++] : 0x00;  // skip the new lines\n                  if ((val_next != CR) && (val_next != LF)) {\n                     --read;\n                  }\n               }\n               if (tmp_line.toLowerCase(Locale.ROOT).startsWith(\"by\") || longline.equals(\"bdy_author\")) {\n                  longkey = \"bdy_author\";\n\n                  // prepend a space to subsequent line, so it gets parsed consistent with the lead line\n                  tmp_line = (longline.equals(longkey) ? \" \" : \"\") + tmp_line;\n\n                  // we have an author candidate\n                  int term = tmp_line.length();\n                  term = Math.min(term, (tmp_line.contains(\"<\") ? tmp_line.indexOf(\"<\")  : term));\n                  term = Math.min(term, (tmp_line.contains(\"=\") ? tmp_line.indexOf(\"=\")  : term));\n                  term = Math.min(term, (tmp_line.contains(\"\\n\") ? tmp_line.indexOf(\"\\n\") : term));\n                  term = (term > 0 ) ? term : tmp_line.length();\n                  bdy_author += tmp_line.substring(tmp_line.indexOf(\" \"), term);\n                  metastarted = true;\n                  longline = ((tmp_line.contains(\"=\")) && (!longline.equals(longkey)) ? longkey : \"\");\n               }\n               else if (FORMAT == this.FMT_IPTC_BLM) {\n                  String byline = \"   by \";\n                  if (tmp_line.toLowerCase(Locale.ROOT).contains(byline)) {\n                     longkey = \"bdy_author\";\n\n                     int term = tmp_line.length();\n                     term = Math.min(term, (tmp_line.contains(\"<\") ? tmp_line.indexOf(\"<\")  : term));\n                     term = Math.min(term, (tmp_line.contains(\"=\") ? tmp_line.indexOf(\"=\")  : term));\n                     term = Math.min(term, (tmp_line.contains(\"\\n\") ? tmp_line.indexOf(\"\\n\") : term));\n                     term = (term > 0 ) ? term : tmp_line.length();\n                     // for bloomberg, the author line sits below their copyright statement\n                     bdy_author += tmp_line.substring(tmp_line.toLowerCase(Locale.ROOT).indexOf(byline) + byline.length(), term) + \" \";\n                     metastarted = true;\n                     longline = ((tmp_line.contains(\"=\")) && (!longline.equals(longkey)) ? longkey : \"\");\n                  }\n                  else if(tmp_line.toLowerCase(Locale.ROOT).startsWith(\"c.\")) {\n                     // the author line for bloomberg is a multiline starting with c.2011 Bloomberg News\n                     // then containing the author info on the next line\n                     if (val_next == TB) {\n                        value[--read] = CT;\n                        continue;\n                     }\n                  }\n                  else if(tmp_line.toLowerCase(Locale.ROOT).trim().startsWith(\"(\") && tmp_line.toLowerCase(Locale.ROOT).trim().endsWith(\")\")) {\n                     // the author line may have one or more comment lines between the copyright\n                     // statement, and the By AUTHORNAME line\n                     if (val_next == TB) {\n                        value[--read] = CT;\n                        continue;\n                     }\n                  }\n               }\n\n               else if (tmp_line.toLowerCase(Locale.ROOT).startsWith(\"eds\") || longline.equals(\"bdy_source\")) {\n                  longkey = \"bdy_source\";\n                  // prepend a space to subsequent line, so it gets parsed consistent with the lead line\n                  tmp_line = (longline.equals(longkey) ? \" \" : \"\") + tmp_line;\n\n                  // we have a source candidate\n                  int term = tmp_line.length();\n                  term = Math.min(term, (tmp_line.contains(\"<\") ? tmp_line.indexOf(\"<\")  : term));\n                  term = Math.min(term, (tmp_line.contains(\"=\") ? tmp_line.indexOf(\"=\")  : term));\n//                  term = Math.min(term, (tmp_line.indexOf(\"\\n\") > -1 ? tmp_line.indexOf(\"\\n\") : term));\n                  term = (term > 0 ) ? term : tmp_line.length();\n                  bdy_source += tmp_line.substring(tmp_line.indexOf(\" \") + 1, term) + \" \";\n                  metastarted = true;\n                  longline = (!longline.equals(longkey) ? longkey  : \"\");\n               }\n               else {\n                  // this has fallen all the way through.  trap it as part of the subject,\n                  // rather than just losing it\n                  if (!metastarted) {\n                     bdy_title += \" , \" + tmp_line;     //  not sure where else to put this but in the title\n                  }\n                  else {\n                     // what to do with stuff that is metadata, which falls after metadata lines started?\n                     bdy_body += \" \" + tmp_line + \" , \";     //  not sure where else to put this but in the title\n                  }\n               }\n            }\n            else {  // we're on to the main body\n               while ((read < value.length) && (val_next != 0))  {\n                  // read until the train runs out of tracks\n                  bdy_body += (char)(val_next & 0xff);  // convert the byte to an unsigned int\n                  val_next =  (read < value.length) ? value[read++] : 0x00;\n                  if (read >= value.length) { break; }  // shouldn't ever hit this, but save a NPE\n               }\n\n            }\n            // we would normally break here, but just let this read out to the end\n         }\n         done = true; // don't let this run back through and start thrashing metadata\n      }\n      properties.put(\"body\", bdy_body);\n      properties.put(\"title\", bdy_title);\n      properties.put(\"subject\", bdy_heading);\n      properties.put(\"author\", bdy_author);\n      properties.put(\"source\", bdy_source);\n\n      added = (bdy_body.length() + bdy_title.length() + bdy_heading.length() + bdy_author.length() +\n               bdy_source.length()) > 0;\n      return added;\n   }\n\n\n   private boolean parseFooter(byte[] value, HashMap<String,String> properties) {\n      boolean added = false;\n\n      String ftr_source = \"\";\n      String ftr_datetime = \"\";\n\n      int read = 0;\n      boolean done = false;\n\n      while (!done && (read < value.length)) {\n\n         // pull apart the footer, getting the news feed source (^....\\x0d\\x0a)\n         byte val_next = value[read++];\n         byte val_peek =  (read < value.length) ? value[read+1] : 0x00;  // skip the new lines\n\n         while (((val_next < (byte)0x30) || (val_next > (byte)0x39)) && (val_next != 0)) {  // consume all non-numerics first\n            ftr_source += (char)(val_next & 0xff);  // convert the byte to an unsigned int\n            val_next =  (read < value.length) ? value[read] : 0x00;  // attempt to read until end of stream\n            read++;\n            if (read >= value.length) { break; }  // shouldn't ever hit this, but save a NPE\n         }\n\n         while ((val_next != LT) && (val_next != CR) && (val_next != LF) && (val_next != 0))  {  // get as much timedate as possible\n            // this is an american format, so arrives as mm-dd-yy HHiizzz\n            ftr_datetime += (char)(val_next & 0xff);  // convert the byte to an unsigned int\n            val_next =  (read < value.length) ? value[read++] : 0x00;  // skip the new lines\n            if (read >= value.length) { break; }  // shouldn't ever hit this, but save a NPE\n         }\n         if (val_next == LT) {\n            // hit the delimiter, carry on\n            val_next =  (read < value.length) ? value[read++] : 0x00;\n         }\n\n         if (ftr_datetime.length() > 0) {\n            // we want to pass this back in a more friendly format\n            String format_out = \"yyyy-MM-dd'T'HH:mm:ss'Z'\";\n            Date dateunix = new Date();\n            try {\n               // standard ap format\n               String format_in = \"MM-dd-yy HHmmzzz\";\n\n               if (FORMAT == this.FMT_IPTC_RTR) {\n                  // standard reuters format\n                  format_in = \"HH:mm MM-dd-yy\";\n               }\n               SimpleDateFormat dfi = new SimpleDateFormat(format_in, Locale.ROOT);\n               dfi.setTimeZone(TimeZone.getTimeZone(\"UTC\"));\n               dateunix = dfi.parse(ftr_datetime);\n            }\n            catch (ParseException ep) {\n               // failed, but this will just fall through to setting the date to now\n            }\n            SimpleDateFormat dfo = new SimpleDateFormat(format_out, Locale.ROOT);\n            dfo.setTimeZone(TimeZone.getTimeZone(\"UTC\"));\n            ftr_datetime = dfo.format(dateunix);\n         }\n         while ((val_next == CR) || (val_next == LF)) {\n            val_next =  (read < value.length) ? value[read++] : 0x00;  // skip the new lines\n            if ((val_next != CR) && (val_next != LF)) {\n               --read;\n            }\n         }\n         done = true; // don't let this run back through and start thrashing metadata\n      }\n\n      properties.put(\"publisher\", ftr_source);\n      properties.put(\"created\", ftr_datetime);\n      properties.put(\"modified\", ftr_datetime);\n\n      added = (ftr_source.length() + ftr_datetime.length()) > 0; \n      return added;\n   }\n\n\n   private void setMetadata(Metadata metadata, HashMap<String,String> properties) {\n\n      // every property that gets set must be non-null, or it will cause NPE\n      // in other consuming applications, like Lucene\n      metadata.set(Metadata.CONTENT_TYPE,  clean(\"text/anpa-1312\"));\n      metadata.set(TikaCoreProperties.TITLE,         clean(properties.get(\"title\")));\n      metadata.set(TikaCoreProperties.SUBJECT,       clean(properties.get(\"subject\")));\n      metadata.set(TikaCoreProperties.CREATOR,        clean(properties.get(\"author\")));\n      metadata.set(TikaCoreProperties.CREATED, clean(properties.get(\"created\")));\n      metadata.set(TikaCoreProperties.MODIFIED,      clean(properties.get(\"modified\")));\n      metadata.set(TikaCoreProperties.SOURCE,      clean(properties.get(\"source\")));\n//      metadata.set(TikaCoreProperties.PUBLISHER,     clean(properties.get(\"publisher\")));\n      metadata.set(TikaCoreProperties.PUBLISHER,     clean(this.getFormatName()));\n\n/*\n        metadata.set(TikaCoreProperties.DATE, font.getHeader().getCreated().getTime());\n        metadata.set(\n                Property.internalDate(TikaCoreProperties.MODIFIED),\n                font.getHeader().getModified().getTime());\n*/\n   }\n\n   private String clean(String value) {\n      if (value == null) {\n         value = \"\";\n      }\n\n      value = value.replaceAll(\"``\", \"`\");\n      value = value.replaceAll(\"''\", \"'\");\n      value = value.replaceAll(new String(new char[] {SL}), \"'\");\n      value = value.replaceAll(new String(new char[] {SR}), \"'\");\n      value = value.replaceAll(new String(new char[] {DL}), \"\\\"\");\n      value = value.replaceAll(new String(new char[] {DR}), \"\\\"\");\n      value = value.trim();\n\n      return (value);\n   }\n}\n",
    "target": 0,
    "language": "java",
    "dataset": "vul4j",
    "idx": 200135,
    "RELATED_CWE": [
      "CWE-908",
      "CWE-362",
      "CWE-667"
    ]
  },
  {
    "CWE_ID": [
      "CWE-835"
    ],
    "code": "/*\n * The MIT License\n * \n * Copyright (c) 2004-2009, Sun Microsystems, Inc., Kohsuke Kawaguchi, InfraDNA, Inc.\n * \n * Permission is hereby granted, free of charge, to any person obtaining a copy\n * of this software and associated documentation files (the \"Software\"), to deal\n * in the Software without restriction, including without limitation the rights\n * to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n * copies of the Software, and to permit persons to whom the Software is\n * furnished to do so, subject to the following conditions:\n * \n * The above copyright notice and this permission notice shall be included in\n * all copies or substantial portions of the Software.\n * \n * THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n * OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\n * THE SOFTWARE.\n */\npackage hudson.scheduler;\n\nimport antlr.ANTLRException;\n\nimport java.io.StringReader;\nimport java.util.Calendar;\nimport java.util.TimeZone;\nimport java.util.GregorianCalendar;\nimport java.util.Locale;\nimport java.util.regex.Matcher;\nimport java.util.regex.Pattern;\n\nimport static java.util.Calendar.*;\nimport javax.annotation.CheckForNull;\n\n/**\n * Table for driving scheduled tasks.\n *\n * @author Kohsuke Kawaguchi\n */\npublic final class CronTab {\n    /**\n     * bits[0]: minutes\n     * bits[1]: hours\n     * bits[2]: days\n     * bits[3]: months\n     *\n     * false:not scheduled &lt;-> true scheduled\n     */\n    final long[] bits = new long[4];\n\n    int dayOfWeek;\n\n    /**\n     * Textual representation.\n     */\n    private String spec;\n\n    /**\n     * Optional timezone string for calendar \n     */\n    private @CheckForNull String specTimezone;\n\n    public CronTab(String format) throws ANTLRException {\n        this(format,null);\n    }\n\n    public CronTab(String format, Hash hash) throws ANTLRException {\n        this(format,1,hash);\n    }\n    \n    /**\n     * @deprecated as of 1.448\n     *      Use {@link #CronTab(String, int, Hash)}\n     */\n    @Deprecated\n    public CronTab(String format, int line) throws ANTLRException {\n        set(format, line, null);\n    }\n\n    /**\n     * @param hash\n     *      Used to spread out token like \"@daily\". Null to preserve the legacy behaviour\n     *      of not spreading it out at all.\n     */\n    public CronTab(String format, int line, Hash hash) throws ANTLRException {\n        this(format, line, hash, null);\n    }\n\n    /**\n     * @param timezone\n     *      Used to schedule cron in a different timezone. Null to use the default system \n     *      timezone\n     * @since 1.615\n     */\n    public CronTab(String format, int line, Hash hash, @CheckForNull String timezone) throws ANTLRException {\n        set(format, line, hash, timezone);\n    }\n    \n    private void set(String format, int line, Hash hash) throws ANTLRException {\n        set(format, line, hash, null);\n    }\n\n    /**\n     * @since 1.615\n     */\n    private void set(String format, int line, Hash hash, String timezone) throws ANTLRException {\n        CrontabLexer lexer = new CrontabLexer(new StringReader(format));\n        lexer.setLine(line);\n        CrontabParser parser = new CrontabParser(lexer);\n        parser.setHash(hash);\n        spec = format;\n        specTimezone = timezone;\n\n        parser.startRule(this);\n        if((dayOfWeek&(1<<7))!=0) {\n            dayOfWeek |= 1; // copy bit 7 over to bit 0\n            dayOfWeek &= ~(1<<7); // clear bit 7 or CalendarField#ceil will return an invalid value 7\n        }\n    }\n\n\n    /**\n     * Returns true if the given calendar matches\n     */\n    boolean check(Calendar cal) {\n\n        Calendar checkCal = cal;\n\n        if(specTimezone != null && !specTimezone.isEmpty()) {\n            Calendar tzCal = Calendar.getInstance(TimeZone.getTimeZone(specTimezone));\n            tzCal.setTime(cal.getTime());\n            checkCal = tzCal;\n        }\n\n        if(!checkBits(bits[0],checkCal.get(MINUTE)))\n            return false;\n        if(!checkBits(bits[1],checkCal.get(HOUR_OF_DAY)))\n            return false;\n        if(!checkBits(bits[2],checkCal.get(DAY_OF_MONTH)))\n            return false;\n        if(!checkBits(bits[3],checkCal.get(MONTH)+1))\n            return false;\n        if(!checkBits(dayOfWeek,checkCal.get(Calendar.DAY_OF_WEEK)-1))\n            return false;\n\n        return true;\n    }\n\n    private static abstract class CalendarField {\n        /**\n         * {@link Calendar} field ID.\n         */\n        final int field;\n        /**\n         * Lower field is a calendar field whose value needs to be reset when we change the value in this field.\n         * For example, if we modify the value in HOUR, MINUTES must be reset.\n         */\n        final CalendarField lowerField;\n        /**\n         * Whether this field is 0-origin or 1-origin differs between Crontab and {@link Calendar},\n         * so this field adjusts that. If crontab is 1 origin and calendar is 0 origin,  this field is 1\n         * that is the value is {@code (cronOrigin-calendarOrigin)}\n         */\n        final int offset;\n        /**\n         * When we reset this field, we set the field to this value.\n         * For example, resetting {@link Calendar#DAY_OF_MONTH} means setting it to 1.\n         */\n        final int min;\n        /**\n         * If this calendar field has other aliases such that a change in this field\n         * modifies other field values, then true.\n         */\n        final boolean redoAdjustmentIfModified;\n\n        /**\n         * What is this field? Useful for debugging\n         */\n        @SuppressWarnings(\"unused\")\n        private final String displayName;\n\n        private CalendarField(String displayName, int field, int min, int offset, boolean redoAdjustmentIfModified, CalendarField lowerField) {\n            this.displayName = displayName;\n            this.field = field;\n            this.min = min;\n            this.redoAdjustmentIfModified= redoAdjustmentIfModified;\n            this.lowerField = lowerField;\n            this.offset = offset;\n        }\n\n        /**\n         * Gets the current value of this field in the given calendar.\n         */\n        int valueOf(Calendar c) {\n            return c.get(field)+offset;\n        }\n\n        void addTo(Calendar c, int i) {\n            c.add(field,i);\n        }\n\n        void setTo(Calendar c, int i) {\n            c.set(field,i-offset);\n        }\n\n        void clear(Calendar c) {\n            setTo(c, min);\n        }\n\n        /**\n         * Given the value 'n' (which represents the current value), finds the smallest x such that:\n         *  1) x matches the specified {@link CronTab} (as far as this field is concerned.)\n         *  2) x>=n   (inclusive)\n         *\n         * If there's no such bit, return -1. Note that if 'n' already matches the crontab, the same n will be returned.\n         */\n        private int ceil(CronTab c, int n) {\n            long bits = bits(c);\n            while ((bits|(1L<<n))!=bits) {\n                if (n>60)   return -1;\n                n++;\n            }\n            return n;\n        }\n\n        /**\n         * Given a bit mask, finds the first bit that's on, and return its index.\n         */\n        private int first(CronTab c) {\n            return ceil(c,0);\n        }\n\n        private int floor(CronTab c, int n) {\n            long bits = bits(c);\n            while ((bits|(1L<<n))!=bits) {\n                if (n==0)   return -1;\n                n--;\n            }\n            return n;\n        }\n\n        private int last(CronTab c) {\n            return floor(c,63);\n        }\n\n        /**\n         * Extracts the bit masks from the given {@link CronTab} that matches this field.\n         */\n        abstract long bits(CronTab c);\n\n        /**\n         * Increment the next field.\n         */\n        abstract void rollUp(Calendar cal, int i);\n\n        private static final CalendarField MINUTE       = new CalendarField(\"minute\", Calendar.MINUTE,        0, 0, false, null) {\n            long bits(CronTab c) { return c.bits[0]; }\n            void rollUp(Calendar cal, int i) { cal.add(Calendar.HOUR_OF_DAY,i); }\n        };\n        private static final CalendarField HOUR         = new CalendarField(\"hour\", Calendar.HOUR_OF_DAY,   0, 0, false, MINUTE) {\n            long bits(CronTab c) { return c.bits[1]; }\n            void rollUp(Calendar cal, int i) { cal.add(Calendar.DAY_OF_MONTH,i); }\n        };\n        private static final CalendarField DAY_OF_MONTH = new CalendarField(\"day\", Calendar.DAY_OF_MONTH,  1, 0, true,  HOUR) {\n            long bits(CronTab c) { return c.bits[2]; }\n            void rollUp(Calendar cal, int i) { cal.add(Calendar.MONTH,i); }\n        };\n        private static final CalendarField MONTH        = new CalendarField(\"month\", Calendar.MONTH,         1, 1, false, DAY_OF_MONTH) {\n            long bits(CronTab c) { return c.bits[3]; }\n            void rollUp(Calendar cal, int i) { cal.add(Calendar.YEAR,i); }\n        };\n        private static final CalendarField DAY_OF_WEEK  = new CalendarField(\"dow\", Calendar.DAY_OF_WEEK,   1,-1, true,  HOUR) {\n            long bits(CronTab c) { return c.dayOfWeek; }\n            void rollUp(Calendar cal, int i) {\n                cal.add(Calendar.DAY_OF_WEEK, 7 * i);\n            }\n\n            @Override\n            void setTo(Calendar c, int i) {\n                int v = i-offset;\n                int was = c.get(field);\n                c.set(field,v);\n                final int firstDayOfWeek = c.getFirstDayOfWeek();\n                if (v < firstDayOfWeek && was >= firstDayOfWeek) {\n                    // in crontab, the first DoW is always Sunday, but in Java, it can be Monday or in theory arbitrary other days.\n                    // When first DoW is 1/2 Monday, calendar points to 1/2 Monday, setting the DoW to Sunday makes\n                    // the calendar moves forward to 1/8 Sunday, instead of 1/1 Sunday. So we need to compensate that effect here.\n                    addTo(c,-7);\n                } else if (was < firstDayOfWeek && firstDayOfWeek <= v) {\n                    // If we wrap the other way around, we need to adjust in the opposite direction of above.\n                    addTo(c, 7);\n                }\n            }\n        };\n\n        private static final CalendarField[] ADJUST_ORDER = {\n            MONTH, DAY_OF_MONTH, DAY_OF_WEEK, HOUR, MINUTE\n        };\n    }\n\n\n    /**\n     * Computes the nearest future timestamp that matches this cron tab.\n     * <p>\n     * More precisely, given the time 't', computes another smallest time x such that:\n     *\n     * <ul>\n     * <li>x \u2265 t (inclusive)\n     * <li>x matches this crontab\n     * </ul>\n     *\n     * <p>\n     * Note that if t already matches this cron, it's returned as is.\n     */\n    public Calendar ceil(long t) {\n        Calendar cal = new GregorianCalendar(Locale.US);\n        cal.setTimeInMillis(t);\n        return ceil(cal);\n    }\n\n    /**\n     * See {@link #ceil(long)}.\n     *\n     * This method modifies the given calendar and returns the same object.\n     *\n     * @throws RareOrImpossibleDateException if the date isn't hit in the 2 years after it indicates an impossible\n     * (e.g. Jun 31) date, or at least a date too rare to be useful. This addresses JENKINS-41864 and was added in 2.49\n     */\n    public Calendar ceil(Calendar cal) {\n        Calendar twoYearsFuture = (Calendar) cal.clone();\n        twoYearsFuture.add(Calendar.YEAR, 2);\n        OUTER:\n        while (true) {\n            if (cal.compareTo(twoYearsFuture) > 0) {\n                // we went too far into the future\n                throw new RareOrImpossibleDateException();\n            }\n            for (CalendarField f : CalendarField.ADJUST_ORDER) {\n                int cur = f.valueOf(cal);\n                int next = f.ceil(this,cur);\n                if (cur==next)  continue;   // this field is already in a good shape. move on to next\n\n                // we are modifying this field, so clear all the lower level fields\n                for (CalendarField l=f.lowerField; l!=null; l=l.lowerField)\n                    l.clear(cal);\n\n                if (next<0) {\n                    // we need to roll over to the next field.\n                    f.rollUp(cal, 1);\n                    f.setTo(cal,f.first(this));\n                    // since higher order field is affected by this, we need to restart from all over\n                    continue OUTER;\n                } else {\n                    f.setTo(cal,next);\n                    if (f.redoAdjustmentIfModified)\n                        continue OUTER; // when we modify DAY_OF_MONTH and DAY_OF_WEEK, do it all over from the top\n                }\n            }\n            return cal; // all fields adjusted\n        }\n    }\n\n    /**\n     * Computes the nearest past timestamp that matched this cron tab.\n     * <p>\n     * More precisely, given the time 't', computes another smallest time x such that:\n     *\n     * <ul>\n     * <li>x &lt;= t (inclusive)\n     * <li>x matches this crontab\n     * </ul>\n     *\n     * <p>\n     * Note that if t already matches this cron, it's returned as is.\n     */\n    public Calendar floor(long t) {\n        Calendar cal = new GregorianCalendar(Locale.US);\n        cal.setTimeInMillis(t);\n        return floor(cal);\n    }\n\n    /**\n     * See {@link #floor(long)}\n     *\n     * This method modifies the given calendar and returns the same object.\n     *\n     * @throws RareOrImpossibleDateException if the date isn't hit in the 2 years before it indicates an impossible\n     * (e.g. Jun 31) date, or at least a date too rare to be useful. This addresses JENKINS-41864 and was added in 2.49\n     */\n    public Calendar floor(Calendar cal) {\n        Calendar twoYearsAgo = (Calendar) cal.clone();\n        twoYearsAgo.add(Calendar.YEAR, -2);\n\n        OUTER:\n        while (true) {\n            if (cal.compareTo(twoYearsAgo) < 0) {\n                // we went too far into the past\n                throw new RareOrImpossibleDateException();\n            }\n            for (CalendarField f : CalendarField.ADJUST_ORDER) {\n                int cur = f.valueOf(cal);\n                int next = f.floor(this,cur);\n                if (cur==next)  continue;   // this field is already in a good shape. move on to next\n\n                // we are modifying this field, so clear all the lower level fields\n                for (CalendarField l=f.lowerField; l!=null; l=l.lowerField)\n                    l.clear(cal);\n\n                if (next<0) {\n                    // we need to borrow from the next field.\n                    f.rollUp(cal,-1);\n                    // the problem here, in contrast with the ceil method, is that\n                    // the maximum value of the field is not always a fixed value (that is, day of month)\n                    // so we zero-clear all the lower fields, set the desired value +1,\n                    f.setTo(cal,f.last(this));\n                    f.addTo(cal,1);\n                    // then subtract a minute to achieve maximum values on all the lower fields,\n                    // with the desired value in 'f'\n                    CalendarField.MINUTE.addTo(cal,-1);\n                    // since higher order field is affected by this, we need to restart from all over\n                    continue OUTER;\n                } else {\n                    f.setTo(cal,next);\n                    f.addTo(cal,1);\n                    CalendarField.MINUTE.addTo(cal,-1);\n                    if (f.redoAdjustmentIfModified)\n                        continue OUTER; // when we modify DAY_OF_MONTH and DAY_OF_WEEK, do it all over from the top\n                }\n            }\n            return cal; // all fields adjusted\n        }\n    }\n\n    void set(String format, Hash hash) throws ANTLRException {\n        set(format,1,hash);\n    }\n\n    /**\n     * Returns true if n-th bit is on.\n     */\n    private boolean checkBits(long bitMask, int n) {\n        return (bitMask|(1L<<n))==bitMask;\n    }\n\n    public String toString() {\n        return super.toString()+\"[\"+\n            toString(\"minute\",bits[0])+','+\n            toString(\"hour\",bits[1])+','+\n            toString(\"dayOfMonth\",bits[2])+','+\n            toString(\"month\",bits[3])+','+\n            toString(\"dayOfWeek\",dayOfWeek)+']';\n    }\n\n    private String toString(String key, long bit) {\n        return key+'='+Long.toHexString(bit);\n    }\n\n    /**\n     * Checks if this crontab entry looks reasonable,\n     * and if not, return an warning message.\n     *\n     * <p>\n     * The point of this method is to catch syntactically correct\n     * but semantically suspicious combinations, like\n     * \"* 0 * * *\"\n     */\n    public @CheckForNull String checkSanity() {\n        OUTER: for (int i = 0; i < 5; i++) {\n            long bitMask = (i<4)?bits[i]:(long)dayOfWeek;\n            for( int j=BaseParser.LOWER_BOUNDS[i]; j<=BaseParser.UPPER_BOUNDS[i]; j++ ) {\n                if(!checkBits(bitMask,j)) {\n                    // this rank has a sparse entry.\n                    // if we have a sparse rank, one of them better be the left-most.\n                    if(i>0)\n                        return Messages.CronTab_do_you_really_mean_every_minute_when_you(spec, \"H \" + spec.substring(spec.indexOf(' ') + 1));\n                    // once we find a sparse rank, upper ranks don't matter\n                    break OUTER;\n                }\n            }\n        }\n\n        int daysOfMonth = 0;\n        for (int i = 1; i < 31; i++) {\n            if (checkBits(bits[2], i)) {\n                daysOfMonth++;\n            }\n        }\n        if (daysOfMonth > 5 && daysOfMonth < 28) { // a bit arbitrary\n            return Messages.CronTab_short_cycles_in_the_day_of_month_field_w();\n        }\n\n        String hashified = hashify(spec);\n        if (hashified != null) {\n            return Messages.CronTab_spread_load_evenly_by_using_rather_than_(hashified, spec);\n        }\n\n        return null;\n    }\n\n    /**\n     * Checks a prospective crontab specification to see if it could benefit from balanced hashes.\n     * @param spec a (legal) spec\n     * @return a similar spec that uses a hash, if such a transformation is necessary; null if it is OK as is\n     * @since 1.510\n     */\n    public static @CheckForNull String hashify(String spec) {\n        if (spec.contains(\"H\")) {\n            // if someone is already using H, presumably he knows what it is, so a warning is likely false positive\n            return null;\n        } else if (spec.startsWith(\"*/\")) {// \"*/15 ....\" (every N minutes) to hash\n            return \"H\" + spec.substring(1);\n        } else if (spec.matches(\"\\\\d+ .+\")) {// \"0 ...\" (certain minute) to hash\n            return \"H \" + spec.substring(spec.indexOf(' ') + 1);\n        } else {\n            Matcher m = Pattern.compile(\"0(,(\\\\d+)(,\\\\d+)*)( .+)\").matcher(spec);\n            if (m.matches()) { // 0,15,30,45 to H/15\n                int period = Integer.parseInt(m.group(2));\n                if (period > 0) {\n                    StringBuilder b = new StringBuilder();\n                    for (int i = period; i < 60; i += period) {\n                        b.append(',').append(i);\n                    }\n                    if (b.toString().equals(m.group(1))) {\n                        return \"H/\" + period + m.group(4);\n                    }\n                }\n            }\n            return null;\n        }\n    }\n\n    /**\n     * Returns the configured time zone, or null if none is configured\n     *\n     * @return the configured time zone, or null if none is configured\n     * @since 2.54\n     */\n    @CheckForNull public TimeZone getTimeZone() {\n        if (this.specTimezone == null) {\n            return null;\n        }\n        return TimeZone.getTimeZone(this.specTimezone);\n    }\n}\n",
    "target": 1,
    "language": "java",
    "dataset": "vul4j",
    "idx": 200160,
    "RELATED_CWE": [
      "CWE-908",
      "CWE-362",
      "CWE-667"
    ]
  },
  {
    "CWE_ID": [
      "CWE-835"
    ],
    "code": "/*\n * The MIT License\n * \n * Copyright (c) 2004-2009, Sun Microsystems, Inc., Kohsuke Kawaguchi, InfraDNA, Inc.\n * \n * Permission is hereby granted, free of charge, to any person obtaining a copy\n * of this software and associated documentation files (the \"Software\"), to deal\n * in the Software without restriction, including without limitation the rights\n * to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n * copies of the Software, and to permit persons to whom the Software is\n * furnished to do so, subject to the following conditions:\n * \n * The above copyright notice and this permission notice shall be included in\n * all copies or substantial portions of the Software.\n * \n * THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n * OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\n * THE SOFTWARE.\n */\npackage hudson.scheduler;\n\nimport antlr.ANTLRException;\n\nimport java.io.StringReader;\nimport java.util.Calendar;\nimport java.util.TimeZone;\nimport java.util.GregorianCalendar;\nimport java.util.Locale;\nimport java.util.regex.Matcher;\nimport java.util.regex.Pattern;\n\nimport static java.util.Calendar.*;\nimport javax.annotation.CheckForNull;\n\n/**\n * Table for driving scheduled tasks.\n *\n * @author Kohsuke Kawaguchi\n */\npublic final class CronTab {\n    /**\n     * bits[0]: minutes\n     * bits[1]: hours\n     * bits[2]: days\n     * bits[3]: months\n     *\n     * false:not scheduled &lt;-> true scheduled\n     */\n    final long[] bits = new long[4];\n\n    int dayOfWeek;\n\n    /**\n     * Textual representation.\n     */\n    private String spec;\n\n    /**\n     * Optional timezone string for calendar \n     */\n    private @CheckForNull String specTimezone;\n\n    public CronTab(String format) throws ANTLRException {\n        this(format,null);\n    }\n\n    public CronTab(String format, Hash hash) throws ANTLRException {\n        this(format,1,hash);\n    }\n    \n    /**\n     * @deprecated as of 1.448\n     *      Use {@link #CronTab(String, int, Hash)}\n     */\n    @Deprecated\n    public CronTab(String format, int line) throws ANTLRException {\n        set(format, line, null);\n    }\n\n    /**\n     * @param hash\n     *      Used to spread out token like \"@daily\". Null to preserve the legacy behaviour\n     *      of not spreading it out at all.\n     */\n    public CronTab(String format, int line, Hash hash) throws ANTLRException {\n        this(format, line, hash, null);\n    }\n\n    /**\n     * @param timezone\n     *      Used to schedule cron in a different timezone. Null to use the default system \n     *      timezone\n     * @since 1.615\n     */\n    public CronTab(String format, int line, Hash hash, @CheckForNull String timezone) throws ANTLRException {\n        set(format, line, hash, timezone);\n    }\n    \n    private void set(String format, int line, Hash hash) throws ANTLRException {\n        set(format, line, hash, null);\n    }\n\n    /**\n     * @since 1.615\n     */\n    private void set(String format, int line, Hash hash, String timezone) throws ANTLRException {\n        CrontabLexer lexer = new CrontabLexer(new StringReader(format));\n        lexer.setLine(line);\n        CrontabParser parser = new CrontabParser(lexer);\n        parser.setHash(hash);\n        spec = format;\n        specTimezone = timezone;\n\n        parser.startRule(this);\n        if((dayOfWeek&(1<<7))!=0) {\n            dayOfWeek |= 1; // copy bit 7 over to bit 0\n            dayOfWeek &= ~(1<<7); // clear bit 7 or CalendarField#ceil will return an invalid value 7\n        }\n    }\n\n\n    /**\n     * Returns true if the given calendar matches\n     */\n    boolean check(Calendar cal) {\n\n        Calendar checkCal = cal;\n\n        if(specTimezone != null && !specTimezone.isEmpty()) {\n            Calendar tzCal = Calendar.getInstance(TimeZone.getTimeZone(specTimezone));\n            tzCal.setTime(cal.getTime());\n            checkCal = tzCal;\n        }\n\n        if(!checkBits(bits[0],checkCal.get(MINUTE)))\n            return false;\n        if(!checkBits(bits[1],checkCal.get(HOUR_OF_DAY)))\n            return false;\n        if(!checkBits(bits[2],checkCal.get(DAY_OF_MONTH)))\n            return false;\n        if(!checkBits(bits[3],checkCal.get(MONTH)+1))\n            return false;\n        if(!checkBits(dayOfWeek,checkCal.get(Calendar.DAY_OF_WEEK)-1))\n            return false;\n\n        return true;\n    }\n\n    private static abstract class CalendarField {\n        /**\n         * {@link Calendar} field ID.\n         */\n        final int field;\n        /**\n         * Lower field is a calendar field whose value needs to be reset when we change the value in this field.\n         * For example, if we modify the value in HOUR, MINUTES must be reset.\n         */\n        final CalendarField lowerField;\n        /**\n         * Whether this field is 0-origin or 1-origin differs between Crontab and {@link Calendar},\n         * so this field adjusts that. If crontab is 1 origin and calendar is 0 origin,  this field is 1\n         * that is the value is {@code (cronOrigin-calendarOrigin)}\n         */\n        final int offset;\n        /**\n         * When we reset this field, we set the field to this value.\n         * For example, resetting {@link Calendar#DAY_OF_MONTH} means setting it to 1.\n         */\n        final int min;\n        /**\n         * If this calendar field has other aliases such that a change in this field\n         * modifies other field values, then true.\n         */\n        final boolean redoAdjustmentIfModified;\n\n        /**\n         * What is this field? Useful for debugging\n         */\n        @SuppressWarnings(\"unused\")\n        private final String displayName;\n\n        private CalendarField(String displayName, int field, int min, int offset, boolean redoAdjustmentIfModified, CalendarField lowerField) {\n            this.displayName = displayName;\n            this.field = field;\n            this.min = min;\n            this.redoAdjustmentIfModified= redoAdjustmentIfModified;\n            this.lowerField = lowerField;\n            this.offset = offset;\n        }\n\n        /**\n         * Gets the current value of this field in the given calendar.\n         */\n        int valueOf(Calendar c) {\n            return c.get(field)+offset;\n        }\n\n        void addTo(Calendar c, int i) {\n            c.add(field,i);\n        }\n\n        void setTo(Calendar c, int i) {\n            c.set(field,Math.min(i-offset, c.getActualMaximum(field)));\n        }\n\n        void clear(Calendar c) {\n            setTo(c, min);\n        }\n\n        /**\n         * Given the value 'n' (which represents the current value), finds the smallest x such that:\n         *  1) x matches the specified {@link CronTab} (as far as this field is concerned.)\n         *  2) x>=n   (inclusive)\n         *\n         * If there's no such bit, return -1. Note that if 'n' already matches the crontab, the same n will be returned.\n         */\n        private int ceil(CronTab c, int n) {\n            long bits = bits(c);\n            while ((bits|(1L<<n))!=bits) {\n                if (n>60)   return -1;\n                n++;\n            }\n            return n;\n        }\n\n        /**\n         * Given a bit mask, finds the first bit that's on, and return its index.\n         */\n        private int first(CronTab c) {\n            return ceil(c,0);\n        }\n\n        private int floor(CronTab c, int n) {\n            long bits = bits(c);\n            while ((bits|(1L<<n))!=bits) {\n                if (n==0)   return -1;\n                n--;\n            }\n            return n;\n        }\n\n        private int last(CronTab c) {\n            return floor(c,63);\n        }\n\n        /**\n         * Extracts the bit masks from the given {@link CronTab} that matches this field.\n         */\n        abstract long bits(CronTab c);\n\n        /**\n         * Increment the next field.\n         */\n        abstract void rollUp(Calendar cal, int i);\n\n        private static final CalendarField MINUTE       = new CalendarField(\"minute\", Calendar.MINUTE,        0, 0, false, null) {\n            long bits(CronTab c) { return c.bits[0]; }\n            void rollUp(Calendar cal, int i) { cal.add(Calendar.HOUR_OF_DAY,i); }\n        };\n        private static final CalendarField HOUR         = new CalendarField(\"hour\", Calendar.HOUR_OF_DAY,   0, 0, false, MINUTE) {\n            long bits(CronTab c) { return c.bits[1]; }\n            void rollUp(Calendar cal, int i) { cal.add(Calendar.DAY_OF_MONTH,i); }\n        };\n        private static final CalendarField DAY_OF_MONTH = new CalendarField(\"day\", Calendar.DAY_OF_MONTH,  1, 0, true,  HOUR) {\n            long bits(CronTab c) { return c.bits[2]; }\n            void rollUp(Calendar cal, int i) { cal.add(Calendar.MONTH,i); }\n        };\n        private static final CalendarField MONTH        = new CalendarField(\"month\", Calendar.MONTH,         1, 1, false, DAY_OF_MONTH) {\n            long bits(CronTab c) { return c.bits[3]; }\n            void rollUp(Calendar cal, int i) { cal.add(Calendar.YEAR,i); }\n        };\n        private static final CalendarField DAY_OF_WEEK  = new CalendarField(\"dow\", Calendar.DAY_OF_WEEK,   1,-1, true,  HOUR) {\n            long bits(CronTab c) { return c.dayOfWeek; }\n            void rollUp(Calendar cal, int i) {\n                cal.add(Calendar.DAY_OF_WEEK, 7 * i);\n            }\n\n            @Override\n            void setTo(Calendar c, int i) {\n                int v = i-offset;\n                int was = c.get(field);\n                c.set(field,v);\n                final int firstDayOfWeek = c.getFirstDayOfWeek();\n                if (v < firstDayOfWeek && was >= firstDayOfWeek) {\n                    // in crontab, the first DoW is always Sunday, but in Java, it can be Monday or in theory arbitrary other days.\n                    // When first DoW is 1/2 Monday, calendar points to 1/2 Monday, setting the DoW to Sunday makes\n                    // the calendar moves forward to 1/8 Sunday, instead of 1/1 Sunday. So we need to compensate that effect here.\n                    addTo(c,-7);\n                } else if (was < firstDayOfWeek && firstDayOfWeek <= v) {\n                    // If we wrap the other way around, we need to adjust in the opposite direction of above.\n                    addTo(c, 7);\n                }\n            }\n        };\n\n        private static final CalendarField[] ADJUST_ORDER = {\n            MONTH, DAY_OF_MONTH, DAY_OF_WEEK, HOUR, MINUTE\n        };\n    }\n\n\n    /**\n     * Computes the nearest future timestamp that matches this cron tab.\n     * <p>\n     * More precisely, given the time 't', computes another smallest time x such that:\n     *\n     * <ul>\n     * <li>x \u2265 t (inclusive)\n     * <li>x matches this crontab\n     * </ul>\n     *\n     * <p>\n     * Note that if t already matches this cron, it's returned as is.\n     */\n    public Calendar ceil(long t) {\n        Calendar cal = new GregorianCalendar(Locale.US);\n        cal.setTimeInMillis(t);\n        return ceil(cal);\n    }\n\n    /**\n     * See {@link #ceil(long)}.\n     *\n     * This method modifies the given calendar and returns the same object.\n     *\n     * @throws RareOrImpossibleDateException if the date isn't hit in the 2 years after it indicates an impossible\n     * (e.g. Jun 31) date, or at least a date too rare to be useful. This addresses JENKINS-41864 and was added in 2.49\n     */\n    public Calendar ceil(Calendar cal) {\n        Calendar twoYearsFuture = (Calendar) cal.clone();\n        twoYearsFuture.add(Calendar.YEAR, 2);\n        OUTER:\n        while (true) {\n            if (cal.compareTo(twoYearsFuture) > 0) {\n                // we went too far into the future\n                throw new RareOrImpossibleDateException();\n            }\n            for (CalendarField f : CalendarField.ADJUST_ORDER) {\n                int cur = f.valueOf(cal);\n                int next = f.ceil(this,cur);\n                if (cur==next)  continue;   // this field is already in a good shape. move on to next\n\n                // we are modifying this field, so clear all the lower level fields\n                for (CalendarField l=f.lowerField; l!=null; l=l.lowerField)\n                    l.clear(cal);\n\n                if (next<0) {\n                    // we need to roll over to the next field.\n                    f.rollUp(cal, 1);\n                    f.setTo(cal,f.first(this));\n                    // since higher order field is affected by this, we need to restart from all over\n                    continue OUTER;\n                } else {\n                    f.setTo(cal,next);\n                    if (f.redoAdjustmentIfModified)\n                        continue OUTER; // when we modify DAY_OF_MONTH and DAY_OF_WEEK, do it all over from the top\n                }\n            }\n            return cal; // all fields adjusted\n        }\n    }\n\n    /**\n     * Computes the nearest past timestamp that matched this cron tab.\n     * <p>\n     * More precisely, given the time 't', computes another smallest time x such that:\n     *\n     * <ul>\n     * <li>x &lt;= t (inclusive)\n     * <li>x matches this crontab\n     * </ul>\n     *\n     * <p>\n     * Note that if t already matches this cron, it's returned as is.\n     */\n    public Calendar floor(long t) {\n        Calendar cal = new GregorianCalendar(Locale.US);\n        cal.setTimeInMillis(t);\n        return floor(cal);\n    }\n\n    /**\n     * See {@link #floor(long)}\n     *\n     * This method modifies the given calendar and returns the same object.\n     *\n     * @throws RareOrImpossibleDateException if the date isn't hit in the 2 years before it indicates an impossible\n     * (e.g. Jun 31) date, or at least a date too rare to be useful. This addresses JENKINS-41864 and was added in 2.49\n     */\n    public Calendar floor(Calendar cal) {\n        Calendar twoYearsAgo = (Calendar) cal.clone();\n        twoYearsAgo.add(Calendar.YEAR, -2);\n\n        OUTER:\n        while (true) {\n            if (cal.compareTo(twoYearsAgo) < 0) {\n                // we went too far into the past\n                throw new RareOrImpossibleDateException();\n            }\n            for (CalendarField f : CalendarField.ADJUST_ORDER) {\n                int cur = f.valueOf(cal);\n                int next = f.floor(this,cur);\n                if (cur==next)  continue;   // this field is already in a good shape. move on to next\n\n                // we are modifying this field, so clear all the lower level fields\n                for (CalendarField l=f.lowerField; l!=null; l=l.lowerField)\n                    l.clear(cal);\n\n                if (next<0) {\n                    // we need to borrow from the next field.\n                    f.rollUp(cal,-1);\n                    // the problem here, in contrast with the ceil method, is that\n                    // the maximum value of the field is not always a fixed value (that is, day of month)\n                    // so we zero-clear all the lower fields, set the desired value +1,\n                    f.setTo(cal,f.last(this));\n                    f.addTo(cal,1);\n                    // then subtract a minute to achieve maximum values on all the lower fields,\n                    // with the desired value in 'f'\n                    CalendarField.MINUTE.addTo(cal,-1);\n                    // since higher order field is affected by this, we need to restart from all over\n                    continue OUTER;\n                } else {\n                    f.setTo(cal,next);\n                    f.addTo(cal,1);\n                    CalendarField.MINUTE.addTo(cal,-1);\n                    if (f.redoAdjustmentIfModified)\n                        continue OUTER; // when we modify DAY_OF_MONTH and DAY_OF_WEEK, do it all over from the top\n                }\n            }\n            return cal; // all fields adjusted\n        }\n    }\n\n    void set(String format, Hash hash) throws ANTLRException {\n        set(format,1,hash);\n    }\n\n    /**\n     * Returns true if n-th bit is on.\n     */\n    private boolean checkBits(long bitMask, int n) {\n        return (bitMask|(1L<<n))==bitMask;\n    }\n\n    public String toString() {\n        return super.toString()+\"[\"+\n            toString(\"minute\",bits[0])+','+\n            toString(\"hour\",bits[1])+','+\n            toString(\"dayOfMonth\",bits[2])+','+\n            toString(\"month\",bits[3])+','+\n            toString(\"dayOfWeek\",dayOfWeek)+']';\n    }\n\n    private String toString(String key, long bit) {\n        return key+'='+Long.toHexString(bit);\n    }\n\n    /**\n     * Checks if this crontab entry looks reasonable,\n     * and if not, return an warning message.\n     *\n     * <p>\n     * The point of this method is to catch syntactically correct\n     * but semantically suspicious combinations, like\n     * \"* 0 * * *\"\n     */\n    public @CheckForNull String checkSanity() {\n        OUTER: for (int i = 0; i < 5; i++) {\n            long bitMask = (i<4)?bits[i]:(long)dayOfWeek;\n            for( int j=BaseParser.LOWER_BOUNDS[i]; j<=BaseParser.UPPER_BOUNDS[i]; j++ ) {\n                if(!checkBits(bitMask,j)) {\n                    // this rank has a sparse entry.\n                    // if we have a sparse rank, one of them better be the left-most.\n                    if(i>0)\n                        return Messages.CronTab_do_you_really_mean_every_minute_when_you(spec, \"H \" + spec.substring(spec.indexOf(' ') + 1));\n                    // once we find a sparse rank, upper ranks don't matter\n                    break OUTER;\n                }\n            }\n        }\n\n        int daysOfMonth = 0;\n        for (int i = 1; i < 31; i++) {\n            if (checkBits(bits[2], i)) {\n                daysOfMonth++;\n            }\n        }\n        if (daysOfMonth > 5 && daysOfMonth < 28) { // a bit arbitrary\n            return Messages.CronTab_short_cycles_in_the_day_of_month_field_w();\n        }\n\n        String hashified = hashify(spec);\n        if (hashified != null) {\n            return Messages.CronTab_spread_load_evenly_by_using_rather_than_(hashified, spec);\n        }\n\n        return null;\n    }\n\n    /**\n     * Checks a prospective crontab specification to see if it could benefit from balanced hashes.\n     * @param spec a (legal) spec\n     * @return a similar spec that uses a hash, if such a transformation is necessary; null if it is OK as is\n     * @since 1.510\n     */\n    public static @CheckForNull String hashify(String spec) {\n        if (spec.contains(\"H\")) {\n            // if someone is already using H, presumably he knows what it is, so a warning is likely false positive\n            return null;\n        } else if (spec.startsWith(\"*/\")) {// \"*/15 ....\" (every N minutes) to hash\n            return \"H\" + spec.substring(1);\n        } else if (spec.matches(\"\\\\d+ .+\")) {// \"0 ...\" (certain minute) to hash\n            return \"H \" + spec.substring(spec.indexOf(' ') + 1);\n        } else {\n            Matcher m = Pattern.compile(\"0(,(\\\\d+)(,\\\\d+)*)( .+)\").matcher(spec);\n            if (m.matches()) { // 0,15,30,45 to H/15\n                int period = Integer.parseInt(m.group(2));\n                if (period > 0) {\n                    StringBuilder b = new StringBuilder();\n                    for (int i = period; i < 60; i += period) {\n                        b.append(',').append(i);\n                    }\n                    if (b.toString().equals(m.group(1))) {\n                        return \"H/\" + period + m.group(4);\n                    }\n                }\n            }\n            return null;\n        }\n    }\n\n    /**\n     * Returns the configured time zone, or null if none is configured\n     *\n     * @return the configured time zone, or null if none is configured\n     * @since 2.54\n     */\n    @CheckForNull public TimeZone getTimeZone() {\n        if (this.specTimezone == null) {\n            return null;\n        }\n        return TimeZone.getTimeZone(this.specTimezone);\n    }\n}\n",
    "target": 0,
    "language": "java",
    "dataset": "vul4j",
    "idx": 200161,
    "RELATED_CWE": [
      "CWE-908",
      "CWE-362",
      "CWE-667"
    ]
  },
  {
    "CWE_ID": [
      "CWE-835"
    ],
    "code": "/*\n * The MIT License\n * \n * Copyright (c) 2004-2009, Sun Microsystems, Inc., Kohsuke Kawaguchi, InfraDNA, Inc.\n * \n * Permission is hereby granted, free of charge, to any person obtaining a copy\n * of this software and associated documentation files (the \"Software\"), to deal\n * in the Software without restriction, including without limitation the rights\n * to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n * copies of the Software, and to permit persons to whom the Software is\n * furnished to do so, subject to the following conditions:\n * \n * The above copyright notice and this permission notice shall be included in\n * all copies or substantial portions of the Software.\n * \n * THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n * OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\n * THE SOFTWARE.\n */\npackage hudson.scheduler;\n\nimport antlr.ANTLRException;\n\nimport java.io.StringReader;\nimport java.util.Calendar;\nimport java.util.TimeZone;\nimport java.util.GregorianCalendar;\nimport java.util.Locale;\nimport java.util.regex.Matcher;\nimport java.util.regex.Pattern;\n\nimport static java.util.Calendar.*;\nimport javax.annotation.CheckForNull;\n\n/**\n * Table for driving scheduled tasks.\n *\n * @author Kohsuke Kawaguchi\n */\npublic final class CronTab {\n    /**\n     * bits[0]: minutes\n     * bits[1]: hours\n     * bits[2]: days\n     * bits[3]: months\n     *\n     * false:not scheduled &lt;-> true scheduled\n     */\n    final long[] bits = new long[4];\n\n    int dayOfWeek;\n\n    /**\n     * Textual representation.\n     */\n    private String spec;\n\n    /**\n     * Optional timezone string for calendar \n     */\n    private @CheckForNull String specTimezone;\n\n    public CronTab(String format) throws ANTLRException {\n        this(format,null);\n    }\n\n    public CronTab(String format, Hash hash) throws ANTLRException {\n        this(format,1,hash);\n    }\n    \n    /**\n     * @deprecated as of 1.448\n     *      Use {@link #CronTab(String, int, Hash)}\n     */\n    @Deprecated\n    public CronTab(String format, int line) throws ANTLRException {\n        set(format, line, null);\n    }\n\n    /**\n     * @param hash\n     *      Used to spread out token like \"@daily\". Null to preserve the legacy behaviour\n     *      of not spreading it out at all.\n     */\n    public CronTab(String format, int line, Hash hash) throws ANTLRException {\n        this(format, line, hash, null);\n    }\n\n    /**\n     * @param timezone\n     *      Used to schedule cron in a different timezone. Null to use the default system \n     *      timezone\n     * @since 1.615\n     */\n    public CronTab(String format, int line, Hash hash, @CheckForNull String timezone) throws ANTLRException {\n        set(format, line, hash, timezone);\n    }\n    \n    private void set(String format, int line, Hash hash) throws ANTLRException {\n        set(format, line, hash, null);\n    }\n\n    /**\n     * @since 1.615\n     */\n    private void set(String format, int line, Hash hash, String timezone) throws ANTLRException {\n        CrontabLexer lexer = new CrontabLexer(new StringReader(format));\n        lexer.setLine(line);\n        CrontabParser parser = new CrontabParser(lexer);\n        parser.setHash(hash);\n        spec = format;\n        specTimezone = timezone;\n\n        parser.startRule(this);\n        if((dayOfWeek&(1<<7))!=0) {\n            dayOfWeek |= 1; // copy bit 7 over to bit 0\n            dayOfWeek &= ~(1<<7); // clear bit 7 or CalendarField#ceil will return an invalid value 7\n        }\n    }\n\n\n    /**\n     * Returns true if the given calendar matches\n     */\n    boolean check(Calendar cal) {\n\n        Calendar checkCal = cal;\n\n        if(specTimezone != null && !specTimezone.isEmpty()) {\n            Calendar tzCal = Calendar.getInstance(TimeZone.getTimeZone(specTimezone));\n            tzCal.setTime(cal.getTime());\n            checkCal = tzCal;\n        }\n\n        if(!checkBits(bits[0],checkCal.get(MINUTE)))\n            return false;\n        if(!checkBits(bits[1],checkCal.get(HOUR_OF_DAY)))\n            return false;\n        if(!checkBits(bits[2],checkCal.get(DAY_OF_MONTH)))\n            return false;\n        if(!checkBits(bits[3],checkCal.get(MONTH)+1))\n            return false;\n        if(!checkBits(dayOfWeek,checkCal.get(Calendar.DAY_OF_WEEK)-1))\n            return false;\n\n        return true;\n    }\n\n    private static abstract class CalendarField {\n        /**\n         * {@link Calendar} field ID.\n         */\n        final int field;\n        /**\n         * Lower field is a calendar field whose value needs to be reset when we change the value in this field.\n         * For example, if we modify the value in HOUR, MINUTES must be reset.\n         */\n        final CalendarField lowerField;\n        /**\n         * Whether this field is 0-origin or 1-origin differs between Crontab and {@link Calendar},\n         * so this field adjusts that. If crontab is 1 origin and calendar is 0 origin,  this field is 1\n         * that is the value is {@code (cronOrigin-calendarOrigin)}\n         */\n        final int offset;\n        /**\n         * When we reset this field, we set the field to this value.\n         * For example, resetting {@link Calendar#DAY_OF_MONTH} means setting it to 1.\n         */\n        final int min;\n        /**\n         * If this calendar field has other aliases such that a change in this field\n         * modifies other field values, then true.\n         */\n        final boolean redoAdjustmentIfModified;\n\n        /**\n         * What is this field? Useful for debugging\n         */\n        @SuppressWarnings(\"unused\")\n        private final String displayName;\n\n        private CalendarField(String displayName, int field, int min, int offset, boolean redoAdjustmentIfModified, CalendarField lowerField) {\n            this.displayName = displayName;\n            this.field = field;\n            this.min = min;\n            this.redoAdjustmentIfModified= redoAdjustmentIfModified;\n            this.lowerField = lowerField;\n            this.offset = offset;\n        }\n\n        /**\n         * Gets the current value of this field in the given calendar.\n         */\n        int valueOf(Calendar c) {\n            return c.get(field)+offset;\n        }\n\n        void addTo(Calendar c, int i) {\n            c.add(field,i);\n        }\n\n        void setTo(Calendar c, int i) {\n            c.set(field,Math.min(i-offset, c.getActualMaximum(field)));\n        }\n\n        void clear(Calendar c) {\n            setTo(c, min);\n        }\n\n        /**\n         * Given the value 'n' (which represents the current value), finds the smallest x such that:\n         *  1) x matches the specified {@link CronTab} (as far as this field is concerned.)\n         *  2) x>=n   (inclusive)\n         *\n         * If there's no such bit, return -1. Note that if 'n' already matches the crontab, the same n will be returned.\n         */\n        private int ceil(CronTab c, int n) {\n            long bits = bits(c);\n            while ((bits|(1L<<n))!=bits) {\n                if (n>60)   return -1;\n                n++;\n            }\n            return n;\n        }\n\n        /**\n         * Given a bit mask, finds the first bit that's on, and return its index.\n         */\n        private int first(CronTab c) {\n            return ceil(c,0);\n        }\n\n        private int floor(CronTab c, int n) {\n            long bits = bits(c);\n            while ((bits|(1L<<n))!=bits) {\n                if (n==0)   return -1;\n                n--;\n            }\n            return n;\n        }\n\n        private int last(CronTab c) {\n            return floor(c,63);\n        }\n\n        /**\n         * Extracts the bit masks from the given {@link CronTab} that matches this field.\n         */\n        abstract long bits(CronTab c);\n\n        /**\n         * Increment the next field.\n         */\n        abstract void rollUp(Calendar cal, int i);\n\n        private static final CalendarField MINUTE       = new CalendarField(\"minute\", Calendar.MINUTE,        0, 0, false, null) {\n            long bits(CronTab c) { return c.bits[0]; }\n            void rollUp(Calendar cal, int i) { cal.add(Calendar.HOUR_OF_DAY,i); }\n        };\n        private static final CalendarField HOUR         = new CalendarField(\"hour\", Calendar.HOUR_OF_DAY,   0, 0, false, MINUTE) {\n            long bits(CronTab c) { return c.bits[1]; }\n            void rollUp(Calendar cal, int i) { cal.add(Calendar.DAY_OF_MONTH,i); }\n        };\n        private static final CalendarField DAY_OF_MONTH = new CalendarField(\"day\", Calendar.DAY_OF_MONTH,  1, 0, true,  HOUR) {\n            long bits(CronTab c) { return c.bits[2]; }\n            void rollUp(Calendar cal, int i) { cal.add(Calendar.MONTH,i); }\n        };\n        private static final CalendarField MONTH        = new CalendarField(\"month\", Calendar.MONTH,         1, 1, false, DAY_OF_MONTH) {\n            long bits(CronTab c) { return c.bits[3]; }\n            void rollUp(Calendar cal, int i) { cal.add(Calendar.YEAR,i); }\n        };\n        private static final CalendarField DAY_OF_WEEK  = new CalendarField(\"dow\", Calendar.DAY_OF_WEEK,   1,-1, true,  HOUR) {\n            long bits(CronTab c) { return c.dayOfWeek; }\n            void rollUp(Calendar cal, int i) {\n                cal.add(Calendar.DAY_OF_WEEK, 7 * i);\n            }\n\n            @Override\n            void setTo(Calendar c, int i) {\n                int v = i-offset;\n                int was = c.get(field);\n                c.set(field,v);\n                final int firstDayOfWeek = c.getFirstDayOfWeek();\n                if (v < firstDayOfWeek && was >= firstDayOfWeek) {\n                    // in crontab, the first DoW is always Sunday, but in Java, it can be Monday or in theory arbitrary other days.\n                    // When first DoW is 1/2 Monday, calendar points to 1/2 Monday, setting the DoW to Sunday makes\n                    // the calendar moves forward to 1/8 Sunday, instead of 1/1 Sunday. So we need to compensate that effect here.\n                    addTo(c,-7);\n                } else if (was < firstDayOfWeek && firstDayOfWeek <= v) {\n                    // If we wrap the other way around, we need to adjust in the opposite direction of above.\n                    addTo(c, 7);\n                }\n            }\n        };\n\n        private static final CalendarField[] ADJUST_ORDER = {\n            MONTH, DAY_OF_MONTH, DAY_OF_WEEK, HOUR, MINUTE\n        };\n    }\n\n\n    /**\n     * Computes the nearest future timestamp that matches this cron tab.\n     * <p>\n     * More precisely, given the time 't', computes another smallest time x such that:\n     *\n     * <ul>\n     * <li>x \u2265 t (inclusive)\n     * <li>x matches this crontab\n     * </ul>\n     *\n     * <p>\n     * Note that if t already matches this cron, it's returned as is.\n     */\n    public Calendar ceil(long t) {\n        Calendar cal = new GregorianCalendar(Locale.US);\n        cal.setTimeInMillis(t);\n        return ceil(cal);\n    }\n\n    /**\n     * See {@link #ceil(long)}.\n     *\n     * This method modifies the given calendar and returns the same object.\n     *\n     * @throws RareOrImpossibleDateException if the date isn't hit in the 2 years after it indicates an impossible\n     * (e.g. Jun 31) date, or at least a date too rare to be useful. This addresses JENKINS-41864 and was added in 2.49\n     */\n    public Calendar ceil(Calendar cal) {\n        Calendar twoYearsFuture = (Calendar) cal.clone();\n        twoYearsFuture.add(Calendar.YEAR, 2);\n        OUTER:\n        while (true) {\n            if (cal.compareTo(twoYearsFuture) > 0) {\n                // we went too far into the future\n                throw new RareOrImpossibleDateException();\n            }\n            for (CalendarField f : CalendarField.ADJUST_ORDER) {\n                int cur = f.valueOf(cal);\n                int next = f.ceil(this,cur);\n                if (cur==next)  continue;   // this field is already in a good shape. move on to next\n\n                // we are modifying this field, so clear all the lower level fields\n                for (CalendarField l=f.lowerField; l!=null; l=l.lowerField)\n                    l.clear(cal);\n\n                if (next<0) {\n                    // we need to roll over to the next field.\n                    f.rollUp(cal, 1);\n                    f.setTo(cal,f.first(this));\n                    // since higher order field is affected by this, we need to restart from all over\n                    continue OUTER;\n                } else {\n                    f.setTo(cal,next);\n                    if (f.redoAdjustmentIfModified)\n                        continue OUTER; // when we modify DAY_OF_MONTH and DAY_OF_WEEK, do it all over from the top\n                }\n            }\n            return cal; // all fields adjusted\n        }\n    }\n\n    /**\n     * Computes the nearest past timestamp that matched this cron tab.\n     * <p>\n     * More precisely, given the time 't', computes another smallest time x such that:\n     *\n     * <ul>\n     * <li>x &lt;= t (inclusive)\n     * <li>x matches this crontab\n     * </ul>\n     *\n     * <p>\n     * Note that if t already matches this cron, it's returned as is.\n     */\n    public Calendar floor(long t) {\n        Calendar cal = new GregorianCalendar(Locale.US);\n        cal.setTimeInMillis(t);\n        return floor(cal);\n    }\n\n    /**\n     * See {@link #floor(long)}\n     *\n     * This method modifies the given calendar and returns the same object.\n     *\n     * @throws RareOrImpossibleDateException if the date isn't hit in the 2 years before it indicates an impossible\n     * (e.g. Jun 31) date, or at least a date too rare to be useful. This addresses JENKINS-41864 and was added in 2.49\n     */\n    public Calendar floor(Calendar cal) {\n        Calendar twoYearsAgo = (Calendar) cal.clone();\n        twoYearsAgo.add(Calendar.YEAR, -2);\n\n        OUTER:\n        while (true) {\n            if (cal.compareTo(twoYearsAgo) < 0) {\n                // we went too far into the past\n                throw new RareOrImpossibleDateException();\n            }\n            for (CalendarField f : CalendarField.ADJUST_ORDER) {\n                int cur = f.valueOf(cal);\n                int next = f.floor(this,cur);\n                if (cur==next)  continue;   // this field is already in a good shape. move on to next\n\n                // we are modifying this field, so clear all the lower level fields\n                for (CalendarField l=f.lowerField; l!=null; l=l.lowerField)\n                    l.clear(cal);\n\n                if (next<0) {\n                    // we need to borrow from the next field.\n                    f.rollUp(cal,-1);\n                    // the problem here, in contrast with the ceil method, is that\n                    // the maximum value of the field is not always a fixed value (that is, day of month)\n                    // so we zero-clear all the lower fields, set the desired value +1,\n                    f.setTo(cal,f.last(this));\n                    f.addTo(cal,1);\n                    // then subtract a minute to achieve maximum values on all the lower fields,\n                    // with the desired value in 'f'\n                    CalendarField.MINUTE.addTo(cal,-1);\n                    // since higher order field is affected by this, we need to restart from all over\n                    continue OUTER;\n                } else {\n                    f.setTo(cal,next);\n                    f.addTo(cal,1);\n                    CalendarField.MINUTE.addTo(cal,-1);\n                    if (f.redoAdjustmentIfModified)\n                        continue OUTER; // when we modify DAY_OF_MONTH and DAY_OF_WEEK, do it all over from the top\n                }\n            }\n            return cal; // all fields adjusted\n        }\n    }\n\n    void set(String format, Hash hash) throws ANTLRException {\n        set(format,1,hash);\n    }\n\n    /**\n     * Returns true if n-th bit is on.\n     */\n    private boolean checkBits(long bitMask, int n) {\n        return (bitMask|(1L<<n))==bitMask;\n    }\n\n    public String toString() {\n        return super.toString()+\"[\"+\n            toString(\"minute\",bits[0])+','+\n            toString(\"hour\",bits[1])+','+\n            toString(\"dayOfMonth\",bits[2])+','+\n            toString(\"month\",bits[3])+','+\n            toString(\"dayOfWeek\",dayOfWeek)+']';\n    }\n\n    private String toString(String key, long bit) {\n        return key+'='+Long.toHexString(bit);\n    }\n\n    /**\n     * Checks if this crontab entry looks reasonable,\n     * and if not, return an warning message.\n     *\n     * <p>\n     * The point of this method is to catch syntactically correct\n     * but semantically suspicious combinations, like\n     * \"* 0 * * *\"\n     */\n    public @CheckForNull String checkSanity() {\n        OUTER: for (int i = 0; i < 5; i++) {\n            long bitMask = (i<4)?bits[i]:(long)dayOfWeek;\n            for( int j=BaseParser.LOWER_BOUNDS[i]; j<=BaseParser.UPPER_BOUNDS[i]; j++ ) {\n                if(!checkBits(bitMask,j)) {\n                    // this rank has a sparse entry.\n                    // if we have a sparse rank, one of them better be the left-most.\n                    if(i>0)\n                        return Messages.CronTab_do_you_really_mean_every_minute_when_you(spec, \"H \" + spec.substring(spec.indexOf(' ') + 1));\n                    // once we find a sparse rank, upper ranks don't matter\n                    break OUTER;\n                }\n            }\n        }\n\n        int daysOfMonth = 0;\n        for (int i = 1; i < 31; i++) {\n            if (checkBits(bits[2], i)) {\n                daysOfMonth++;\n            }\n        }\n        if (daysOfMonth > 5 && daysOfMonth < 28) { // a bit arbitrary\n            return Messages.CronTab_short_cycles_in_the_day_of_month_field_w();\n        }\n\n        String hashified = hashify(spec);\n        if (hashified != null) {\n            return Messages.CronTab_spread_load_evenly_by_using_rather_than_(hashified, spec);\n        }\n\n        return null;\n    }\n\n    /**\n     * Checks a prospective crontab specification to see if it could benefit from balanced hashes.\n     * @param spec a (legal) spec\n     * @return a similar spec that uses a hash, if such a transformation is necessary; null if it is OK as is\n     * @since 1.510\n     */\n    public static @CheckForNull String hashify(String spec) {\n        if (spec.contains(\"H\")) {\n            // if someone is already using H, presumably he knows what it is, so a warning is likely false positive\n            return null;\n        } else if (spec.startsWith(\"*/\")) {// \"*/15 ....\" (every N minutes) to hash\n            return \"H\" + spec.substring(1);\n        } else if (spec.matches(\"\\\\d+ .+\")) {// \"0 ...\" (certain minute) to hash\n            return \"H \" + spec.substring(spec.indexOf(' ') + 1);\n        } else {\n            Matcher m = Pattern.compile(\"0(,(\\\\d+)(,\\\\d+)*)( .+)\").matcher(spec);\n            if (m.matches()) { // 0,15,30,45 to H/15\n                int period = Integer.parseInt(m.group(2));\n                if (period > 0) {\n                    StringBuilder b = new StringBuilder();\n                    for (int i = period; i < 60; i += period) {\n                        b.append(',').append(i);\n                    }\n                    if (b.toString().equals(m.group(1))) {\n                        return \"H/\" + period + m.group(4);\n                    }\n                }\n            }\n            return null;\n        }\n    }\n\n    /**\n     * Returns the configured time zone, or null if none is configured\n     *\n     * @return the configured time zone, or null if none is configured\n     * @since 2.54\n     */\n    @CheckForNull public TimeZone getTimeZone() {\n        if (this.specTimezone == null) {\n            return null;\n        }\n        return TimeZone.getTimeZone(this.specTimezone);\n    }\n}\n",
    "target": 1,
    "language": "java",
    "dataset": "vul4j",
    "idx": 200164,
    "RELATED_CWE": [
      "CWE-908",
      "CWE-362",
      "CWE-667"
    ]
  },
  {
    "CWE_ID": [
      "CWE-835"
    ],
    "code": "/*\n * The MIT License\n * \n * Copyright (c) 2004-2009, Sun Microsystems, Inc., Kohsuke Kawaguchi, InfraDNA, Inc.\n * \n * Permission is hereby granted, free of charge, to any person obtaining a copy\n * of this software and associated documentation files (the \"Software\"), to deal\n * in the Software without restriction, including without limitation the rights\n * to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n * copies of the Software, and to permit persons to whom the Software is\n * furnished to do so, subject to the following conditions:\n * \n * The above copyright notice and this permission notice shall be included in\n * all copies or substantial portions of the Software.\n * \n * THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n * OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\n * THE SOFTWARE.\n */\npackage hudson.scheduler;\n\nimport antlr.ANTLRException;\n\nimport java.io.StringReader;\nimport java.util.Calendar;\nimport java.util.TimeZone;\nimport java.util.GregorianCalendar;\nimport java.util.Locale;\nimport java.util.regex.Matcher;\nimport java.util.regex.Pattern;\n\nimport static java.util.Calendar.*;\nimport javax.annotation.CheckForNull;\n\n/**\n * Table for driving scheduled tasks.\n *\n * @author Kohsuke Kawaguchi\n */\npublic final class CronTab {\n    /**\n     * bits[0]: minutes\n     * bits[1]: hours\n     * bits[2]: days\n     * bits[3]: months\n     *\n     * false:not scheduled &lt;-> true scheduled\n     */\n    final long[] bits = new long[4];\n\n    int dayOfWeek;\n\n    /**\n     * Textual representation.\n     */\n    private String spec;\n\n    /**\n     * Optional timezone string for calendar \n     */\n    private @CheckForNull String specTimezone;\n\n    public CronTab(String format) throws ANTLRException {\n        this(format,null);\n    }\n\n    public CronTab(String format, Hash hash) throws ANTLRException {\n        this(format,1,hash);\n    }\n    \n    /**\n     * @deprecated as of 1.448\n     *      Use {@link #CronTab(String, int, Hash)}\n     */\n    @Deprecated\n    public CronTab(String format, int line) throws ANTLRException {\n        set(format, line, null);\n    }\n\n    /**\n     * @param hash\n     *      Used to spread out token like \"@daily\". Null to preserve the legacy behaviour\n     *      of not spreading it out at all.\n     */\n    public CronTab(String format, int line, Hash hash) throws ANTLRException {\n        this(format, line, hash, null);\n    }\n\n    /**\n     * @param timezone\n     *      Used to schedule cron in a different timezone. Null to use the default system \n     *      timezone\n     * @since 1.615\n     */\n    public CronTab(String format, int line, Hash hash, @CheckForNull String timezone) throws ANTLRException {\n        set(format, line, hash, timezone);\n    }\n    \n    private void set(String format, int line, Hash hash) throws ANTLRException {\n        set(format, line, hash, null);\n    }\n\n    /**\n     * @since 1.615\n     */\n    private void set(String format, int line, Hash hash, String timezone) throws ANTLRException {\n        CrontabLexer lexer = new CrontabLexer(new StringReader(format));\n        lexer.setLine(line);\n        CrontabParser parser = new CrontabParser(lexer);\n        parser.setHash(hash);\n        spec = format;\n        specTimezone = timezone;\n\n        parser.startRule(this);\n        if((dayOfWeek&(1<<7))!=0) {\n            dayOfWeek |= 1; // copy bit 7 over to bit 0\n            dayOfWeek &= ~(1<<7); // clear bit 7 or CalendarField#ceil will return an invalid value 7\n        }\n    }\n\n\n    /**\n     * Returns true if the given calendar matches\n     */\n    boolean check(Calendar cal) {\n\n        Calendar checkCal = cal;\n\n        if(specTimezone != null && !specTimezone.isEmpty()) {\n            Calendar tzCal = Calendar.getInstance(TimeZone.getTimeZone(specTimezone));\n            tzCal.setTime(cal.getTime());\n            checkCal = tzCal;\n        }\n\n        if(!checkBits(bits[0],checkCal.get(MINUTE)))\n            return false;\n        if(!checkBits(bits[1],checkCal.get(HOUR_OF_DAY)))\n            return false;\n        if(!checkBits(bits[2],checkCal.get(DAY_OF_MONTH)))\n            return false;\n        if(!checkBits(bits[3],checkCal.get(MONTH)+1))\n            return false;\n        if(!checkBits(dayOfWeek,checkCal.get(Calendar.DAY_OF_WEEK)-1))\n            return false;\n\n        return true;\n    }\n\n    private static abstract class CalendarField {\n        /**\n         * {@link Calendar} field ID.\n         */\n        final int field;\n        /**\n         * Lower field is a calendar field whose value needs to be reset when we change the value in this field.\n         * For example, if we modify the value in HOUR, MINUTES must be reset.\n         */\n        final CalendarField lowerField;\n        /**\n         * Whether this field is 0-origin or 1-origin differs between Crontab and {@link Calendar},\n         * so this field adjusts that. If crontab is 1 origin and calendar is 0 origin,  this field is 1\n         * that is the value is {@code (cronOrigin-calendarOrigin)}\n         */\n        final int offset;\n        /**\n         * When we reset this field, we set the field to this value.\n         * For example, resetting {@link Calendar#DAY_OF_MONTH} means setting it to 1.\n         */\n        final int min;\n        /**\n         * If this calendar field has other aliases such that a change in this field\n         * modifies other field values, then true.\n         */\n        final boolean redoAdjustmentIfModified;\n\n        /**\n         * What is this field? Useful for debugging\n         */\n        @SuppressWarnings(\"unused\")\n        private final String displayName;\n\n        private CalendarField(String displayName, int field, int min, int offset, boolean redoAdjustmentIfModified, CalendarField lowerField) {\n            this.displayName = displayName;\n            this.field = field;\n            this.min = min;\n            this.redoAdjustmentIfModified= redoAdjustmentIfModified;\n            this.lowerField = lowerField;\n            this.offset = offset;\n        }\n\n        /**\n         * Gets the current value of this field in the given calendar.\n         */\n        int valueOf(Calendar c) {\n            return c.get(field)+offset;\n        }\n\n        void addTo(Calendar c, int i) {\n            c.add(field,i);\n        }\n\n        void setTo(Calendar c, int i) {\n            c.set(field,Math.min(i-offset, c.getActualMaximum(field)));\n        }\n\n        void clear(Calendar c) {\n            setTo(c, min);\n        }\n\n        /**\n         * Given the value 'n' (which represents the current value), finds the smallest x such that:\n         *  1) x matches the specified {@link CronTab} (as far as this field is concerned.)\n         *  2) x>=n   (inclusive)\n         *\n         * If there's no such bit, return -1. Note that if 'n' already matches the crontab, the same n will be returned.\n         */\n        private int ceil(CronTab c, int n) {\n            long bits = bits(c);\n            while ((bits|(1L<<n))!=bits) {\n                if (n>60)   return -1;\n                n++;\n            }\n            return n;\n        }\n\n        /**\n         * Given a bit mask, finds the first bit that's on, and return its index.\n         */\n        private int first(CronTab c) {\n            return ceil(c,0);\n        }\n\n        private int floor(CronTab c, int n) {\n            long bits = bits(c);\n            while ((bits|(1L<<n))!=bits) {\n                if (n==0)   return -1;\n                n--;\n            }\n            return n;\n        }\n\n        private int last(CronTab c) {\n            return floor(c,63);\n        }\n\n        /**\n         * Extracts the bit masks from the given {@link CronTab} that matches this field.\n         */\n        abstract long bits(CronTab c);\n\n        /**\n         * Increment the next field.\n         */\n        abstract void rollUp(Calendar cal, int i);\n\n        private static final CalendarField MINUTE       = new CalendarField(\"minute\", Calendar.MINUTE,        0, 0, false, null) {\n            long bits(CronTab c) { return c.bits[0]; }\n            void rollUp(Calendar cal, int i) { cal.add(Calendar.HOUR_OF_DAY,i); }\n        };\n        private static final CalendarField HOUR         = new CalendarField(\"hour\", Calendar.HOUR_OF_DAY,   0, 0, false, MINUTE) {\n            long bits(CronTab c) { return c.bits[1]; }\n            void rollUp(Calendar cal, int i) { cal.add(Calendar.DAY_OF_MONTH,i); }\n        };\n        private static final CalendarField DAY_OF_MONTH = new CalendarField(\"day\", Calendar.DAY_OF_MONTH,  1, 0, true,  HOUR) {\n            long bits(CronTab c) { return c.bits[2]; }\n            void rollUp(Calendar cal, int i) { cal.add(Calendar.MONTH,i); }\n        };\n        private static final CalendarField MONTH        = new CalendarField(\"month\", Calendar.MONTH,         1, 1, false, DAY_OF_MONTH) {\n            long bits(CronTab c) { return c.bits[3]; }\n            void rollUp(Calendar cal, int i) { cal.add(Calendar.YEAR,i); }\n        };\n        private static final CalendarField DAY_OF_WEEK  = new CalendarField(\"dow\", Calendar.DAY_OF_WEEK,   1,-1, true,  HOUR) {\n            long bits(CronTab c) { return c.dayOfWeek; }\n            void rollUp(Calendar cal, int i) {\n                cal.add(Calendar.DAY_OF_WEEK, 7 * i);\n            }\n\n            @Override\n            void setTo(Calendar c, int i) {\n                int v = i-offset;\n                int was = c.get(field);\n                c.set(field,v);\n                final int firstDayOfWeek = c.getFirstDayOfWeek();\n                if (v < firstDayOfWeek && was >= firstDayOfWeek) {\n                    // in crontab, the first DoW is always Sunday, but in Java, it can be Monday or in theory arbitrary other days.\n                    // When first DoW is 1/2 Monday, calendar points to 1/2 Monday, setting the DoW to Sunday makes\n                    // the calendar moves forward to 1/8 Sunday, instead of 1/1 Sunday. So we need to compensate that effect here.\n                    addTo(c,-7);\n                } else if (was < firstDayOfWeek && firstDayOfWeek <= v) {\n                    // If we wrap the other way around, we need to adjust in the opposite direction of above.\n                    addTo(c, 7);\n                }\n            }\n        };\n\n        private static final CalendarField[] ADJUST_ORDER = {\n            MONTH, DAY_OF_MONTH, DAY_OF_WEEK, HOUR, MINUTE\n        };\n    }\n\n\n    /**\n     * Computes the nearest future timestamp that matches this cron tab.\n     * <p>\n     * More precisely, given the time 't', computes another smallest time x such that:\n     *\n     * <ul>\n     * <li>x \u2265 t (inclusive)\n     * <li>x matches this crontab\n     * </ul>\n     *\n     * <p>\n     * Note that if t already matches this cron, it's returned as is.\n     */\n    public Calendar ceil(long t) {\n        Calendar cal = new GregorianCalendar(Locale.US);\n        cal.setTimeInMillis(t);\n        return ceil(cal);\n    }\n\n    /**\n     * See {@link #ceil(long)}.\n     *\n     * This method modifies the given calendar and returns the same object.\n     *\n     * @throws RareOrImpossibleDateException if the date isn't hit in the 2 years after it indicates an impossible\n     * (e.g. Jun 31) date, or at least a date too rare to be useful. This addresses JENKINS-41864 and was added in 2.49\n     */\n    public Calendar ceil(Calendar cal) {\n        Calendar twoYearsFuture = (Calendar) cal.clone();\n        twoYearsFuture.add(Calendar.YEAR, 2);\n        OUTER:\n        while (true) {\n            if (cal.compareTo(twoYearsFuture) > 0) {\n                // we went too far into the future\n                throw new RareOrImpossibleDateException();\n            }\n            for (CalendarField f : CalendarField.ADJUST_ORDER) {\n                int cur = f.valueOf(cal);\n                int next = f.ceil(this,cur);\n                if (cur==next)  continue;   // this field is already in a good shape. move on to next\n\n                // we are modifying this field, so clear all the lower level fields\n                for (CalendarField l=f.lowerField; l!=null; l=l.lowerField)\n                    l.clear(cal);\n\n                if (next<0) {\n                    // we need to roll over to the next field.\n                    f.rollUp(cal, 1);\n                    f.setTo(cal,f.first(this));\n                    // since higher order field is affected by this, we need to restart from all over\n                    continue OUTER;\n                } else {\n                    f.setTo(cal,next);\n                    //check if value was actually set\n                    if (f.valueOf(cal) != next) {\n                        // we need to roll over to the next field.\n                        f.rollUp(cal, 1);\n                        f.setTo(cal,f.first(this));\n                        // since higher order field is affected by this, we need to restart from all over\n                        continue OUTER;\n                    }\n                    if (f.redoAdjustmentIfModified)\n                        continue OUTER; // when we modify DAY_OF_MONTH and DAY_OF_WEEK, do it all over from the top\n                }\n            }\n            return cal; // all fields adjusted\n        }\n    }\n\n    /**\n     * Computes the nearest past timestamp that matched this cron tab.\n     * <p>\n     * More precisely, given the time 't', computes another smallest time x such that:\n     *\n     * <ul>\n     * <li>x &lt;= t (inclusive)\n     * <li>x matches this crontab\n     * </ul>\n     *\n     * <p>\n     * Note that if t already matches this cron, it's returned as is.\n     */\n    public Calendar floor(long t) {\n        Calendar cal = new GregorianCalendar(Locale.US);\n        cal.setTimeInMillis(t);\n        return floor(cal);\n    }\n\n    /**\n     * See {@link #floor(long)}\n     *\n     * This method modifies the given calendar and returns the same object.\n     *\n     * @throws RareOrImpossibleDateException if the date isn't hit in the 2 years before it indicates an impossible\n     * (e.g. Jun 31) date, or at least a date too rare to be useful. This addresses JENKINS-41864 and was added in 2.49\n     */\n    public Calendar floor(Calendar cal) {\n        Calendar twoYearsAgo = (Calendar) cal.clone();\n        twoYearsAgo.add(Calendar.YEAR, -2);\n\n        OUTER:\n        while (true) {\n            if (cal.compareTo(twoYearsAgo) < 0) {\n                // we went too far into the past\n                throw new RareOrImpossibleDateException();\n            }\n            for (CalendarField f : CalendarField.ADJUST_ORDER) {\n                int cur = f.valueOf(cal);\n                int next = f.floor(this,cur);\n                if (cur==next)  continue;   // this field is already in a good shape. move on to next\n\n                // we are modifying this field, so clear all the lower level fields\n                for (CalendarField l=f.lowerField; l!=null; l=l.lowerField)\n                    l.clear(cal);\n\n                if (next<0) {\n                    // we need to borrow from the next field.\n                    f.rollUp(cal,-1);\n                    // the problem here, in contrast with the ceil method, is that\n                    // the maximum value of the field is not always a fixed value (that is, day of month)\n                    // so we zero-clear all the lower fields, set the desired value +1,\n                    f.setTo(cal,f.last(this));\n                    f.addTo(cal,1);\n                    // then subtract a minute to achieve maximum values on all the lower fields,\n                    // with the desired value in 'f'\n                    CalendarField.MINUTE.addTo(cal,-1);\n                    // since higher order field is affected by this, we need to restart from all over\n                    continue OUTER;\n                } else {\n                    f.setTo(cal,next);\n                    f.addTo(cal,1);\n                    CalendarField.MINUTE.addTo(cal,-1);\n                    if (f.redoAdjustmentIfModified)\n                        continue OUTER; // when we modify DAY_OF_MONTH and DAY_OF_WEEK, do it all over from the top\n                }\n            }\n            return cal; // all fields adjusted\n        }\n    }\n\n    void set(String format, Hash hash) throws ANTLRException {\n        set(format,1,hash);\n    }\n\n    /**\n     * Returns true if n-th bit is on.\n     */\n    private boolean checkBits(long bitMask, int n) {\n        return (bitMask|(1L<<n))==bitMask;\n    }\n\n    public String toString() {\n        return super.toString()+\"[\"+\n            toString(\"minute\",bits[0])+','+\n            toString(\"hour\",bits[1])+','+\n            toString(\"dayOfMonth\",bits[2])+','+\n            toString(\"month\",bits[3])+','+\n            toString(\"dayOfWeek\",dayOfWeek)+']';\n    }\n\n    private String toString(String key, long bit) {\n        return key+'='+Long.toHexString(bit);\n    }\n\n    /**\n     * Checks if this crontab entry looks reasonable,\n     * and if not, return an warning message.\n     *\n     * <p>\n     * The point of this method is to catch syntactically correct\n     * but semantically suspicious combinations, like\n     * \"* 0 * * *\"\n     */\n    public @CheckForNull String checkSanity() {\n        OUTER: for (int i = 0; i < 5; i++) {\n            long bitMask = (i<4)?bits[i]:(long)dayOfWeek;\n            for( int j=BaseParser.LOWER_BOUNDS[i]; j<=BaseParser.UPPER_BOUNDS[i]; j++ ) {\n                if(!checkBits(bitMask,j)) {\n                    // this rank has a sparse entry.\n                    // if we have a sparse rank, one of them better be the left-most.\n                    if(i>0)\n                        return Messages.CronTab_do_you_really_mean_every_minute_when_you(spec, \"H \" + spec.substring(spec.indexOf(' ') + 1));\n                    // once we find a sparse rank, upper ranks don't matter\n                    break OUTER;\n                }\n            }\n        }\n\n        int daysOfMonth = 0;\n        for (int i = 1; i < 31; i++) {\n            if (checkBits(bits[2], i)) {\n                daysOfMonth++;\n            }\n        }\n        if (daysOfMonth > 5 && daysOfMonth < 28) { // a bit arbitrary\n            return Messages.CronTab_short_cycles_in_the_day_of_month_field_w();\n        }\n\n        String hashified = hashify(spec);\n        if (hashified != null) {\n            return Messages.CronTab_spread_load_evenly_by_using_rather_than_(hashified, spec);\n        }\n\n        return null;\n    }\n\n    /**\n     * Checks a prospective crontab specification to see if it could benefit from balanced hashes.\n     * @param spec a (legal) spec\n     * @return a similar spec that uses a hash, if such a transformation is necessary; null if it is OK as is\n     * @since 1.510\n     */\n    public static @CheckForNull String hashify(String spec) {\n        if (spec.contains(\"H\")) {\n            // if someone is already using H, presumably he knows what it is, so a warning is likely false positive\n            return null;\n        } else if (spec.startsWith(\"*/\")) {// \"*/15 ....\" (every N minutes) to hash\n            return \"H\" + spec.substring(1);\n        } else if (spec.matches(\"\\\\d+ .+\")) {// \"0 ...\" (certain minute) to hash\n            return \"H \" + spec.substring(spec.indexOf(' ') + 1);\n        } else {\n            Matcher m = Pattern.compile(\"0(,(\\\\d+)(,\\\\d+)*)( .+)\").matcher(spec);\n            if (m.matches()) { // 0,15,30,45 to H/15\n                int period = Integer.parseInt(m.group(2));\n                if (period > 0) {\n                    StringBuilder b = new StringBuilder();\n                    for (int i = period; i < 60; i += period) {\n                        b.append(',').append(i);\n                    }\n                    if (b.toString().equals(m.group(1))) {\n                        return \"H/\" + period + m.group(4);\n                    }\n                }\n            }\n            return null;\n        }\n    }\n\n    /**\n     * Returns the configured time zone, or null if none is configured\n     *\n     * @return the configured time zone, or null if none is configured\n     * @since 2.54\n     */\n    @CheckForNull public TimeZone getTimeZone() {\n        if (this.specTimezone == null) {\n            return null;\n        }\n        return TimeZone.getTimeZone(this.specTimezone);\n    }\n}\n",
    "target": 0,
    "language": "java",
    "dataset": "vul4j",
    "idx": 200165,
    "RELATED_CWE": [
      "CWE-908",
      "CWE-362",
      "CWE-667"
    ]
  }
]